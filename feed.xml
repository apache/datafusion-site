<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://datafusion.apache.org/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://datafusion.apache.org/blog/" rel="alternate" type="text/html" /><updated>2024-07-24T10:33:30+00:00</updated><id>https://datafusion.apache.org/blog/feed.xml</id><title type="html">Apache DataFusion Project News &amp;amp; Blog</title><subtitle>Apache DataFusion is a very fast, extensible query engine for building high-quality  data-centric systems in Rust, using the Apache Arrow in-memory format.</subtitle><entry><title type="html">Apache DataFusion 40.0.0 Released</title><link href="https://datafusion.apache.org/blog/2024/07/24/datafusion-40.0.0/" rel="alternate" type="text/html" title="Apache DataFusion 40.0.0 Released" /><published>2024-07-24T00:00:00+00:00</published><updated>2024-07-24T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2024/07/24/datafusion-40.0.0</id><content type="html" xml:base="https://datafusion.apache.org/blog/2024/07/24/datafusion-40.0.0/"><![CDATA[<!--

-->

<!-- see https://github.com/apache/datafusion/issues/9602 for details -->

<h2 id="introduction">Introduction</h2>

<p>We are proud to announce <a href="https://crates.io/crates/datafusion/40.0.0">DataFusion 40.0.0</a>. This blog highlights some of the
many major improvements since we released <a href="https://datafusion.apache.org/blog/2024/01/19/datafusion-34.0.0/">DataFusion 34.0.0</a> and a preview of
what the community is thinking about in the next 6 months. We are hoping to make
more regular blog posts ‚Äì if you are interested in helping write them, please
reach out!</p>

<p><a href="https://datafusion.apache.org/">Apache DataFusion</a> is an extensible query engine, written in <a href="https://www.rust-lang.org/">Rust</a>, that
uses <a href="https://arrow.apache.org">Apache Arrow</a> as its in-memory format. DataFusion is used by developers to
create new, fast data centric systems such as databases, dataframe libraries,
machine learning and streaming applications. While <a href="https://datafusion.apache.org/user-guide/introduction.html#project-goals">DataFusion‚Äôs primary design
goal</a> is to accelerate the creation of other data centric systems, it has a
reasonable experience directly out of the box as a <a href="https://datafusion.apache.org/python/">dataframe library</a> and
<a href="https://datafusion.apache.org/user-guide/cli/">command line SQL tool</a>.</p>

<p>DataFusion‚Äôs core thesis is that as a community, together we can build much more
advanced technology than any of us as individuals or companies could do alone. 
Without DataFusion, highly performant vectorized query engines would remain
the domain of a few large companies and world-class research institutions. 
With DataFusion, we can all build on top of a shared foundation, and focus on
what makes our projects unique.</p>

<h2 id="community-growth--">Community Growth  üìà</h2>

<p>In the last 6 months, between <code class="language-plaintext highlighter-rouge">34.0.0</code> and <code class="language-plaintext highlighter-rouge">40.0.0</code>, our community continues to
grow in new and exciting ways.</p>

<ol>
  <li>DataFusion became a top level Apache Software Foundation project (read the
<a href="https://news.apache.org/foundation/entry/apache-software-foundation-announces-new-top-level-project-apache-datafusion">press release</a> and <a href="https://datafusion.apache.org/blog/2024/05/07/datafusion-tlp/">blog post</a>).</li>
  <li>We added several PMC members and new
committers: <a href="https://github.com/comphead">@comphead</a>, <a href="https://github.com/mustafasrepo">@mustafasrepo</a>, <a href="https://github.com/ozankabak">@ozankabak</a>, and <a href="https://github.com/waynexia">@waynexia</a> joined the PMC,
<a href="https://github.com/jonahgao">@jonahgao</a> and <a href="https://github.com/lewiszlw">@lewiszlw</a> joined as committers. See the <a href="https://lists.apache.org/list.html?dev@datafusion.apache.org">mailing list</a> for
more details.</li>
  <li><a href="https://datafusion.apache.org/comet/">DataFusion Comet</a> was <a href="https://arrow.apache.org/blog/2024/03/06/comet-donation/">donated</a> and is nearing its first release.</li>
  <li>In the <a href="https://github.com/apache/arrow-datafusion">core DataFusion repo</a> alone we reviewed and accepted almost 1500 PRs from 182 different
committers, created over 1000 issues and closed 781 of them üöÄ. This is up
almost 50% from our last post (1000 PRs from 124 committers with 650 issues
created in our last post) ü§Ø. All changes are listed in the detailed
<a href="https://github.com/apache/datafusion/blob/main/datafusion/CHANGELOG.md">CHANGELOG</a>.</li>
  <li>DataFusion focused meetups happened or are happening in multiple cities 
around the world: <a href="https://github.com/apache/datafusion/discussions/8522">Austin</a>, <a href="https://github.com/apache/datafusion/discussions/10800">San Francisco</a>, <a href="https://www.huodongxing.com/event/5761971909400?td=1965290734055">Hangzhou</a>, <a href="https://github.com/apache/datafusion/discussions/11213">New York</a>, and
<a href="https://github.com/apache/datafusion/discussions/11431">Belgrade</a>.</li>
  <li>Many new projects started in the <a href="https://github.com/datafusion-contrib">datafusion-contrib</a> organization, including
<a href="https://github.com/datafusion-contrib/datafusion-table-providers">Table Providers</a>, <a href="https://github.com/datafusion-contrib/datafusion-sqlancer">SQLancer</a>, <a href="https://github.com/datafusion-contrib/datafusion-functions-variant">Open Variant</a>, <a href="https://github.com/datafusion-contrib/datafusion-functions-json">JSON</a>, and <a href="https://github.com/datafusion-contrib/datafusion-orc">ORC</a>.</li>
</ol>

<!--
$ git log --pretty=oneline 34.0.0..40.0.0 . | wc -l
     1453 (up from 1009)

$ git shortlog -sn 34.0.0..40.0.0 . | wc -l
      182 (up from 124)

https://crates.io/crates/datafusion/34.0.0
DataFusion 34 released Dec 17, 2023

https://crates.io/crates/datafusion/40.0.0
DataFusion 34 released July 12, 2024

Issues created in this time: 321 open, 781 closed (up from 214 open, 437 closed)
https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+created%3A2023-12-17..2024-07-12

Issues closed: 911 (up from 517)
https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+closed%3A2023-12-17..2024-07-12

PRs merged in this time 1490 (up from 908)
https://github.com/apache/arrow-datafusion/pulls?q=is%3Apr+merged%3A2023-12-17..2024-07-12

-->

<p>In addition, DataFusion has been appearing publicly more and more, both online and offline. Here are some highlights:</p>

<ol>
  <li><a href="https://dl.acm.org/doi/10.1145/3626246.3653368">Apache Arrow DataFusion: A Fast, Embeddable, Modular Analytic Query Engine</a>, was presented in <a href="https://2024.sigmod.org/">SIGMOD ‚Äò24</a>, one of the major database conferences</li>
  <li>As part of the trend to define ‚Äúthe POSIX of databases‚Äù in <a href="https://db.cs.cmu.edu/papers/2024/whatgoesaround-sigmodrec2024.pdf">‚ÄúWhat Goes Around Comes Around‚Ä¶ And Around‚Ä¶‚Äù</a> from Andy Pavlo and Mike Stonebraker</li>
  <li><a href="https://www.cpard.xyz/posts/datafusion/">‚ÄúWhy you should keep an eye on Apache DataFusion and its community‚Äù</a></li>
  <li><a href="https://www.tisonkun.org/2024/07/15/datafusion-meetup-san-francisco/">Apache DataFusion offline meetup in the Bay Area</a></li>
</ol>

<h2 id="improved-performance-">Improved Performance üöÄ</h2>

<p>Performance is a key feature of DataFusion, and the community continues to work
to keep DataFusion state of the art in this area. One major area DataFusion
improved is the time it takes to convert a SQL query into a plan that can be
executed. Planning is now almost 2x faster for TPC-DS and TPC-H queries, and
over 10x faster for some queries with many columns.</p>

<p>Here is a chart showing the improvement due to the concerted effort of many
contributors including <a href="https://github.com/jackwener">@jackwener</a>, <a href="https://github.com/alamb">@alamb</a>, <a href="https://github.com/Lordworms">@Lordworms</a>, <a href="https://github.com/dmitrybugakov">@dmitrybugakov</a>,
<a href="https://github.com/appletreeisyellow">@appletreeisyellow</a>, <a href="https://github.com/ClSlaid">@ClSlaid</a>, <a href="https://github.com/rohitrastogi">@rohitrastogi</a>, <a href="https://github.com/emgeee">@emgeee</a>, <a href="https://github.com/kevinmingtarja">@kevinmingtarja</a>,
and <a href="https://github.com/peter-toth">@peter-toth</a> over several months (see <a href="https://github.com/apache/arrow-datafusion/issues/8045">ticket</a> for more details)</p>

<p><img src="/blog/assets/datafusion-40.0.0/improved-planning-time.png" width="700" /></p>

<p>DataFusion is now up to 40% faster for queries that <code class="language-plaintext highlighter-rouge">GROUP BY</code> a single string
or binary column due to a <a href="https://github.com/apache/datafusion/pull/8827">specialization for single
Uft8/LargeUtf8/Binary/LargeBinary</a>. We are working on improving performance when
there are <a href="https://github.com/apache/datafusion/issues/9403">multiple variable length columns in the <code class="language-plaintext highlighter-rouge">GROUP BY</code> clause</a>.</p>

<p>We are also in the final phases of <a href="https://github.com/apache/datafusion/issues/10918">integrating</a> the new <a href="https://docs.rs/arrow/latest/arrow/array/struct.GenericByteViewArray.html">Arrow StringView</a>
which significantly improves performance for workloads that scan, filter and
group by variable length string and binary data. We expect the improvement to be
especially pronounced for Parquet files due to <a href="https://github.com/apache/arrow-rs/issues/5530">upstream work in the parquet
reader</a>. Kudos to <a href="https://github.com/XiangpengHong">@XiangpengHong</a>, <a href="https://github.com/AriesDevil">@AriesDevil</a>, <a href="https://github.com/PsiACE">@PsiACE</a>, <a href="https://github.com/Weijun-H">@Weijun-H</a>,
<a href="https://github.com/a10y">@a10y</a>, and <a href="https://github.com/RinChanNOWWW">@RinChanNOWWW</a> for driving this project.</p>

<h2 id="improved-quality-">Improved Quality üìã</h2>

<p>DataFusion continues to improve overall in quality. In addition to ongoing bug
fixes, one of the most exciting improvements is the addition of a new <a href="https://github.com/datafusion-contrib/datafusion-sqlancer">SQLancer</a>
based <a href="https://github.com/apache/datafusion/issues/11030">DataFusion Fuzzing</a> suite thanks to <a href="https://github.com/2010YOUY01">@2010YOUY01</a> that has already found
several bugs and thanks to <a href="https://github.com/jonahgao">@jonahgao</a>, <a href="https://github.com/tshauck">@tshauck</a>, <a href="https://github.com/xinlifoobar">@xinlifoobar</a>,
<a href="https://github.com/LorrensP-2158466">@LorrensP-2158466</a> for fixing them so fast.</p>

<h2 id="improved-documentation-">Improved Documentation üìö</h2>

<p>We continue to improve the documentation to make it easier to get started using DataFusion with
the <a href="https://datafusion.apache.org/library-user-guide/index.html">Library Users Guide</a>, <a href="https://docs.rs/datafusion/latest/datafusion/index.html">API documentation</a>, and <a href="https://github.com/apache/datafusion/tree/main/datafusion-examples">Examples</a>.</p>

<p>Some notable new examples include:</p>
<ul>
  <li><a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/sql_analysis.rs">sql_analysis.rs</a> to analyse SQL queries with DataFusion structures (thanks <a href="https://github.com/LorrensP-2158466">@LorrensP-2158466</a>)</li>
  <li><a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/function_factory.rs">function_factory.rs</a> to create custom functions via SQL (thanks <a href="https://github.com/milenkovicm">@milenkovicm</a>)</li>
  <li><a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/plan_to_sql.rs">plan_to_sql.rs</a> to generate SQL from DataFusion Expr and LogicalPlan (thanks <a href="https://github.com/edmondop">@edmondop</a>)</li>
  <li><a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/parquet_index.rs">parquet_index.rs</a> and <a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/advanced_parquet_index.rs">advanced_parquet_index.rs</a> for parquet indexing, described more below (thanks <a href="https://github.com/alamb">@alamb</a>)</li>
</ul>

<h2 id="new-features-">New Features ‚ú®</h2>

<p>There are too many new features in the last 6 months to list them all, but here
are some highlights:</p>

<h1 id="sql">SQL</h1>
<ul>
  <li>Support for <code class="language-plaintext highlighter-rouge">UNNEST</code> (thanks <a href="https://github.com/duongcongtoai">@duongcongtoai</a>, <a href="https://github.com/JasonLi-cn">@JasonLi-cn</a> and <a href="https://github.com/jayzhan211">@jayzhan211</a>)</li>
  <li>Support for <a href="https://github.com/apache/datafusion/issues/462">Recursive CTEs</a> (thanks <a href="https://github.com/jonahgao">@jonahgao</a> and <a href="https://github.com/matthewgapp">@matthewgapp</a>)</li>
  <li>Support for <code class="language-plaintext highlighter-rouge">CREATE FUNCTION</code> (see below)</li>
  <li>Many new SQL functions</li>
</ul>

<p>DataFusion now has much improved support for structured types such <code class="language-plaintext highlighter-rouge">STRUCT</code>,
<code class="language-plaintext highlighter-rouge">LIST</code>/<code class="language-plaintext highlighter-rouge">ARRAY</code> and <code class="language-plaintext highlighter-rouge">MAP</code>. For example, you can now create <code class="language-plaintext highlighter-rouge">STRUCT</code> literals 
in SQL like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="n">select</span> <span class="p">{</span><span class="nv">'foo</span><span class="err">'</span><span class="p">:</span> <span class="p">{</span><span class="nv">'bar</span><span class="err">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">}};</span>
<span class="o">+--------------------------------------------------------------+</span>
<span class="p">|</span> <span class="nf">named_struct</span><span class="p">(</span><span class="nf">Utf8</span><span class="p">(</span><span class="s">"foo"</span><span class="p">),</span><span class="nf">named_struct</span><span class="p">(</span><span class="nf">Utf8</span><span class="p">(</span><span class="s">"bar"</span><span class="p">),</span><span class="nf">Int64</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span> <span class="p">|</span>
<span class="o">+--------------------------------------------------------------+</span>
<span class="p">|</span> <span class="p">{</span><span class="n">foo</span><span class="p">:</span> <span class="p">{</span><span class="n">bar</span><span class="p">:</span> <span class="mi">2</span><span class="p">}}</span>                                              <span class="p">|</span>
<span class="o">+--------------------------------------------------------------+</span>
<span class="mi">1</span> <span class="nf">row</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="n">fetched</span><span class="py">.
Elapsed</span> <span class="mf">0.002</span> <span class="n">seconds</span><span class="err">.</span>
</code></pre></div></div>

<h1 id="sql-unparser-sql-formatter">SQL Unparser (SQL Formatter)</h1>

<p>DataFusion now supports converting <code class="language-plaintext highlighter-rouge">Expr</code>s and <code class="language-plaintext highlighter-rouge">LogicalPlan</code>s BACK to SQL text.
This can be useful in query federation to push predicates down into other
systems that only accept SQL, and for building systems that generate SQL.</p>

<p>For example, you can now convert a logical expression back to SQL text:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Form a logical expression that represents the SQL "a &lt; 5 OR a = 8"</span>
<span class="k">let</span> <span class="n">expr</span> <span class="o">=</span> <span class="nf">col</span><span class="p">(</span><span class="s">"a"</span><span class="p">)</span><span class="nf">.lt</span><span class="p">(</span><span class="nf">lit</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span><span class="nf">.or</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="s">"a"</span><span class="p">)</span><span class="nf">.eq</span><span class="p">(</span><span class="nf">lit</span><span class="p">(</span><span class="mi">8</span><span class="p">)));</span>
<span class="c1">// convert the expression back to SQL text</span>
<span class="k">let</span> <span class="n">sql</span> <span class="o">=</span> <span class="nf">expr_to_sql</span><span class="p">(</span><span class="o">&amp;</span><span class="n">expr</span><span class="p">)</span><span class="o">?</span><span class="nf">.to_string</span><span class="p">();</span>
<span class="nd">assert_eq!</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="s">"a &lt; 5 OR a = 8"</span><span class="p">);</span>
</code></pre></div></div>

<p>You can also do complex things like parsing SQL, modifying the plan, and convert
it back to SQL:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">df</span> <span class="o">=</span> <span class="n">ctx</span>
  <span class="c1">// Use SQL to read some data from the parquet file</span>
  <span class="nf">.sql</span><span class="p">(</span><span class="s">"SELECT int_col, double_col, CAST(date_string_col as VARCHAR) FROM alltypes_plain"</span><span class="p">)</span>
  <span class="k">.await</span><span class="o">?</span><span class="p">;</span>
<span class="c1">// Programmatically add new filters `id &gt; 1 and tinyint_col &lt; double_col`</span>
<span class="k">let</span> <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="nf">.filter</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="s">"id"</span><span class="p">)</span><span class="nf">.gt</span><span class="p">(</span><span class="nf">lit</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="nf">.and</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="s">"tinyint_col"</span><span class="p">)</span><span class="nf">.lt</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="s">"double_col"</span><span class="p">))))</span><span class="o">?</span>
<span class="c1">// Convert the new logical plan back to SQL</span>
<span class="k">let</span> <span class="n">sql</span> <span class="o">=</span> <span class="nf">plan_to_sql</span><span class="p">(</span><span class="n">df</span><span class="nf">.logical_plan</span><span class="p">())</span><span class="o">?</span><span class="nf">.to_string</span><span class="p">();</span>
<span class="nd">assert_eq!</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> 
           <span class="s">"SELECT alltypes_plain.int_col, alltypes_plain.double_col, CAST(alltypes_plain.date_string_col AS VARCHAR) </span><span class="err">\</span><span class="s">
           FROM alltypes_plain WHERE ((alltypes_plain.id &gt; 1) AND (alltypes_plain.tinyint_col &lt; alltypes_plain.double_col))"</span><span class="p">)</span>
<span class="p">);</span>
</code></pre></div></div>

<p>See the <a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/plan_to_sql.rs">Plan to SQL example</a> or the APIs <a href="https://docs.rs/datafusion/latest/datafusion/sql/unparser/fn.expr_to_sql.html">expr_to_sql</a> and <a href="https://docs.rs/datafusion/latest/datafusion/sql/unparser/fn.plan_to_sql.html">plan_to_sql</a> for more details.</p>

<h1 id="low-level-apis-for-fast-parquet-access-indexing">Low Level APIs for Fast Parquet Access (indexing)</h1>

<p>With their rising prevalence, supporting efficient access to Parquet files
stored remotely on object storage is important. Part of doing this efficiently
is minimizing the number of object store requests made by caching metadata and
skipping over parts of the file that are not needed (e.g. via an index).</p>

<p>DataFusion‚Äôs Parquet reader has long internally supported <a href="https://arrow.apache.org/blog/2022/12/26/querying-parquet-with-millisecond-latency/">advanced predicate
pushdown</a> by reading the parquet metadata from the file footer and pruning based
on row group and data page statistics. DataFusion now also supports users
supplying their own low level pruning information via the <a href="https://docs.rs/datafusion/latest/datafusion/datasource/physical_plan/parquet/struct.ParquetAccessPlan.html"><code class="language-plaintext highlighter-rouge">ParquetAccessPlan</code></a>
API.</p>

<p>This API can be used along with index information to selectively skip decoding
parts of the file. For example, Spice AI used this feature to add <a href="https://github.com/spiceai/spiceai/pull/1891">efficient
support</a> for reading from DeltaLake tables and handling <a href="https://docs.delta.io/latest/delta-deletion-vectors.html">deletion vectors</a>.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   If the RowSelection does not include any
        ‚îÇ          ...          ‚îÇ   rows from a particular Data Page, that
        ‚îÇ                       ‚îÇ   Data Page is not fetched or decoded.
        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   Note this requires a PageIndex
        ‚îÇ ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ ‚îÇ
Row     ‚îÇ ‚îÇ     ‚îÇDataPage 0‚îÇ  ‚îÇ ‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
Groups  ‚îÇ ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚îÇ                 ‚îÇ                    ‚îÇ
        ‚îÇ ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ ‚îÇ                 ‚îÇ    ParquetExec     ‚îÇ
        ‚îÇ ‚îÇ ... ‚îÇDataPage 1‚îÇ ‚óÄ‚îº ‚îº ‚îÄ ‚îÄ ‚îÄ           ‚îÇ  (Parquet Reader)  ‚îÇ
        ‚îÇ ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚îÇ      ‚îî ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ‚îÇ                    ‚îÇ
        ‚îÇ ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ ‚îÇ                 ‚îÇ ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó  ‚îÇ
        ‚îÇ ‚îÇ     ‚îÇDataPage 2‚îÇ  ‚îÇ ‚îÇ If only rows    ‚îÇ ‚ïëParquetMetadata‚ïë  ‚îÇ
        ‚îÇ ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚îÇ from DataPage 1 ‚îÇ ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚îÇ
        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ are selected,   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ only DataPage 1
        ‚îÇ          ...          ‚îÇ is fetched and
        ‚îÇ                       ‚îÇ decoded
        ‚îÇ ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó ‚îÇ
        ‚îÇ ‚ïë  Thrift metadata  ‚ïë ‚îÇ
        ‚îÇ ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         Parquet File
</code></pre></div></div>

<p>See the <a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/parquet_index.rs">parquet_index.rs</a> and <a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/advanced_parquet_index.rs">advanced_parquet_index.rs</a> examples for more details.</p>

<p>Thanks to <a href="https://github.com/alamb">@alamb</a> and <a href="https://github.com/Ted-Jiang">@Ted-Jiang</a> for this feature.</p>

<h2 id="building-systems-is-easier-with-datafusion-Ô∏è">Building Systems is Easier with DataFusion üõ†Ô∏è</h2>

<p>In addition to many incremental API improvements, there are several new APIs that make
it easier to build systems on top of DataFusion:</p>

<ul>
  <li>Faster and easier to use <a href="https://docs.rs/datafusion/latest/datafusion/common/tree_node/trait.TreeNode.html#overview">TreeNode API</a> for traversing and manipulating plans and expressions.</li>
  <li>All functions now use the same <a href="https://docs.rs/datafusion/latest/datafusion/logical_expr/trait.ScalarUDFImpl.html">Scalar User Defined Function API</a>, making it easier to customize
DataFusion‚Äôs behavior without sacrificing performance. See <a href="https://github.com/apache/arrow-datafusion/issues/8045">ticket</a> for more details.</li>
  <li>DataFusion can now be compiled to <a href="https://github.com/apache/datafusion/discussions/9834">WASM</a>.</li>
</ul>

<h1 id="user-defined-sql-parsing-extensions">User Defined SQL Parsing Extensions</h1>

<p>As of DataFusion 40.0.0, you can use the <a href="https://docs.rs/datafusion/latest/datafusion/logical_expr/planner/trait.ExprPlanner.html"><code class="language-plaintext highlighter-rouge">ExprPlanner</code></a> trait to extend
DataFusion‚Äôs SQL planner to support custom operators or syntax.</p>

<p>For example the <a href="https://github.com/datafusion-contrib/datafusion-functions-json">datafusion-functions-json</a> project uses this API to support
JSON operators in SQL queries. It provides a custom implementation for
planning JSON operators such as <code class="language-plaintext highlighter-rouge">-&gt;</code> and <code class="language-plaintext highlighter-rouge">-&gt;&gt;</code> with code like:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">MyCustomPlanner</span><span class="p">;</span>

<span class="k">impl</span> <span class="n">ExprPlanner</span> <span class="k">for</span> <span class="n">MyCustomPlanner</span> <span class="p">{</span>
    <span class="c1">// Provide custom implementation for planning a binary operators</span>
    <span class="c1">// such as `-&gt;` and `-&gt;&gt;`</span>
    <span class="k">fn</span> <span class="nf">plan_binary_op</span><span class="p">(</span>
        <span class="o">&amp;</span><span class="k">self</span><span class="p">,</span>
        <span class="n">expr</span><span class="p">:</span> <span class="n">RawBinaryExpr</span><span class="p">,</span>
        <span class="n">_schema</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">DFSchema</span><span class="p">,</span>
    <span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">PlannerResult</span><span class="o">&lt;</span><span class="n">RawBinaryExpr</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
        <span class="k">match</span> <span class="o">&amp;</span><span class="n">expr</span><span class="py">.op</span> <span class="p">{</span>
           <span class="nn">BinaryOperator</span><span class="p">::</span><span class="n">Arrow</span> <span class="k">=&gt;</span> <span class="p">{</span> <span class="cm">/* plan -&gt; operator */</span> <span class="p">}</span>
           <span class="nn">BinaryOperator</span><span class="p">::</span><span class="n">LongArrow</span> <span class="k">=&gt;</span> <span class="p">{</span> <span class="cm">/* plan -&gt;&gt; operator */</span> <span class="p">}</span>
           <span class="o">...</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Thanks to <a href="https://github.com/samuelcolvin">@samuelcolvin</a>, <a href="https://github.com/jayzhan211">@jayzhan211</a> and <a href="https://github.com/dharanad">@dharanad</a> for helping make this
feature happen.</p>

<h1 id="pluggable-support-for-create-function">Pluggable Support for <code class="language-plaintext highlighter-rouge">CREATE FUNCTION</code></h1>

<p>DataFusion‚Äôs new <a href="https://docs.rs/datafusion/latest/datafusion/execution/context/trait.FunctionFactory.html"><code class="language-plaintext highlighter-rouge">FunctionFactory</code></a> API let‚Äôs users provide a handler for
<code class="language-plaintext highlighter-rouge">CREATE FUNCTION</code> SQL statements. This feature lets you build systems that
support defining functions in SQL such as</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- SQL based functions</span>
<span class="k">CREATE</span> <span class="k">FUNCTION</span> <span class="n">my_func</span><span class="p">(</span><span class="nb">DOUBLE</span><span class="p">,</span> <span class="nb">DOUBLE</span><span class="p">)</span> <span class="k">RETURNS</span> <span class="nb">DOUBLE</span>
    <span class="k">RETURN</span> <span class="err">$</span><span class="mi">1</span> <span class="o">+</span> <span class="err">$</span><span class="mi">3</span>
<span class="p">;</span>

<span class="c1">-- ML Models</span>
<span class="k">CREATE</span> <span class="k">FUNCTION</span> <span class="n">iris</span><span class="p">(</span><span class="nb">FLOAT</span><span class="p">[])</span> <span class="k">RETURNS</span> <span class="nb">FLOAT</span><span class="p">[]</span> 
<span class="k">LANGUAGE</span> <span class="n">TORCH</span> <span class="k">AS</span> <span class="s1">'models:/iris@champion'</span><span class="p">;</span>

<span class="c1">-- WebAssembly</span>
<span class="k">CREATE</span> <span class="k">FUNCTION</span> <span class="n">func</span><span class="p">(</span><span class="nb">FLOAT</span><span class="p">[])</span> <span class="k">RETURNS</span> <span class="nb">FLOAT</span><span class="p">[]</span> 
<span class="k">LANGUAGE</span> <span class="n">WASM</span> <span class="k">AS</span> <span class="s1">'func.wasm'</span>
</code></pre></div></div>

<p>Huge thanks to <a href="https://github.com/milenkovicm">@milenkovicm</a> for this feature. There is an example of how to
make macro like functions in <a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/function_factory.rs">function_factory.rs</a>. It would be
great if <a href="https://github.com/apache/datafusion/issues/9326">someone made a demo</a> showing how to create WASMs üé£.</p>

<h2 id="looking-ahead-the-next-six-months-">Looking Ahead: The Next Six Months üî≠</h2>

<p>The community has been <a href="https://github.com/apache/datafusion/issues/11442">discussing what we will work on in the next six months</a>.
Some major initiatives from that discussion are:</p>

<ol>
  <li>
    <p><em>Performance</em>: Improve the speed of <a href="https://github.com/apache/arrow-datafusion/issues/7000">aggregating ‚Äúhigh cardinality‚Äù</a>
  data when there are many (e.g. millions) of distinct groups as well as additional
  ideas to improve parquet performance.</p>
  </li>
  <li>
    <p><em>Modularity</em>: Make DataFusion even more modular, by completely unifying
built in and user <a href="https://github.com/apache/datafusion/issues/8708">aggregate functions</a> and <a href="https://github.com/apache/datafusion/issues/8709">window functions</a>.</p>
  </li>
  <li>
    <p><em>LogicalTypes</em>: <a href="https://github.com/apache/datafusion/issues/11513">Introduce Logical Types</a> to make it easier to use
different encodings like <code class="language-plaintext highlighter-rouge">StringView</code>, <code class="language-plaintext highlighter-rouge">RunEnd</code> and <code class="language-plaintext highlighter-rouge">Dictionary</code> arrays as well
as user defined types. Thanks <a href="https://github.com/notfilippo">@notfilippo</a> for driving this.</p>
  </li>
  <li>
    <p><em>Improved Documentation</em>: Write blog posts and videos explaining
how to use DataFusion for real-world use cases.</p>
  </li>
  <li>
    <p><em>Testing</em>: Improve CI infrastructure and test coverage, more fuzz
testing, and better functional and performance regression testing.</p>
  </li>
</ol>

<h1 id="how-to-get-involved">How to Get Involved</h1>

<p>DataFusion is not a project built or driven by a single person, company, or
foundation. Rather, our community of users and contributors work together to
build a shared technology that none of us could have built alone.</p>

<p>If you are interested in joining us we would love to have you. You can try out
DataFusion on some of your own data and projects and let us know how it goes,
contribute suggestions, documentation, bug reports, or a PR with documentation,
tests or code. A list of open issues suitable for beginners is <a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">here</a> and you
can find how to reach us on the <a href="https://datafusion.apache.org/contributor-guide/communication.html">communication doc</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Apache DataFusion Comet 0.1.0 Release</title><link href="https://datafusion.apache.org/blog/2024/07/20/datafusion-comet-0.1.0/" rel="alternate" type="text/html" title="Apache DataFusion Comet 0.1.0 Release" /><published>2024-07-20T00:00:00+00:00</published><updated>2024-07-20T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2024/07/20/datafusion-comet-0.1.0</id><content type="html" xml:base="https://datafusion.apache.org/blog/2024/07/20/datafusion-comet-0.1.0/"><![CDATA[<!--

-->

<p>The Apache DataFusion PMC is pleased to announce the first official source release of the <a href="https://datafusion.apache.org/comet/">Comet</a> subproject.</p>

<p>Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.</p>

<p>Comet runs on commodity hardware and aims to provide 100% compatibility with Apache Spark. Any operators or
expressions that are not fully compatible will fall back to Spark unless explicitly enabled by the user. Refer
to the <a href="https://datafusion.apache.org/comet/user-guide/compatibility.html">compatibility guide</a> for more information.</p>

<p>This release covers five months of development work since the project was <a href="https://datafusion.apache.org/blog/2024/03/06/comet-donation/">donated</a> to the Apache DataFusion
project and is the result of merging 343 PRs from 41 contributors. See the <a href="https://github.com/apache/datafusion-comet/blob/main/dev/changelog/0.1.0.md">change log</a> for more information.</p>

<p>This first release supports 15 <a href="https://datafusion.apache.org/comet/user-guide/datatypes.html#">data types</a>, 13 <a href="https://datafusion.apache.org/comet/user-guide/operators.html#">operators</a>, and 106 <a href="https://datafusion.apache.org/comet/user-guide/expressions.html#">expressions</a>. Comet is compatible with Apache
Spark versions 3.3, 3.4, and 3.5. There is also experimental support for preview versions of Spark 4.0.</p>

<h2 id="project-status">Project Status</h2>

<p>The project‚Äôs recent focus has been on fixing correctness and stability issues and implementing additional
native operators and expressions so that a broader range of queries can be executed natively.</p>

<p>Here are some of the highlights since the project was donated:</p>

<ul>
  <li>Implemented native support for:
    <ul>
      <li>SortMergeJoin</li>
      <li>HashJoin</li>
      <li>BroadcastHashJoin</li>
      <li>Columnar Shuffle</li>
      <li>More aggregate expressions</li>
      <li>Window aggregates</li>
      <li>Many Spark-compatible CAST expressions</li>
    </ul>
  </li>
  <li>Implemented a simple Spark Fuzz Testing utility to find correctness issues</li>
  <li>Published a <a href="https://datafusion.apache.org/comet/user-guide/overview.html">User Guide</a> and <a href="https://datafusion.apache.org/comet/contributor-guide/contributing.html">Contributors Guide</a></li>
  <li>Created a <a href="https://github.com/apache/datafusion-benchmarks">DataFusion Benchmarks</a> repository with scripts and documentation for running benchmarks derived<br />
from TPC-H and TPC-DS with DataFusion and Comet</li>
</ul>

<h2 id="current-performance">Current Performance</h2>

<p>Comet already delivers a modest performance speedup for many queries, enabling faster data processing and
shorter time-to-insights.</p>

<p>We use benchmarks derived from the industry standard TPC-H and TPC-DS benchmarks for tracking progress with
performance. The following chart shows the time it takes to run the 22 TPC-H queries against 100 GB of data in
Parquet format using a single executor with eight cores. See the <a href="https://datafusion.apache.org/comet/contributor-guide/benchmarking.html">Comet Benchmarking Guide</a>
for details of the environment used for these benchmarks.</p>

<p><img src="/blog/img/comet-0.1.0/tpch_allqueries.png" width="100%" class="img-responsive" alt="Chart showing TPC-H benchmark results for Comet 0.1.0" /></p>

<p>Comet reduces the overall execution time from 626 seconds to 407 seconds, a 54% speedup (1.54x faster).</p>

<p>Running the same queries with DataFusion standalone using the same number of cores results in a 3.9x speedup
compared to Spark. Although this isn‚Äôt a fair comparison (DataFusion does not have shuffle or match Spark
semantics in some cases, for example), it does give some idea about the potential future performance of
Comet. Comet aims to provide a 2x-4x speedup for a wide range of queries once more operators and expressions
can run natively.</p>

<p>The following chart shows how much Comet currently accelerates each query from the benchmark.</p>

<p><img src="/blog/img/comet-0.1.0/tpch_queries_speedup.png" width="100%" class="img-responsive" alt="Chart showing TPC-H benchmark results for Comet 0.1.0" /></p>

<p>These benchmarks can be reproduced in any environment using the documentation in the <a href="https://datafusion.apache.org/comet/contributor-guide/benchmarking.html">Comet Benchmarking Guide</a>. We
encourage you to run these benchmarks in your environment or, even better, try Comet out with your existing Spark jobs.</p>

<h2 id="roadmap">Roadmap</h2>

<p>Comet is an open-source project, and contributors are welcome to work on any features they are interested in, but
here are some current focus areas.</p>

<ul>
  <li>Improve Performance &amp; Reliability:
    <ul>
      <li>Implement the remaining features needed so that all TPC-H queries can run entirely natively</li>
      <li>Implement spill support in SortMergeJoin</li>
      <li>Enable columnar shuffle by default</li>
    </ul>
  </li>
  <li>Fully support Spark version 4.0.0</li>
  <li>Support more Spark operators and expressions
    <ul>
      <li>We would like to support many more expressions natively in Comet, and this is a great place to start
contributing. The contributors‚Äô guide has a section covering <a href="https://datafusion.apache.org/comet/contributor-guide/adding_a_new_expression.html">adding support for new expressions</a>.</li>
    </ul>
  </li>
  <li>Move more Spark expressions into the <a href="https://crates.io/crates/datafusion-comet-spark-expr">datafusion-comet-spark-expr</a> crate. Although the main focus of the Comet
project is to provide an accelerator for Apache Spark, we also publish a standalone crate containing
Spark-compatible expressions that can be used by any project using DataFusion, without adding any dependencies
on JVM or Apache Spark.</li>
  <li>Release Process &amp; Documentation
    <ul>
      <li>Implement a binary release process so that we can publish JAR files to Maven for all supported platforms</li>
      <li>Add documentation for running Spark and Comet in Kubernetes, and add example Dockerfiles.</li>
    </ul>
  </li>
</ul>

<h2 id="getting-involved">Getting Involved</h2>

<p>The Comet project welcomes new contributors. We use the same <a href="https://datafusion.apache.org/contributor-guide/communication.html#slack-and-discord">Slack and Discord</a> channels as the main DataFusion
project, and there is a Comet community video call held every four weeks on Wednesdays at 11:30 a.m. Eastern Time,
which is 16:30 UTC during Eastern Standard Time and 15:30 UTC during Eastern Daylight Time. See the
<a href="https://docs.google.com/document/d/1NBpkIAuU7O9h8Br5CbFksDhX-L9TyO9wmGLPMe0Plc8/edit?usp=sharing">Comet Community Meeting</a> Google Document for the next scheduled meeting date, the video call link, and
recordings of previous calls.</p>

<p>The easiest way to get involved is to test Comet with your current Spark jobs and file issues for any bugs or
performance regressions that you find. See the <a href="https://datafusion.apache.org/comet/user-guide/installation.html">Getting Started</a> guide for instructions on downloading and installing
Comet.</p>

<p>There are also many <a href="https://github.com/apache/datafusion-comet/contribute">good first issues</a> waiting for contributions.</p>]]></content><author><name>pmc</name></author><category term="subprojects" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Announcing Apache Arrow DataFusion is now Apache DataFusion</title><link href="https://datafusion.apache.org/blog/2024/05/07/datafusion-tlp/" rel="alternate" type="text/html" title="Announcing Apache Arrow DataFusion is now Apache DataFusion" /><published>2024-05-07T00:00:00+00:00</published><updated>2024-05-07T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2024/05/07/datafusion-tlp</id><content type="html" xml:base="https://datafusion.apache.org/blog/2024/05/07/datafusion-tlp/"><![CDATA[<!--

-->

<h2 id="introduction">Introduction</h2>

<p>TLDR; <a href="https://arrow.apache.org/">Apache Arrow</a> DataFusion ‚Äì&gt; <a href="https://datafusion.apache.org/">Apache DataFusion</a></p>

<p>The Arrow PMC and newly created DataFusion PMC are happy to announce that as of
April 16, 2024 the Apache Arrow DataFusion subproject is now a top level
<a href="https://www.apache.org/">Apache Software Foundation</a> project.</p>

<h2 id="background">Background</h2>

<p>Apache DataFusion is a fast, extensible query engine for building high-quality
data-centric systems in Rust, using the Apache Arrow in-memory format.</p>

<p>When DataFusion was <a href="https://arrow.apache.org/blog/2019/02/04/datafusion-donation/">donated to the Apache Software Foundation</a> in 2019, the
DataFusion community was not large enough to stand on its own and the Arrow
project agreed to help support it. The community has grown significantly since
2019, benefiting immensely from being part of Arrow and following <a href="https://www.apache.org/theapacheway/">The Apache
Way</a>.</p>

<h2 id="why-now">Why now?</h2>

<p>The community <a href="https://github.com/apache/datafusion/discussions/6475">discussed graduating to a top level project publicly</a> for almost
a year, as the project seemed ready to stand on its own and would benefit from
more focused governance. For example, earlier in DataFusion‚Äôs life many
contributed to both <a href="https://github.com/apache/arrow-rs">arrow-rs</a> and DataFusion, but as DataFusion has matured many
contributors, committers and PMC members focused more and more exclusively on
DataFusion.</p>

<h2 id="looking-forward">Looking forward</h2>

<p>The future looks bright. There are now <a href="https://datafusion.apache.org/user-guide/introduction.html#known-users">10s of known projects built with
DataFusion</a>, and that number continues to grow. We recently held our <a href="https://github.com/apache/datafusion/discussions/8522">first in
person meetup</a> passed <a href="https://github.com/apache/datafusion/stargazers">5000 stars</a> on GitHub, <a href="https://github.com/apache/datafusion/issues/8373#issuecomment-2025133714">wrote a paper that was accepted
at SIGMOD 2024</a>, and began work on <a href="https://github.com/apache/datafusion-comet">Comet</a>, an <a href="https://spark.apache.org/">Apache Spark</a> accelerator
<a href="https://arrow.apache.org/blog/2024/03/06/comet-donation/">initially donated by Apple</a>.</p>

<p>Thank you to everyone in the Arrow community who helped DataFusion grow and
mature over the years, and we look forward to continuing our collaboration as
projects. All future blogs and announcements will be posted on the <a href="https://datafusion.apache.org/">Apache
DataFusion</a> website.</p>

<h2 id="get-involved">Get Involved</h2>

<p>If you are interested in joining the community, we would love to have you join
us. Get in touch using <a href="https://datafusion.apache.org/contributor-guide/communication.html">Communication Doc</a> and learn how to get involved in the
<a href="https://datafusion.apache.org/contributor-guide/index.html">Contributor Guide</a>. We welcome everyone to try DataFusion on their
own data and projects and let us know how it goes, contribute suggestions,
documentation, bug reports, or a PR with documentation, tests or code.</p>]]></content><author><name>pmc</name></author><category term="subprojects" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Announcing Apache Arrow DataFusion Comet</title><link href="https://datafusion.apache.org/blog/2024/03/06/comet-donation/" rel="alternate" type="text/html" title="Announcing Apache Arrow DataFusion Comet" /><published>2024-03-06T00:00:00+00:00</published><updated>2024-03-06T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2024/03/06/comet-donation</id><content type="html" xml:base="https://datafusion.apache.org/blog/2024/03/06/comet-donation/"><![CDATA[<!--

-->

<h1 id="introduction">Introduction</h1>
<p>The Apache Arrow PMC is pleased to announce the donation of the <a href="https://github.com/apache/arrow-datafusion-comet">Comet project</a>,
a native Spark SQL Accelerator built on <a href="https://arrow.apache.org/datafusion">Apache Arrow DataFusion</a>.</p>

<p>Comet is an Apache Spark plugin that uses Apache Arrow DataFusion to
accelerate Spark workloads. It is designed as a drop-in
replacement for Spark‚Äôs JVM based SQL execution engine and offers significant
performance improvements for some workloads as shown below.</p>

<figure style="text-align: center;">
  <img src="/blog/img/datafusion-comet/comet-architecture.png" width="100%" class="img-responsive" alt="Fig 1: Adaptive Arrow schema architecture overview." />
  <figcaption>
   <b>Figure 1</b>: With Comet, users interact with the same Spark ecosystem, tools
    and APIs such as Spark SQL. Queries still run through Spark's query optimizer and planner. 
    However, the execution is delegated to Comet,
    which is significantly faster and more resource efficient than a JVM based
    implementation.
</figcaption>
</figure>

<p>Comet is one of a growing class of projects that aim to accelerate Spark using
native columnar engines such as the proprietary <a href="https://www.databricks.com/product/photon">Databricks Photon Engine</a> and
open source projects <a href="https://incubator.apache.org/projects/gluten.html">Gluten</a>, <a href="https://github.com/NVIDIA/spark-rapids">Spark RAPIDS</a>, and <a href="https://github.com/kwai/blaze">Blaze</a> (also built using
DataFusion).</p>

<p>Comet was originally implemented at Apple and the engineers who worked on the
project are also significant contributors to Arrow and DataFusion. Bringing 
Comet into the Apache Software Foundation will accelerate its development and 
grow its community of contributors and users.</p>

<h1 id="get-involved">Get Involved</h1>
<p>Comet is still in the early stages of development and we would love to have you
join us and help shape the project. We are working on an initial release, and 
expect to post another update with more details at that time.</p>

<p>Before then, here are some ways to get involved:</p>

<ul>
  <li>
    <p>Learn more by visiting the <a href="https://github.com/apache/arrow-datafusion-comet">Comet project</a> page and reading the <a href="https://lists.apache.org/thread/0q1rb11jtpopc7vt1ffdzro0omblsh0s">mailing list
discussion</a> about the initial donation.</p>
  </li>
  <li>
    <p>Help us plan out the <a href="https://github.com/apache/arrow-datafusion-comet/issues/19">roadmap</a></p>
  </li>
  <li>
    <p>Try out the project and provide feedback, file issues, and contribute code.</p>
  </li>
</ul>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Apache Arrow DataFusion 34.0.0 Released, Looking Forward to 2024</title><link href="https://datafusion.apache.org/blog/2024/01/19/datafusion-34.0.0/" rel="alternate" type="text/html" title="Apache Arrow DataFusion 34.0.0 Released, Looking Forward to 2024" /><published>2024-01-19T00:00:00+00:00</published><updated>2024-01-19T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2024/01/19/datafusion-34.0.0</id><content type="html" xml:base="https://datafusion.apache.org/blog/2024/01/19/datafusion-34.0.0/"><![CDATA[<!--

-->

<h2 id="introduction">Introduction</h2>

<p>We recently <a href="https://crates.io/crates/datafusion/34.0.0">released DataFusion 34.0.0</a>. This blog highlights some of the major
improvements since we <a href="https://arrow.apache.org/blog/2023/06/24/datafusion-25.0.0/.">released DataFusion 26.0.0</a> (spoiler alert there are many)
and a preview of where the community plans to focus in the next 6 months.</p>

<p><a href="https://arrow.apache.org/datafusion/">Apache Arrow DataFusion</a> is an extensible query engine, written in <a href="https://www.rust-lang.org/">Rust</a>, that
uses <a href="https://arrow.apache.org">Apache Arrow</a> as its in-memory format. DataFusion is used by developers to
create new, fast data centric systems such as databases, dataframe libraries,
machine learning and streaming applications. While <a href="https://arrow.apache.org/datafusion/user-guide/introduction.html#project-goals">DataFusion‚Äôs primary design
goal</a> is to accelerate creating other data centric systems, it has a
reasonable experience directly out of the box as a <a href="https://arrow.apache.org/datafusion-python/">dataframe library</a> and
<a href="https://arrow.apache.org/datafusion/user-guide/cli.html">command line SQL tool</a>.</p>

<p>This may also be our last update on the Apache Arrow Site. Future
updates will likely be on the DataFusion website as we are working to <a href="https://github.com/apache/arrow-datafusion/discussions/6475">graduate
to a top level project</a> (Apache Arrow DataFusion ‚Üí Apache DataFusion!) which
will help focus governance and project growth. Also exciting, our <a href="https://github.com/apache/arrow-datafusion/discussions/8522">first
DataFusion in person meetup</a> is planned for March 2024.</p>

<p>DataFusion is very much a community endeavor. Our core thesis is that as a
community we can build much more advanced technology than any of us as
individuals or companies could alone. In the last 6 months between <code class="language-plaintext highlighter-rouge">26.0.0</code> and
<code class="language-plaintext highlighter-rouge">34.0.0</code>, community growth has been strong. We accepted and reviewed over a
thousand PRs from 124 different committers, created over 650 issues and closed 517
of them.
You can find a list of all changes in the detailed <a href="https://github.com/apache/arrow-datafusion/blob/main/datafusion/CHANGELOG.md">CHANGELOG</a>.</p>

<!--
$ git log --pretty=oneline 26.0.0..34.0.0 . | wc -l
     1009

$ git shortlog -sn 26.0.0..34.0.0 . | wc -l
      124

https://crates.io/crates/datafusion/26.0.0
DataFusion 26 released June 7, 2023

https://crates.io/crates/datafusion/34.0.0
DataFusion 34 released Dec 17, 2023

Issues created in this time: 214 open, 437 closed
https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+created%3A2023-06-23..2023-12-17

Issues closes: 517
https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+closed%3A2023-06-23..2023-12-17+

PRs merged in this time 908
https://github.com/apache/arrow-datafusion/pulls?q=is%3Apr+merged%3A2023-06-23..2023-12-17
-->

<h1 id="improved-performance-">Improved Performance üöÄ</h1>

<p>Performance is a key feature of DataFusion, DataFusion is 
more than 2x faster on <a href="https://benchmark.clickhouse.com/">ClickBench</a> compared to version <code class="language-plaintext highlighter-rouge">25.0.0</code>, as shown below:</p>

<!--
  Scripts: https://github.com/alamb/datafusion-duckdb-benchmark/tree/datafusion-25-34
  Spreadsheet: https://docs.google.com/spreadsheets/d/1FtI3652WIJMC5LmJbLfT3G06w0JQIxEPG4yfMafexh8/edit#gid=1879366976
  Average runtime on 25.0.0: 7.2s (for the queries that actually ran)
  Average runtime on 34.0.0: 3.6s (for the same queries that ran in 25.0.0)
-->

<figure style="text-align: center;">
  <img src="/blog/img/datafusion-34.0.0/compare-new.png" width="100%" class="img-responsive" alt="Fig 1: Adaptive Arrow schema architecture overview." />
  <figcaption>
    <b>Figure 1</b>: Performance improvement between <code>25.0.0</code> and <code>34.0.0</code> on ClickBench. 
    Note that DataFusion <code>25.0.0</code>, could not run several queries due to 
    unsupported SQL (Q9, Q11, Q12, Q14) or memory requirements (Q33).
  </figcaption>
</figure>

<figure style="text-align: center;">
  <img src="/blog/img/datafusion-34.0.0/compare.png" width="100%" class="img-responsive" alt="Fig 1: Adaptive Arrow schema architecture overview." />
  <figcaption>
    <b>Figure 2</b>: Total query runtime for DataFusion <code>34.0.0</code> and DataFusion <code>25.0.0</code>.
  </figcaption>
</figure>

<p>Here are some specific enhancements we have made to improve performance:</p>
<ul>
  <li><a href="https://arrow.apache.org/blog/2023/08/05/datafusion_fast_grouping/">2-3x better aggregation performance with many distinct groups</a></li>
  <li>Partially ordered grouping / streaming grouping</li>
  <li><a href="https://github.com/apache/arrow-datafusion/pull/7721">Specialized operator for ‚ÄúTopK‚Äù <code class="language-plaintext highlighter-rouge">ORDER BY LIMIT XXX</code></a></li>
  <li><a href="https://github.com/apache/arrow-datafusion/pull/7192">Specialized operator for <code class="language-plaintext highlighter-rouge">min(col) GROUP BY .. ORDER by min(col) LIMIT XXX</code></a></li>
  <li><a href="https://github.com/apache/arrow-datafusion/pull/8126">Improved join performance</a></li>
  <li>Eliminate redundant sorting with sort order aware optimizers</li>
</ul>

<h1 id="new-features-">New Features ‚ú®</h1>

<h2 id="dml--insert--creating-files">DML / Insert / Creating Files</h2>

<p>DataFusion now supports writing data in parallel, to individual or multiple
files, using <code class="language-plaintext highlighter-rouge">Parquet</code>, <code class="language-plaintext highlighter-rouge">CSV</code>, <code class="language-plaintext highlighter-rouge">JSON</code>, <code class="language-plaintext highlighter-rouge">ARROW</code> and user defined formats.
<a href="https://github.com/apache/arrow-datafusion/pull/7655">Benchmark results</a> show improvements up to 5x in some cases.</p>

<p>Similarly to reading, data can now be written to any <a href="https://docs.rs/object_store/0.9.0/object_store/index.html"><code class="language-plaintext highlighter-rouge">ObjectStore</code></a>
implementation, including AWS S3, Azure Blob Storage, GCP Cloud Storage, local
files, and user defined implementations. While reading from <a href="https://docs.rs/datafusion/latest/datafusion/datasource/listing/struct.ListingTable.html#features">hive style
partitioned tables</a> has long been supported, it is now possible to write to such
tables as well.</p>

<p>For example, to write to a local file:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">‚ùØ</span> <span class="k">CREATE</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">awesome_table</span><span class="p">(</span><span class="n">x</span> <span class="nb">INT</span><span class="p">)</span> <span class="n">STORED</span> <span class="k">AS</span> <span class="n">PARQUET</span> <span class="k">LOCATION</span> <span class="s1">'/tmp/my_awesome_table'</span><span class="p">;</span>
<span class="mi">0</span> <span class="k">rows</span> <span class="k">in</span> <span class="k">set</span><span class="p">.</span> <span class="n">Query</span> <span class="n">took</span> <span class="mi">0</span><span class="p">.</span><span class="mi">003</span> <span class="n">seconds</span><span class="p">.</span>

<span class="err">‚ùØ</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">awesome_table</span> <span class="k">SELECT</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">10</span> <span class="k">FROM</span> <span class="n">my_source_table</span><span class="p">;</span>
<span class="o">+</span><span class="c1">-------+</span>
<span class="o">|</span> <span class="k">count</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">-------+</span>
<span class="o">|</span> <span class="mi">3</span>     <span class="o">|</span>
<span class="o">+</span><span class="c1">-------+</span>
<span class="mi">1</span> <span class="k">row</span> <span class="k">in</span> <span class="k">set</span><span class="p">.</span> <span class="n">Query</span> <span class="n">took</span> <span class="mi">0</span><span class="p">.</span><span class="mi">024</span> <span class="n">seconds</span><span class="p">.</span>
</code></pre></div></div>

<p>You can also write to files with the <a href="https://arrow.apache.org/datafusion/user-guide/sql/dml.html#copy"><code class="language-plaintext highlighter-rouge">COPY</code></a>, similarly to <a href="https://duckdb.org/docs/sql/statements/copy.html">DuckDB‚Äôs <code class="language-plaintext highlighter-rouge">COPY</code></a>:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">‚ùØ</span> <span class="k">COPY</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">FROM</span> <span class="n">my_source_table</span><span class="p">)</span> <span class="k">TO</span> <span class="s1">'/tmp/output.json'</span><span class="p">;</span>
<span class="o">+</span><span class="c1">-------+</span>
<span class="o">|</span> <span class="k">count</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">-------+</span>
<span class="o">|</span> <span class="mi">3</span>     <span class="o">|</span>
<span class="o">+</span><span class="c1">-------+</span>
<span class="mi">1</span> <span class="k">row</span> <span class="k">in</span> <span class="k">set</span><span class="p">.</span> <span class="n">Query</span> <span class="n">took</span> <span class="mi">0</span><span class="p">.</span><span class="mi">014</span> <span class="n">seconds</span><span class="p">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> /tmp/output.json
<span class="o">{</span><span class="s2">"x"</span>:1<span class="o">}</span>
<span class="o">{</span><span class="s2">"x"</span>:2<span class="o">}</span>
<span class="o">{</span><span class="s2">"x"</span>:3<span class="o">}</span>
</code></pre></div></div>

<h2 id="improved-struct-and-array-support">Improved <code class="language-plaintext highlighter-rouge">STRUCT</code> and <code class="language-plaintext highlighter-rouge">ARRAY</code> support</h2>

<p>DataFusion <code class="language-plaintext highlighter-rouge">34.0.0</code> has much improved <code class="language-plaintext highlighter-rouge">STRUCT</code> and <code class="language-plaintext highlighter-rouge">ARRAY</code>
support, including a full range of <a href="https://arrow.apache.org/datafusion/user-guide/sql/scalar_functions.html#struct-functions">struct functions</a> and <a href="https://arrow.apache.org/datafusion/user-guide/sql/scalar_functions.html#array-functions">array functions</a>.</p>

<!--
‚ùØ create table my_table as values ([1,2,3]), ([2]), ([4,5]);
-->

<p>For example, you can now use <code class="language-plaintext highlighter-rouge">[]</code> syntax and <code class="language-plaintext highlighter-rouge">array_length</code> to access and inspect arrays:</p>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">‚ùØ</span> <span class="k">SELECT</span> <span class="n">column1</span><span class="p">,</span> 
         <span class="n">column1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">AS</span> <span class="n">first_element</span><span class="p">,</span> 
         <span class="n">array_length</span><span class="p">(</span><span class="n">column1</span><span class="p">)</span> <span class="k">AS</span> <span class="n">len</span> 
  <span class="k">FROM</span> <span class="n">my_table</span><span class="p">;</span>
<span class="o">+</span><span class="c1">-----------+---------------+-----+</span>
<span class="o">|</span> <span class="n">column1</span>   <span class="o">|</span> <span class="n">first_element</span> <span class="o">|</span> <span class="n">len</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">-----------+---------------+-----+</span>
<span class="o">|</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">|</span> <span class="mi">1</span>             <span class="o">|</span> <span class="mi">3</span>   <span class="o">|</span>
<span class="o">|</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span>       <span class="o">|</span> <span class="mi">2</span>             <span class="o">|</span> <span class="mi">1</span>   <span class="o">|</span>
<span class="o">|</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>    <span class="o">|</span> <span class="mi">4</span>             <span class="o">|</span> <span class="mi">2</span>   <span class="o">|</span>
<span class="o">+</span><span class="c1">-----------+---------------+-----+</span>
</code></pre></div></div>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">‚ùØ</span> <span class="k">SELECT</span> <span class="n">column1</span><span class="p">,</span> <span class="n">column1</span><span class="p">[</span><span class="s1">'c0'</span><span class="p">]</span> <span class="k">FROM</span>  <span class="n">my_table</span><span class="p">;</span>
<span class="o">+</span><span class="c1">------------------+----------------------+</span>
<span class="o">|</span> <span class="n">column1</span>          <span class="o">|</span> <span class="n">my_table</span><span class="p">.</span><span class="n">column1</span><span class="p">[</span><span class="n">c0</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">------------------+----------------------+</span>
<span class="o">|</span> <span class="p">{</span><span class="n">c0</span><span class="p">:</span> <span class="n">foo</span><span class="p">,</span> <span class="n">c1</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span> <span class="o">|</span> <span class="n">foo</span>                  <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">c0</span><span class="p">:</span> <span class="n">bar</span><span class="p">,</span> <span class="n">c1</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span> <span class="o">|</span> <span class="n">bar</span>                  <span class="o">|</span>
<span class="o">+</span><span class="c1">------------------+----------------------+</span>
<span class="mi">2</span> <span class="k">rows</span> <span class="k">in</span> <span class="k">set</span><span class="p">.</span> <span class="n">Query</span> <span class="n">took</span> <span class="mi">0</span><span class="p">.</span><span class="mi">002</span> <span class="n">seconds</span><span class="p">.</span>
</code></pre></div></div>

<h2 id="other-features">Other Features</h2>
<p>Other notable features include:</p>
<ul>
  <li>Support aggregating datasets that exceed memory size, with <a href="https://github.com/apache/arrow-datafusion/pull/7400">group by spill to disk</a></li>
  <li>All operators now track and limit their memory consumption, including Joins</li>
</ul>

<h1 id="building-systems-is-easier-with-datafusion-Ô∏è">Building Systems is Easier with DataFusion üõ†Ô∏è</h1>

<h2 id="documentation">Documentation</h2>
<p>It is easier than ever to get started using DataFusion with the
new <a href="https://arrow.apache.org/datafusion/library-user-guide/index.html">Library Users Guide</a> as well as significantly improved the <a href="https://docs.rs/datafusion/latest/datafusion/index.html">API documentation</a>.</p>

<h2 id="user-defined-window-and-table-functions">User Defined Window and Table Functions</h2>
<p>In addition to DataFusion‚Äôs <a href="https://arrow.apache.org/datafusion/library-user-guide/adding-udfs.html#adding-a-scalar-udf">User Defined Scalar Functions</a>, and <a href="https://arrow.apache.org/datafusion/library-user-guide/adding-udfs.html#adding-an-aggregate-udf">User Defined Aggregate Functions</a>, DataFusion now supports <a href="https://arrow.apache.org/datafusion/library-user-guide/adding-udfs.html#adding-a-window-udf">User Defined Window Functions</a> 
 and <a href="https://arrow.apache.org/datafusion/library-user-guide/adding-udfs.html#adding-a-user-defined-table-function">User Defined Table Functions</a>.</p>

<p>For example, <a href="https://arrow.apache.org/datafusion/user-guide/cli.html">the <code class="language-plaintext highlighter-rouge">datafusion-cli</code></a> implements a DuckDB style <a href="https://arrow.apache.org/datafusion/user-guide/cli.html#supported-sql"><code class="language-plaintext highlighter-rouge">parquet_metadata</code></a>
function as a user defined table function (<a href="https://github.com/apache/arrow-datafusion/blob/3f219bc929cfd418b0e3d3501f8eba1d5a2c87ae/datafusion-cli/src/functions.rs#L222-L248">source code here</a>):</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">‚ùØ</span> <span class="k">SELECT</span> 
      <span class="n">path_in_schema</span><span class="p">,</span> <span class="n">row_group_id</span><span class="p">,</span> <span class="n">row_group_num_rows</span><span class="p">,</span> <span class="n">stats_min</span><span class="p">,</span> <span class="n">stats_max</span><span class="p">,</span> <span class="n">total_compressed_size</span> 
<span class="k">FROM</span> 
      <span class="n">parquet_metadata</span><span class="p">(</span><span class="s1">'hits.parquet'</span><span class="p">)</span>
<span class="k">WHERE</span> <span class="n">path_in_schema</span> <span class="o">=</span> <span class="s1">'"WatchID"'</span> 
<span class="k">LIMIT</span> <span class="mi">3</span><span class="p">;</span>

<span class="o">+</span><span class="c1">----------------+--------------+--------------------+---------------------+---------------------+-----------------------+</span>
<span class="o">|</span> <span class="n">path_in_schema</span> <span class="o">|</span> <span class="n">row_group_id</span> <span class="o">|</span> <span class="n">row_group_num_rows</span> <span class="o">|</span> <span class="n">stats_min</span>           <span class="o">|</span> <span class="n">stats_max</span>           <span class="o">|</span> <span class="n">total_compressed_size</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">----------------+--------------+--------------------+---------------------+---------------------+-----------------------+</span>
<span class="o">|</span> <span class="nv">"WatchID"</span>      <span class="o">|</span> <span class="mi">0</span>            <span class="o">|</span> <span class="mi">450560</span>             <span class="o">|</span> <span class="mi">4611687214012840539</span> <span class="o">|</span> <span class="mi">9223369186199968220</span> <span class="o">|</span> <span class="mi">3883759</span>               <span class="o">|</span>
<span class="o">|</span> <span class="nv">"WatchID"</span>      <span class="o">|</span> <span class="mi">1</span>            <span class="o">|</span> <span class="mi">612174</span>             <span class="o">|</span> <span class="mi">4611689135232456464</span> <span class="o">|</span> <span class="mi">9223371478009085789</span> <span class="o">|</span> <span class="mi">5176803</span>               <span class="o">|</span>
<span class="o">|</span> <span class="nv">"WatchID"</span>      <span class="o">|</span> <span class="mi">2</span>            <span class="o">|</span> <span class="mi">344064</span>             <span class="o">|</span> <span class="mi">4611692774829951781</span> <span class="o">|</span> <span class="mi">9223363791697310021</span> <span class="o">|</span> <span class="mi">3031680</span>               <span class="o">|</span>
<span class="o">+</span><span class="c1">----------------+--------------+--------------------+---------------------+---------------------+-----------------------+</span>
<span class="mi">3</span> <span class="k">rows</span> <span class="k">in</span> <span class="k">set</span><span class="p">.</span> <span class="n">Query</span> <span class="n">took</span> <span class="mi">0</span><span class="p">.</span><span class="mi">053</span> <span class="n">seconds</span><span class="p">.</span>
</code></pre></div></div>

<h3 id="growth-of-datafusion-">Growth of DataFusion üìà</h3>
<p>DataFusion has been appearing more publically in the wild. For example</p>
<ul>
  <li>New projects built using DataFusion such as <a href="https://lancedb.com/">lancedb</a>, <a href="https://glaredb.com/">GlareDB</a>, <a href="https://www.arroyo.dev/">Arroyo</a>, and <a href="https://github.com/cmu-db/optd">optd</a>.</li>
  <li>Public talks such as <a href="https://www.youtube.com/watch?v=AJU9rdRNk9I">Apache Arrow Datafusion: Vectorized
Execution Framework For Maximum Performance</a> in <a href="https://www.bagevent.com/event/8432178">CommunityOverCode Asia 2023</a></li>
  <li>Blogs posts such as <a href="https://www.synnada.ai/blog/apache-arrow-arrow-datafusion-ai-native-data-infra-an-interview-with-our-ceo-ozan">Apache Arrow, Arrow/DataFusion, AI-native Data Infra</a>,
<a href="https://www.influxdata.com/blog/flight-datafusion-arrow-parquet-fdap-architecture-influxdb/">Flight, DataFusion, Arrow, and Parquet: Using the FDAP Architecture to build InfluxDB 3.0</a>, and 
<a href="https://www.linkedin.com/pulse/guide-user-defined-functions-apache-arrow-datafusion-dade-aderemi/">A Guide to User-Defined Functions in Apache Arrow DataFusion</a></li>
</ul>

<p>We have also <a href="https://github.com/apache/arrow-datafusion/issues/6782">submitted a paper</a> to <a href="https://2024.sigmod.org/">SIGMOD 2024</a>, one of the
premiere database conferences, describing DataFusion in a technically formal
style and making the case that it is possible to create a modular and extensive query engine 
without sacrificing performance. We hope this paper helps people 
evaluating DataFusion for their needs understand it better.</p>

<h1 id="datafusion-in-2024-">DataFusion in 2024 ü•≥</h1>

<p>Some major initiatives from contributors we know of this year are:</p>

<ol>
  <li>
    <p><em>Modularity</em>: Make DataFusion even more modular, such as <a href="https://github.com/apache/arrow-datafusion/issues/8045">unifying
built in and user functions</a>, making it easier to customize 
DataFusion‚Äôs behavior.</p>
  </li>
  <li>
    <p><em>Community Growth</em>: Graduate to our own top level Apache project, and
subsequently add more committers and PMC members to keep pace with project
growth.</p>
  </li>
  <li>
    <p><em>Use case white papers</em>: Write blog posts and videos explaining
how to use DataFusion for real-world use cases.</p>
  </li>
  <li>
    <p><em>Testing</em>: Improve CI infrastructure and test coverage, more fuzz
testing, and better functional and performance regression testing.</p>
  </li>
  <li>
    <p><em>Planning Time</em>: Reduce the time taken to plan queries, both <a href="https://github.com/apache/arrow-datafusion/issues/7698">wide
tables of 1000s of columns</a>, and in <a href="https://github.com/apache/arrow-datafusion/issues/5637">general</a>.</p>
  </li>
  <li>
    <p><em>Aggregate Performance</em>: Improve the speed of <a href="https://github.com/apache/arrow-datafusion/issues/7000">aggregating ‚Äúhigh cardinality‚Äù</a> data
when there are many (e.g. millions) of distinct groups.</p>
  </li>
  <li>
    <p><em>Statistics</em>: <a href="https://github.com/apache/arrow-datafusion/issues/8227">Improved statistics handling</a> with an eye towards more
sophisticated expression analysis and cost models.</p>
  </li>
</ol>

<h1 id="how-to-get-involved">How to Get Involved</h1>

<p>If you are interested in contributing to DataFusion we would love to have you
join us. You can try out DataFusion on some of your own data and projects and
let us know how it goes, contribute suggestions, documentation, bug reports, or
a PR with documentation, tests or code. A list of open issues
suitable for beginners is <a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">here</a>.</p>

<p>As the community grows, we are also looking to restart biweekly calls /
meetings. Timezones are always a challenge for such meetings, but we hope to
have two calls that can work for most attendees. If you are interested
in helping, or just want to say hi, please drop us a note via one of 
the methods listed in our <a href="https://arrow.apache.org/datafusion/contributor-guide/communication.html">Communication Doc</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Aggregating Millions of Groups Fast in Apache Arrow DataFusion 28.0.0</title><link href="https://datafusion.apache.org/blog/2023/08/05/datafusion_fast_grouping/" rel="alternate" type="text/html" title="Aggregating Millions of Groups Fast in Apache Arrow DataFusion 28.0.0" /><published>2023-08-05T00:00:00+00:00</published><updated>2023-08-05T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2023/08/05/datafusion_fast_grouping</id><content type="html" xml:base="https://datafusion.apache.org/blog/2023/08/05/datafusion_fast_grouping/"><![CDATA[<!--

-->

<!-- Converted from Google Docs using https://www.buymeacoffee.com/docstomarkdown -->

<h2 id="aggregating-millions-of-groups-fast-in-apache-arrow-datafusion">Aggregating Millions of Groups Fast in Apache Arrow DataFusion</h2>

<p>Andrew Lamb, Dani√´l Heres, Raphael Taylor-Davies,</p>

<p><em>Note: this article was originally published on the <a href="https://www.influxdata.com/blog/aggregating-millions-groups-fast-apache-arrow-datafusion">InfluxData Blog</a></em></p>

<h2 id="tldr">TLDR</h2>

<p>Grouped aggregations are a core part of any analytic tool, creating understandable summaries of huge data volumes. <a href="https://arrow.apache.org/datafusion/">Apache Arrow DataFusion</a>‚Äôs parallel aggregation capability is 2-3x faster in the <a href="https://crates.io/crates/datafusion/28.0.0">newly released version <code class="language-plaintext highlighter-rouge">28.0.0</code></a> for queries with a large number (10,000 or more) of groups.</p>

<p>Improving aggregation performance matters to all users of DataFusion. For example, both InfluxDB, a <a href="https://github.com/influxdata/influxdb">time series data platform</a> and Coralogix, a <a href="https://coralogix.com/?utm_source=InfluxDB&amp;utm_medium=Blog&amp;utm_campaign=organic">full-stack observability</a> platform, aggregate vast amounts of raw data to monitor and create insights for our customers. Improving DataFusion‚Äôs performance lets us provide better user experiences by generating insights faster with fewer resources. Because DataFusion is open source and released under the permissive <a href="https://github.com/apache/arrow-datafusion/blob/main/LICENSE.txt">Apache 2.0</a> license, the whole DataFusion community benefits as well.</p>

<p>With the new optimizations, DataFusion‚Äôs grouping speed is now close to DuckDB, a system that regularly reports <a href="https://duckdblabs.github.io/db-benchmark/">great</a> <a href="https://duckdb.org/2022/03/07/aggregate-hashtable.html#experiments">grouping</a> benchmark performance numbers. Figure 1 contains a representative sample of <a href="https://github.com/ClickHouse/ClickBench/tree/main">ClickBench</a> on a single Parquet file, and the full results are at the end of this article.</p>

<p><img src="/blog/assets/datafusion_fast_grouping/summary.png" width="700" /></p>

<p><strong>Figure 1</strong>: Query performance for ClickBench queries on queries 16, 17, 18 and 19 on a single Parquet file for DataFusion <code class="language-plaintext highlighter-rouge">27.0.0</code>, DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code> and DuckDB <code class="language-plaintext highlighter-rouge">0.8.1</code>.</p>

<h2 id="introduction-to-high-cardinality-grouping">Introduction to high cardinality grouping</h2>

<p>Aggregation is a fancy word for computing summary statistics across many rows that have the same value in one or more columns. We call the rows with the same values <em>groups</em> and ‚Äúhigh cardinality‚Äù means there are a large number of distinct groups in the dataset. At the time of writing, a ‚Äúlarge‚Äù number of groups in analytic engines is around 10,000.</p>

<p>For example the <a href="https://github.com/ClickHouse/ClickBench">ClickBench</a> <em>hits</em> dataset contains 100 million anonymized user clicks across a set of websites. ClickBench Query 17 is:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="nv">"UserID"</span><span class="p">,</span> <span class="nv">"SearchPhrase"</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">hits</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="nv">"UserID"</span><span class="p">,</span> <span class="nv">"SearchPhrase"</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>
<span class="k">DESC</span> <span class="k">LIMIT</span> <span class="mi">10</span><span class="p">;</span>
</code></pre></div></div>

<p>In English, this query finds ‚Äúthe top ten (user, search phrase) combinations, across all clicks‚Äù and produces the following results (there are no search phrases for the top ten users):</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+---------------------+--------------+-----------------+
| UserID              | SearchPhrase | COUNT(UInt8(1)) |
+---------------------+--------------+-----------------+
| 1313338681122956954 |              | 29097           |
| 1907779576417363396 |              | 25333           |
| 2305303682471783379 |              | 10597           |
| 7982623143712728547 |              | 6669            |
| 7280399273658728997 |              | 6408            |
| 1090981537032625727 |              | 6196            |
| 5730251990344211405 |              | 6019            |
| 6018350421959114808 |              | 5990            |
| 835157184735512989  |              | 5209            |
| 770542365400669095  |              | 4906            |
+---------------------+--------------+-----------------+
</code></pre></div></div>

<p>The ClickBench dataset contains</p>

<ul>
  <li>99,997,497 total rows<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></li>
  <li>17,630,976 different users (distinct UserIDs)<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></li>
  <li>6,019,103 different search phrases<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup></li>
  <li>24,070,560 distinct combinations<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup> of (UserID, SearchPhrase)
Thus, to answer the query, DataFusion must map each of the 100M different input rows into one of the <strong>24 million different groups</strong>, and keep count of how many such rows there are in each group.</li>
</ul>

<h2 id="the-solution">The solution</h2>

<p>Like most concepts in databases and other analytic systems, the basic ideas of this algorithm are straightforward and taught in introductory computer science courses. You could compute the query with a program such as this<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="n">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>

<span class="c1"># read file
</span><span class="n">hits</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_parquet</span><span class="p">(</span><span class="sh">'</span><span class="s">hits.parquet</span><span class="sh">'</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="sh">'</span><span class="s">pyarrow</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># build groups
</span><span class="n">counts</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">hits</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">group</span> <span class="o">=</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">UserID</span><span class="sh">'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">SearchPhrase</span><span class="sh">'</span><span class="p">]);</span>
    <span class="c1"># update the dict entry for the corresponding key
</span>    <span class="n">counts</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Print the top 10 values
</span><span class="nf">print </span><span class="p">(</span><span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">counts</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="nf">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</code></pre></div></div>

<p>This approach, while simple, is both slow and very memory inefficient. It requires over 40 seconds to compute the results for less than 1% of the dataset<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">6</a></sup>. Both DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code> and DuckDB <code class="language-plaintext highlighter-rouge">0.8.1</code> compute results in under 10 seconds for the <em>entire</em> dataset.</p>

<p>To answer this query quickly and efficiently, you have to write your code such that it:</p>

<ol>
  <li>Keeps all cores busy aggregating via parallelized computation</li>
  <li>Updates aggregate values quickly, using vectorizable loops that are easy for compilers to translate into the high performance <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a> instructions available in modern CPUs.</li>
</ol>

<p>The rest of this article explains how grouping works in DataFusion and the improvements we made in <code class="language-plaintext highlighter-rouge">28.0.0</code>.</p>

<h3 id="two-phase-parallel-partitioned-grouping">Two phase parallel partitioned grouping</h3>

<p>Both DataFusion <code class="language-plaintext highlighter-rouge">27.0.</code> and <code class="language-plaintext highlighter-rouge">28.0.0</code> use state-of-the-art, two phase parallel hash partitioned grouping, similar to other high-performance vectorized engines like <a href="https://duckdb.org/2022/03/07/aggregate-hashtable.html">DuckDB‚Äôs Parallel Grouped Aggregates</a>. In pictures this looks like:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            ‚ñ≤                        ‚ñ≤
            ‚îÇ                        ‚îÇ
            ‚îÇ                        ‚îÇ
            ‚îÇ                        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        GroupBy        ‚îÇ  ‚îÇ      GroupBy      ‚îÇ      Step 4
‚îÇ        (Final)        ‚îÇ  ‚îÇ      (Final)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚ñ≤                        ‚ñ≤
            ‚îÇ                        ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ       Repartition       ‚îÇ               Step 3
            ‚îÇ         HASH(x)         ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñ≤
                         ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ                       ‚îÇ
            ‚îÇ                       ‚îÇ
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ      GroupyBy      ‚îÇ  ‚îÇ       GroupBy       ‚îÇ      Step 2
 ‚îÇ     (Partial)      ‚îÇ  ‚îÇ      (Partial)      ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚ñ≤                       ‚ñ≤
         ‚îå‚îÄ‚îÄ‚îò                       ‚îî‚îÄ‚îê
         ‚îÇ                            ‚îÇ
    .‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ.                  .‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ.
 ,‚îÄ'           '‚îÄ.            ,‚îÄ'           '‚îÄ.
;      Input      :          ;      Input      :      Step 1
:    Stream 1     ;          :    Stream 2     ;
 ‚ï≤               ‚ï±            ‚ï≤               ‚ï±
  '‚îÄ.         ,‚îÄ'              '‚îÄ.         ,‚îÄ'
     `‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ'                    `‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ'
</code></pre></div></div>

<p><strong>Figure 2</strong>: Two phase repartitioned grouping: data flows from bottom (source) to top (results) in two phases. First (Steps 1 and 2), each core reads the data into a core-specific hash table, computing intermediate aggregates without any cross-core coordination. Then (Steps 3 and 4) DataFusion divides the data (‚Äúrepartitions‚Äù) into distinct subsets by group value, and each subset is sent to a specific core which computes the final aggregate.</p>

<p>The two phases are critical for keeping cores busy in a multi-core system. Both phases use the same hash table approach (explained in the next section), but differ in how the groups are distributed and the partial results emitted from the accumulators. The first phase aggregates data as soon as possible after it is produced. However, as shown in Figure 2, the groups can be anywhere in any input, so the same group is often found on many different cores. The second phase uses a hash function to redistribute data evenly across the cores, so each group value is processed by exactly one core which emits the final results for that group.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  1  ‚îÇ    ‚îÇ  3  ‚îÇ
    ‚îÇ  2  ‚îÇ    ‚îÇ  4  ‚îÇ   2. After Repartitioning: each
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   group key  appears in exactly
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   one partition
    ‚îÇ  1  ‚îÇ    ‚îÇ  3  ‚îÇ
    ‚îÇ  2  ‚îÇ    ‚îÇ  4  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ

    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  2  ‚îÇ    ‚îÇ  2  ‚îÇ
    ‚îÇ  1  ‚îÇ    ‚îÇ  2  ‚îÇ
    ‚îÇ  3  ‚îÇ    ‚îÇ  3  ‚îÇ
    ‚îÇ  4  ‚îÇ    ‚îÇ  1  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    1. Input Stream: groups
      ...        ...      values are spread
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    arbitrarily over each input
    ‚îÇ  1  ‚îÇ    ‚îÇ  4  ‚îÇ
    ‚îÇ  4  ‚îÇ    ‚îÇ  3  ‚îÇ
    ‚îÇ  1  ‚îÇ    ‚îÇ  1  ‚îÇ
    ‚îÇ  4  ‚îÇ    ‚îÇ  3  ‚îÇ
    ‚îÇ  3  ‚îÇ    ‚îÇ  2  ‚îÇ
    ‚îÇ  2  ‚îÇ    ‚îÇ  2  ‚îÇ
    ‚îÇ  2  ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    Core A      Core B

</code></pre></div></div>

<p><strong>Figure 3</strong>: Group value distribution across 2 cores during aggregation phases. In the first phase, every group value <code class="language-plaintext highlighter-rouge">1</code>, <code class="language-plaintext highlighter-rouge">2</code>, <code class="language-plaintext highlighter-rouge">3</code>, <code class="language-plaintext highlighter-rouge">4</code>, is present in the input stream processed by each core. In the second phase, after repartitioning, the group values <code class="language-plaintext highlighter-rouge">1</code> and <code class="language-plaintext highlighter-rouge">2</code> are processed by core A, and values <code class="language-plaintext highlighter-rouge">3</code> and <code class="language-plaintext highlighter-rouge">4</code> are processed only by core B.</p>

<p>There are some additional subtleties in the <a href="https://github.com/apache/arrow-datafusion/blob/main/datafusion/core/src/physical_plan/aggregates/row_hash.rs">DataFusion implementation</a> not mentioned above due to space constraints, such as:</p>

<ol>
  <li>The policy of when to emit data from the first phase‚Äôs hash table (e.g. because the data is partially sorted)</li>
  <li>Handling specific filters per aggregate (due to the <code class="language-plaintext highlighter-rouge">FILTER</code> SQL clause)</li>
  <li>Data types of intermediate values (which may not be the same as the final output for some aggregates such as <code class="language-plaintext highlighter-rouge">AVG</code>).</li>
  <li>Action taken when memory use exceeds its budget.</li>
</ol>

<h3 id="hash-grouping">Hash grouping</h3>

<p>DataFusion queries can compute many different aggregate functions for each group, both <a href="https://arrow.apache.org/datafusion/user-guide/sql/aggregate_functions.html">built in</a> and/or user defined <a href="https://docs.rs/datafusion/latest/datafusion/logical_expr/struct.AggregateUDF.html"><code class="language-plaintext highlighter-rouge">AggregateUDFs</code></a>. The state for each aggregate function, called an <em>accumulator</em>, is tracked with a hash table (DataFusion uses the excellent <a href="https://docs.rs/hashbrown/latest/hashbrown/index.html">HashBrown</a> <a href="https://docs.rs/hashbrown/latest/hashbrown/raw/struct.RawTable.html">RawTable API</a>), which logically stores the ‚Äúindex‚Äù  identifying the specific group value.</p>

<h3 id="hash-grouping-in-2700">Hash grouping in <code class="language-plaintext highlighter-rouge">27.0.0</code></h3>

<p>As shown in Figure 3, DataFusion <code class="language-plaintext highlighter-rouge">27.0.0</code> stores the data in a <a href="https://github.com/apache/arrow-datafusion/blob/4d93b6a3802151865b68967bdc4c7d7ef425b49a/datafusion/core/src/physical_plan/aggregates/utils.rs#L38-L50"><code class="language-plaintext highlighter-rouge">GroupState</code></a> structure which, unsurprisingly, tracks the state for each group. The state for each group consists of:</p>

<ol>
  <li>The actual value of the group columns, in <a href="https://docs.rs/arrow-row/latest/arrow_row/index.html">Arrow Row</a> format.</li>
  <li>In-progress accumulations (e.g. the running counts for the <code class="language-plaintext highlighter-rouge">COUNT</code> aggregate) for each group, in one of two possible formats (<a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/expr/src/accumulator.rs#L24-L49"><code class="language-plaintext highlighter-rouge">Accumulator</code></a>  or <a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/physical-expr/src/aggregate/row_accumulator.rs#L26-L46"><code class="language-plaintext highlighter-rouge">RowAccumulator</code></a>).</li>
  <li>Scratch space for tracking which rows match each aggregate in each batch.</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ                                      ‚îÇ
                           ‚îÇ                  ...                 ‚îÇ
                           ‚îÇ ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì ‚îÇ
                           ‚îÇ ‚îÉ                                  ‚îÉ ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ ‚îÉ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÉ ‚îÇ
    ‚îÇ         ‚îÇ            ‚îÇ ‚îÉ ‚îÇgroup values: OwnedRow        ‚îÇ ‚îÉ ‚îÇ
    ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ            ‚îÇ ‚îÉ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÉ ‚îÇ
    ‚îÇ ‚îÇ  5  ‚îÇ ‚îÇ            ‚îÇ ‚îÉ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÉ ‚îÇ
    ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ            ‚îÇ ‚îÉ ‚îÇRow accumulator:              ‚îÇ ‚îÉ ‚îÇ
    ‚îÇ ‚îÇ  9  ‚îÇ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ ‚îÉ ‚îÇVec&lt;u8&gt;                       ‚îÇ ‚îÉ ‚îÇ
    ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ    ‚îÇ       ‚îÇ ‚îÉ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÉ ‚îÇ
    ‚îÇ ‚îÇ ... ‚îÇ ‚îÇ    ‚îÇ       ‚îÇ ‚îÉ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÉ ‚îÇ
    ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ    ‚îÇ       ‚îÇ ‚îÉ ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ         ‚îÉ ‚îÇ
    ‚îÇ ‚îÇ  1  ‚îÇ ‚îÇ    ‚îÇ       ‚îÇ ‚îÉ ‚îÇ‚îÇAccumulator 1 ‚îÇ      ‚îÇ         ‚îÉ ‚îÇ
    ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ    ‚îÇ       ‚îÇ ‚îÉ ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ         ‚îÉ ‚îÇ
    ‚îÇ ‚îÇ ... ‚îÇ ‚îÇ    ‚îÇ       ‚îÇ ‚îÉ ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ         ‚îÉ ‚îÇ
    ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ    ‚îÇ       ‚îÇ ‚îÉ ‚îÇ‚îÇAccumulator 2 ‚îÇ      ‚îÇ         ‚îÉ ‚îÇ
    ‚îÇ         ‚îÇ    ‚îÇ       ‚îÇ ‚îÉ ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ         ‚îÉ ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ       ‚îÇ ‚îÉ ‚îÇ Box&lt;dyn Accumulator&gt; ‚îÇ         ‚îÉ ‚îÇ
    Hash Table     ‚îÇ       ‚îÇ ‚îÉ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÉ ‚îÇ
                   ‚îÇ       ‚îÇ ‚îÉ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÉ ‚îÇ
                   ‚îÇ       ‚îÇ ‚îÉ ‚îÇscratch indices: Vec&lt;u32&gt;‚îÇ      ‚îÉ ‚îÇ
                   ‚îÇ       ‚îÇ ‚îÉ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÉ ‚îÇ
                   ‚îÇ       ‚îÇ ‚îÉ GroupState                       ‚îÉ ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ ‚îÇ
                           ‚îÇ                                      ‚îÇ
  Hash table tracks an     ‚îÇ                 ...                  ‚îÇ
  index into group_states  ‚îÇ                                      ‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           group_states: Vec&lt;GroupState&gt;

                           There is one GroupState PER GROUP

</code></pre></div></div>

<p><strong>Figure 4</strong>: Hash group operator structure in DataFusion <code class="language-plaintext highlighter-rouge">27.0.0</code>. A hash table maps each group to a GroupState which contains all the per-group states.</p>

<p>To compute the aggregate, DataFusion performs the following steps for each input batch:</p>

<ol>
  <li>Calculate hash using <a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/physical-expr/src/hash_utils.rs#L264-L307">efficient vectorized code</a>, specialized for each data type.</li>
  <li>Determine group indexes for each input row using the hash table (creating new entries for newly seen groups).</li>
  <li><a href="https://github.com/apache/arrow-datafusion/blob/4ab8be57dee3bfa72dd105fbd7b8901b873a4878/datafusion/core/src/physical_plan/aggregates/row_hash.rs#L562-L602">Update Accumulators for each group that had input rows,</a> assembling the rows into a contiguous range for vectorized accumulator if there are a sufficient number of them.</li>
</ol>

<p>DataFusion also stores the hash values in the table to avoid potentially costly hash recomputation when resizing the hash table.</p>

<p>This scheme works very well for a relatively small number of distinct groups: all accumulators are efficiently updated with large contiguous batches of rows.</p>

<p>However, this scheme is not ideal for high cardinality grouping due to:</p>

<ol>
  <li><strong>Multiple allocations per group</strong> for the group value row format, as well as for the <code class="language-plaintext highlighter-rouge">RowAccumulator</code>s and each  <code class="language-plaintext highlighter-rouge">Accumulator</code>. The <code class="language-plaintext highlighter-rouge">Accumulator</code> may have additional allocations within it as well.</li>
  <li><strong>Non-vectorized updates:</strong> Accumulator updates often fall back to a slower non-vectorized form because the number of distinct groups is large (and thus number of values per group is small) in each input batch.</li>
</ol>

<h3 id="hash-grouping-in-2800">Hash grouping in <code class="language-plaintext highlighter-rouge">28.0.0</code></h3>

<p>For <code class="language-plaintext highlighter-rouge">28.0.0</code>, we rewrote the core group by implementation following traditional system optimization principles: fewer allocations, type specialization, and aggressive vectorization.</p>

<p>DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code> uses the same RawTable and still stores group indexes. The major differences, as shown in Figure 4, are:</p>

<ol>
  <li>Group values are stored either
    <ol>
      <li>Inline in the <code class="language-plaintext highlighter-rouge">RawTable</code> (for single columns of primitive types), where the conversion to Row format costs more than its benefit</li>
      <li>In a separate <a href="https://docs.rs/arrow-row/latest/arrow_row/struct.Row.html">Rows</a> structure with a single contiguous allocation for all groups values, rather than an allocation per group. Accumulators manage the state for all the groups internally, so the code to update intermediate values is a tight type specialized loop. The new <a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/physical-expr/src/aggregate/groups_accumulator/mod.rs#L66-L75"><code class="language-plaintext highlighter-rouge">GroupsAccumulator</code></a> interface results in highly efficient type accumulator update loops.</li>
    </ol>
  </li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚îå ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ     ‚îÇ ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì ‚îÇ
‚îÇ                ‚îÇ                 ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÉ ‚îÇ
‚îÇ ‚îÇ           ‚îÇ  ‚îÇ ‚îå ‚îÄ ‚îÄ ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÉ ‚îÇ
‚îÇ                ‚îÇ    X   ‚îÇ  5  ‚îÇ  ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îÇ‚îÇ  value1   ‚îÇ ‚îÇ ‚îÉ ‚îÇ
‚îÇ ‚îÇ           ‚îÇ  ‚îÇ ‚îú ‚îÄ ‚îÄ ‚î§‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÉ ‚îÇ
‚îÇ                ‚îÇ    Q   ‚îÇ  9  ‚îÇ‚îÄ‚îÄ‚îº‚îº‚îÄ‚îÄ‚îê  ‚îÇ ‚îÉ  ‚îÇ     ...      ‚îÇ ‚îÉ ‚îÇ
‚îÇ ‚îÇ           ‚îÇ  ‚îÇ ‚îú ‚îÄ ‚îÄ ‚î§‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ‚îÇ  ‚îî‚îÄ‚îÄ‚îº‚îÄ‚ïã‚îÄ‚ñ∂‚îÇ              ‚îÇ ‚îÉ ‚îÇ
‚îÇ                ‚îÇ   ...  ‚îÇ ... ‚îÇ  ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÉ ‚îÇ
‚îÇ ‚îÇ           ‚îÇ  ‚îÇ ‚îú ‚îÄ ‚îÄ ‚î§‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îÇ‚îÇ  valueN   ‚îÇ ‚îÇ ‚îÉ ‚îÇ
‚îÇ                ‚îÇ    H   ‚îÇ  1  ‚îÇ  ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÉ ‚îÇ
‚îÇ ‚îÇ           ‚îÇ  ‚îÇ ‚îú ‚îÄ ‚îÄ ‚î§‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îÇvalues: Vec&lt;T&gt;‚îÇ ‚îÉ ‚îÇ
‚îÇ     Rows       ‚îÇ   ...  ‚îÇ ... ‚îÇ  ‚îÇ‚îÇ     ‚îÇ ‚îÉ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÉ ‚îÇ
‚îÇ ‚îÇ           ‚îÇ  ‚îÇ ‚îî ‚îÄ ‚îÄ ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ‚îÇ     ‚îÇ ‚îÉ                   ‚îÉ ‚îÇ
‚îÇ  ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ   ‚îÇ                 ‚îÇ‚îÇ     ‚îÇ ‚îÉ GroupsAccumulator ‚îÉ ‚îÇ
‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ     ‚îÇ ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ ‚îÇ
‚îÇ                  Hash Table       ‚îÇ     ‚îÇ                       ‚îÇ
‚îÇ                                   ‚îÇ     ‚îÇ          ...          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  GroupState                               Accumulators


Hash table value stores group_indexes     One  GroupsAccumulator
and group values.                         per aggregate. Each
                                          stores the state for
Group values are stored either inline     *ALL* groups, typically
in the hash table or in a single          using a native Vec&lt;T&gt;
allocation using the arrow Row format
</code></pre></div></div>

<p><strong>Figure 5</strong>: Hash group operator structure in DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code>. Group values are stored either directly in the hash table, or in a single allocation using the arrow Row format. The hash table contains group indexes. A single <code class="language-plaintext highlighter-rouge">GroupsAccumulator</code> stores the per-aggregate state for <em>all</em> groups.</p>

<p>This new structure improves performance significantly for high cardinality groups due to:</p>

<ol>
  <li><strong>Reduced allocations</strong>: There are no longer any individual allocations per group.</li>
  <li><strong>Contiguous native accumulator states</strong>: Type-specialized accumulators store the values for all groups in a single contiguous allocation using a <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html">Rust Vec&lt;T&gt;</a> of some native type.</li>
  <li><strong>Vectorized state update</strong>: The inner aggregate update loops, which are type-specialized and in terms of native <code class="language-plaintext highlighter-rouge">Vec</code>s, are well-vectorized by the Rust compiler (thanks <a href="https://llvm.org/">LLVM</a>!).</li>
</ol>

<h3 id="notes">Notes</h3>

<p>Some vectorized grouping implementations store the accumulator state row-wise directly in the hash table, which often uses modern CPU caches efficiently. Managing accumulator state in columnar fashion may sacrifice some cache locality, however it ensures the size of the hash table remains small, even when there are large numbers of groups and aggregates, making it easier for the compiler to vectorize the accumulator update.</p>

<p>Depending on the cost of recomputing hash values, DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code> may or may not store the hash values in the table. This optimizes the tradeoff between the cost of computing the hash value (which is expensive for strings, for example) vs. the cost of storing it in the hash table.</p>

<p>One subtlety that arises from pushing state updates into GroupsAccumulators is that each accumulator must handle similar variations with/without filtering and with/without nulls in the input. DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code> uses a templated <a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/physical-expr/src/aggregate/groups_accumulator/accumulate.rs#L28-L54"><code class="language-plaintext highlighter-rouge">NullState</code></a> which encapsulates these common patterns across accumulators.</p>

<p>The code structure is heavily influenced by the fact DataFusion is implemented using <a href="https://www.rust-lang.org/">Rust</a>, a new(ish) systems programming language focused on speed and safety. Rust heavily discourages many of the traditional pointer casting ‚Äútricks‚Äù used in C/C++ hash grouping implementations. The DataFusion aggregation code is almost entirely <a href="https://doc.rust-lang.org/nomicon/meet-safe-and-unsafe.html#:~:text=Safe%20Rust%20is%20the%20true,Undefined%20Behavior%20(a.k.a.%20UB)."><code class="language-plaintext highlighter-rouge">safe</code></a>, deviating into <code class="language-plaintext highlighter-rouge">unsafe</code> only when necessary. (Rust is a great choice because it makes DataFusion fast, easy to embed, and prevents many crashes and security issues often associated with multi-threaded C/C++ code).</p>

<h2 id="clickbench-results">ClickBench results</h2>

<p>The full results of running the <a href="https://github.com/ClickHouse/ClickBench/tree/main">ClickBench</a> queries against the single Parquet file with DataFusion <code class="language-plaintext highlighter-rouge">27.0.0</code>, DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code>, and DuckDB <code class="language-plaintext highlighter-rouge">0.8.1</code> are below. These numbers were run on a GCP <code class="language-plaintext highlighter-rouge">e2-standard-8 machine</code> with 8 cores and 32 GB of RAM, using the scripts <a href="https://github.com/alamb/datafusion-duckdb-benchmark">here</a>.</p>

<p>As the industry moves towards data systems assembled from components, it is increasingly important that they exchange data using open standards such as <a href="https://arrow.apache.org/">Apache Arrow</a> and <a href="https://parquet.apache.org/">Parquet</a> rather than custom storage and in-memory formats. Thus, this benchmark uses a single input Parquet file representative of many DataFusion users and aligned with the current trend in analytics of avoiding a costly load/transformation into a custom storage format prior to query.</p>

<p>DataFusion now reaches near-DuckDB-speeds querying Parquet data. While we don‚Äôt plan to engage in a benchmarking shootout with a team that literally wrote <a href="https://dl.acm.org/doi/abs/10.1145/3209950.3209955">Fair Benchmarking Considered Difficult</a>, hopefully everyone can agree that DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code> is a significant improvement.</p>

<p><img src="/blog/assets/datafusion_fast_grouping/full.png" width="700" /></p>

<p><strong>Figure 6</strong>: Performance of DataFusion <code class="language-plaintext highlighter-rouge">27.0.0</code>, DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code>, and DuckDB <code class="language-plaintext highlighter-rouge">0.8.1</code> on all 43 ClickBench queries against a single <code class="language-plaintext highlighter-rouge">hits.parquet</code> file. Lower is better.</p>

<h3 id="notes-1">Notes</h3>

<p>DataFusion <code class="language-plaintext highlighter-rouge">27.0.0</code> was not able to run several queries due to either planner bugs (Q9, Q11, Q12, 14) or running out of memory (Q33). DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code> solves those issues.</p>

<p>DataFusion is faster than DuckDB for query 21 and 22, likely due to optimized implementations of string pattern matching.</p>

<h2 id="conclusion-performance-matters">Conclusion: performance matters</h2>

<p>Improving aggregation performance by more than a factor of two allows developers building products and projects with DataFusion to spend more time on value-added domain specific features. We believe building systems with DataFusion is much faster than trying to build something similar from scratch. DataFusion increases productivity because it eliminates the need to rebuild well-understood, but costly to implement, analytic database technology. While we‚Äôre pleased with the improvements in DataFusion <code class="language-plaintext highlighter-rouge">28.0.0</code>, we are by no means done and are pursuing <a href="https://github.com/apache/arrow-datafusion/issues/7000">(Even More) Aggregation Performance</a>. The future for performance is bright.</p>

<h2 id="acknowledgments">Acknowledgments</h2>

<p>DataFusion is a <a href="https://arrow.apache.org/datafusion/contributor-guide/communication.html">community effort</a> and this work was not possible without contributions from many in the community. A special shout out to <a href="https://github.com/sunchao">sunchao</a>, <a href="https://github.com/jyshen">yjshen</a>, <a href="https://github.com/yahoNanJing">yahoNanJing</a>, <a href="https://github.com/mingmwang">mingmwang</a>, <a href="https://github.com/ozankabak">ozankabak</a>, <a href="https://github.com/mustafasrepo">mustafasrepo</a>, and everyone else who contributed ideas, reviews, and encouragement <a href="https://github.com/apache/arrow-datafusion/pull/6800">during</a> this <a href="https://github.com/apache/arrow-datafusion/pull/6904">work</a>.</p>

<h2 id="about-datafusion">About DataFusion</h2>

<p><a href="https://arrow.apache.org/datafusion/">Apache Arrow DataFusion</a> is an extensible query engine and database toolkit, written in <a href="https://www.rust-lang.org/">Rust</a>, that uses <a href="https://arrow.apache.org/">Apache Arrow</a> as its in-memory format. DataFusion, along with <a href="https://calcite.apache.org/">Apache Calcite</a>, Facebook‚Äôs <a href="https://github.com/facebookincubator/velox">Velox</a>, and similar technology are part of the next generation ‚Äú<a href="https://www.usenix.org/publications/login/winter2018/khurana">Deconstructed Database</a>‚Äù architectures, where new systems are built on a foundation of fast, modular components, rather than as a single tightly integrated system.</p>

<!-- Footnotes themselves at the bottom. -->
<h2 id="notes-2">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p><code class="language-plaintext highlighter-rouge">SELECT COUNT(*) FROM 'hits.parquet';</code>¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><code class="language-plaintext highlighter-rouge">SELECT COUNT(DISTINCT "UserID") as num_users FROM 'hits.parquet';</code>¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p><code class="language-plaintext highlighter-rouge">SELECT COUNT(DISTINCT "SearchPhrase") as num_phrases FROM 'hits.parquet';</code>¬†<a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p><code class="language-plaintext highlighter-rouge">SELECT COUNT(*) FROM (SELECT DISTINCT "UserID", "SearchPhrase" FROM 'hits.parquet')</code>¬†<a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Full script at <a href="https://github.com/alamb/datafusion-duckdb-benchmark/blob/main/hash.py">hash.py</a>¬†<a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p><a href="https://datasets.clickhouse.com/hits_compatible/athena_partitioned/hits_%7B%7D.parquet">hits_0.parquet</a>, one of the files from the partitioned ClickBench dataset, which has <code class="language-plaintext highlighter-rouge">100,000</code> rows and is 117 MB in size. The entire dataset has <code class="language-plaintext highlighter-rouge">100,000,000</code> rows in a single 14 GB Parquet file. The script did not complete on the entire dataset after 40 minutes, and used 212 GB RAM at peak.¬†<a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>alamb, Dandandan, tustvold</name></author><category term="release" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Apache Arrow DataFusion 26.0.0</title><link href="https://datafusion.apache.org/blog/2023/06/24/datafusion-25.0.0/" rel="alternate" type="text/html" title="Apache Arrow DataFusion 26.0.0" /><published>2023-06-24T00:00:00+00:00</published><updated>2023-06-24T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2023/06/24/datafusion-25.0.0</id><content type="html" xml:base="https://datafusion.apache.org/blog/2023/06/24/datafusion-25.0.0/"><![CDATA[<!--

-->

<p>It has been a whirlwind 6 months of DataFusion development since <a href="https://arrow.apache.org/blog/2023/01/19/datafusion-16.0.0">our
last update</a>: the community has grown, many features have been added,
performance improved and we are <a href="https://github.com/apache/arrow-datafusion/discussions/6475">discussing</a> branching out to our own
top level Apache Project.</p>

<h2 id="background">Background</h2>

<p><a href="https://arrow.apache.org/datafusion/">Apache Arrow DataFusion</a> is an extensible query engine and database
toolkit, written in <a href="https://www.rust-lang.org/">Rust</a>, that uses <a href="https://arrow.apache.org">Apache Arrow</a> as its in-memory
format.</p>

<p>DataFusion, along with <a href="https://calcite.apache.org">Apache Calcite</a>, Facebook‚Äôs <a href="https://github.com/facebookincubator/velox">Velox</a> and
similar technology are part of the next generation ‚Äú<a href="https://www.usenix.org/publications/login/winter2018/khurana">Deconstructed
Database</a>‚Äù architectures, where new systems are built on a foundation
of fast, modular components, rather as a single tightly integrated
system.</p>

<p>While single tightly integrated systems such as <a href="https://spark.apache.org/">Spark</a>, <a href="https://duckdb.org">DuckDB</a> and
<a href="https://www.pola.rs/">Pola.rs</a> are great pieces of technology, our community believes that
anyone developing new data heavy application, such as those common in
machine learning in the next 5 years, will <strong>require</strong> a high
performance, vectorized, query engine to remain relevant. The only
practical way to gain access to such technology without investing many
millions of dollars to build a new tightly integrated engine, is
though open source projects like DataFusion and similar enabling
technologies such as <a href="https://arrow.apache.org">Apache Arrow</a> and <a href="https://www.rust-lang.org/">Rust</a>.</p>

<p>DataFusion is targeted primarily at developers creating other data
intensive analytics, and offers:</p>

<ul>
  <li>High performance, native, parallel streaming execution engine</li>
  <li>Mature <a href="https://arrow.apache.org/datafusion/user-guide/sql/index.html">SQL support</a>, featuring  subqueries, window functions, grouping sets, and more</li>
  <li>Built in support for Parquet, Avro, CSV, JSON and Arrow formats and easy extension for others</li>
  <li>Native DataFrame API and <a href="https://arrow.apache.org/datafusion-python/">python bindings</a></li>
  <li><a href="https://docs.rs/datafusion/latest/datafusion/index.html">Well documented</a> source code and architecture, designed to be customized to suit downstream project needs</li>
  <li>High quality, easy to use code <a href="https://crates.io/crates/datafusion/versions">released every 2 weeks to crates.io</a></li>
  <li>Welcoming, open community, governed by the highly regarded and well understood <a href="https://www.apache.org/">Apache Software Foundation</a></li>
</ul>

<p>The rest of this post highlights some of the improvements we have made
to DataFusion over the last 6 months and a preview of where we are
heading. You can see a list of all changes in the detailed
<a href="https://github.com/apache/arrow-datafusion/blob/main/datafusion/CHANGELOG.md">CHANGELOG</a>.</p>

<h2 id="even-better-performance">(Even) Better Performance</h2>

<p><a href="https://voltrondata.com/resources/speeds-and-feeds-hardware-and-software-matter">Various</a> benchmarks show DataFusion to be quite close or <a href="https://github.com/tustvold/access-log-bench">even
faster</a> to the state of the art in analytic performance (at the moment
this seems to be DuckDB). We continually work on improving performance
(see <a href="https://github.com/apache/arrow-datafusion/issues/5546">#5546</a> for a list) and would love additional help in this area.</p>

<p>DataFusion now reads single large Parquet files significantly faster by
<a href="https://github.com/apache/arrow-datafusion/pull/5057">parallelizing across multiple cores</a>. Native speeds for reading JSON
and CSV files are also up to 2.5x faster thanks to improvements
upstream in arrow-rs <a href="https://github.com/apache/arrow-rs/pull/3479#issuecomment-1384353159">JSON reader</a> and <a href="https://github.com/apache/arrow-rs/pull/3365">CSV reader</a>.</p>

<p>Also, we have integrated the <a href="https://arrow.apache.org/blog/2022/11/07/multi-column-sorts-in-arrow-rust-part-1/">arrow-rs Row Format</a> into DataFusion resulting in up to <a href="https://github.com/apache/arrow-datafusion/pull/6163">2-3x faster sorting and merging</a>.</p>

<h2 id="improved-documentation-and-website">Improved Documentation and Website</h2>

<p>Part of growing the DataFusion community is ensuring that DataFusion‚Äôs
features are understood and that it is easy to contribute and
participate. To that end the <a href="https://arrow.apache.org/datafusion/">website</a> has been cleaned up, <a href="https://docs.rs/datafusion/latest/datafusion/index.html#architecture">the
architecture guide</a> expanded, the <a href="https://arrow.apache.org/datafusion/contributor-guide/roadmap.html">roadmap</a> updated, and several
overview talks created:</p>

<ul>
  <li>Apr 2023 <em>Query Engine</em>: <a href="https://youtu.be/NVKujPxwSBA">recording</a> and <a href="https://docs.google.com/presentation/d/1D3GDVas-8y0sA4c8EOgdCvEjVND4s2E7I6zfs67Y4j8/edit#slide=id.p">slides</a></li>
  <li>April 2023 <em>Logical Plan and Expressions</em>: <a href="https://youtu.be/EzZTLiSJnhY">recording</a> and <a href="https://docs.google.com/presentation/d/1ypylM3-w60kVDW7Q6S99AHzvlBgciTdjsAfqNP85K30">slides</a></li>
  <li>April 2023 <em>Physical Plan and Execution</em>: <a href="https://youtu.be/2jkWU3_w6z0">recording</a> and <a href="https://docs.google.com/presentation/d/1cA2WQJ2qg6tx6y4Wf8FH2WVSm9JQ5UgmBWATHdik0hg">slides</a></li>
</ul>

<h2 id="new-features">New Features</h2>

<h3 id="more-streaming-less-memory">More Streaming, Less Memory</h3>

<p>We have made significant progress on the <a href="https://github.com/apache/arrow-datafusion/issues/4285">streaming execution roadmap</a>
such as <a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/trait.ExecutionPlan.html#method.unbounded_output">unbounded datasources</a>, <a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/aggregates/enum.GroupByOrderMode.html">streaming group by</a>, sophisticated
<a href="https://docs.rs/datafusion/latest/datafusion/physical_optimizer/global_sort_selection/index.html">sort</a> and <a href="https://docs.rs/datafusion/latest/datafusion/physical_optimizer/repartition/index.html">repartitioning</a> improvements in the optimizer, and support
for <a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/joins/struct.SymmetricHashJoinExec.html">symmetric hash join</a> (read more about that in the great <a href="https://www.synnada.ai/blog/general-purpose-stream-joins-via-pruning-symmetric-hash-joins">Synnada
Blog Post</a> on the topic). Together, these features both 1) make it
easier to build streaming systems using DataFusion that can
incrementally generate output before (or ever) seeing the end of the
input and 2) allow general queries to use less memory and generate their
results faster.</p>

<p>We have also improved the runtime <a href="https://docs.rs/datafusion/latest/datafusion/execution/memory_pool/index.html">memory management</a> system so that
DataFusion now stays within its declared memory budget <a href="https://github.com/apache/arrow-datafusion/issues/3941">generate
runtime errors</a>.</p>

<h3 id="dml-support-insert-delete-update-etc">DML Support (<code class="language-plaintext highlighter-rouge">INSERT</code>, <code class="language-plaintext highlighter-rouge">DELETE</code>, <code class="language-plaintext highlighter-rouge">UPDATE</code>, etc)</h3>

<p>Part of building high performance data systems includes writing data,
and DataFusion supports several features for creating new files:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">INSERT INTO</code> and <code class="language-plaintext highlighter-rouge">SELECT ... INTO </code> support for memory backed and CSV tables</li>
  <li>New <a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/insert/trait.DataSink.html">API for writing data into TableProviders</a></li>
</ul>

<p>We are working on easier to use <a href="https://github.com/apache/arrow-datafusion/issues/5654">COPY INTO</a> syntax, better support
for writing parquet, JSON, and AVRO, and more ‚Äì see our <a href="https://github.com/apache/arrow-datafusion/issues/6569">tracking epic</a>
for more details.</p>

<h3 id="timestamp-and-intervals">Timestamp and Intervals</h3>

<p>One mark of the maturity of a SQL engine is how it handles the tricky
world of timestamp, date, times and interval arithmetic. DataFusion is
feature complete in this area and behaves as you would expect,
supporting queries such as</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">now</span><span class="p">()</span> <span class="o">+</span> <span class="s1">'1 month'</span> <span class="k">FROM</span> <span class="n">my_table</span><span class="p">;</span>
</code></pre></div></div>

<p>We still have a long tail of <a href="https://github.com/apache/arrow-datafusion/issues/3148">date and time improvements</a>, which we are working on as well.</p>

<h3 id="querying-structured-types-list-and-structs">Querying Structured Types (<code class="language-plaintext highlighter-rouge">List</code> and <code class="language-plaintext highlighter-rouge">Struct</code>s)</h3>

<p>Arrow and Parquet <a href="https://arrow.apache.org/blog/2022/10/08/arrow-parquet-encoding-part-2/">support nested data</a> well and DataFusion lets you
easily query such <code class="language-plaintext highlighter-rouge">Struct</code> and <code class="language-plaintext highlighter-rouge">List</code>. For example, you can use
DataFusion to read and query the <a href="https://data.mendeley.com/datasets/ct8f9skv97">JSON Datasets for Exploratory OLAP -
Mendeley Data</a> like this:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">----------</span>
<span class="c1">-- Explore structured data using SQL</span>
<span class="c1">----------</span>
<span class="k">SELECT</span> <span class="k">delete</span> <span class="k">FROM</span> <span class="s1">'twitter-sample-head-100000.parquet'</span> <span class="k">WHERE</span> <span class="k">delete</span> <span class="k">IS</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">limit</span> <span class="mi">10</span><span class="p">;</span>
<span class="o">+</span><span class="c1">---------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="k">delete</span>                                                                                                                    <span class="o">|</span>
<span class="o">+</span><span class="c1">---------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">135037425050320896</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">135037425050320896</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">334902461</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">334902461</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134703982051463168</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134703982051463168</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">405383453</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">405383453</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134773741740765184</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134773741740765184</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">64823441</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">64823441</span><span class="p">}}</span>   <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">132543659655704576</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">132543659655704576</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">45917834</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">45917834</span><span class="p">}}</span>   <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">133786431926697984</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">133786431926697984</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">67229952</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">67229952</span><span class="p">}}</span>   <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134619093570560002</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134619093570560002</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">182430773</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">182430773</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134019857527214080</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134019857527214080</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">257396311</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">257396311</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">133931546469076993</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">133931546469076993</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">124539548</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">124539548</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134397743350296576</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134397743350296576</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">139836391</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">139836391</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">127833661767823360</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">127833661767823360</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">244442687</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">244442687</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">---------------------------------------------------------------------------------------------------------------------------+</span>

<span class="c1">----------</span>
<span class="c1">-- Select some deeply nested fields</span>
<span class="c1">----------</span>
<span class="k">SELECT</span>
  <span class="k">delete</span><span class="p">[</span><span class="s1">'status'</span><span class="p">][</span><span class="s1">'id'</span><span class="p">][</span><span class="s1">'$numberLong'</span><span class="p">]</span> <span class="k">as</span> <span class="n">delete_id</span><span class="p">,</span>
  <span class="k">delete</span><span class="p">[</span><span class="s1">'status'</span><span class="p">][</span><span class="s1">'user_id'</span><span class="p">]</span> <span class="k">as</span> <span class="n">delete_user_id</span>
<span class="k">FROM</span> <span class="s1">'twitter-sample-head-100000.parquet'</span> <span class="k">WHERE</span> <span class="k">delete</span> <span class="k">IS</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">LIMIT</span> <span class="mi">10</span><span class="p">;</span>

<span class="o">+</span><span class="c1">--------------------+----------------+</span>
<span class="o">|</span> <span class="n">delete_id</span>          <span class="o">|</span> <span class="n">delete_user_id</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">--------------------+----------------+</span>
<span class="o">|</span> <span class="mi">135037425050320896</span> <span class="o">|</span> <span class="mi">334902461</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">134703982051463168</span> <span class="o">|</span> <span class="mi">405383453</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">134773741740765184</span> <span class="o">|</span> <span class="mi">64823441</span>       <span class="o">|</span>
<span class="o">|</span> <span class="mi">132543659655704576</span> <span class="o">|</span> <span class="mi">45917834</span>       <span class="o">|</span>
<span class="o">|</span> <span class="mi">133786431926697984</span> <span class="o">|</span> <span class="mi">67229952</span>       <span class="o">|</span>
<span class="o">|</span> <span class="mi">134619093570560002</span> <span class="o">|</span> <span class="mi">182430773</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">134019857527214080</span> <span class="o">|</span> <span class="mi">257396311</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">133931546469076993</span> <span class="o">|</span> <span class="mi">124539548</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">134397743350296576</span> <span class="o">|</span> <span class="mi">139836391</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">127833661767823360</span> <span class="o">|</span> <span class="mi">244442687</span>      <span class="o">|</span>
<span class="o">+</span><span class="c1">--------------------+----------------+</span>
</code></pre></div></div>

<h3 id="subqueries-all-the-way-down">Subqueries All the Way Down</h3>

<p>DataFusion can run many different subqueries by rewriting them to
joins. It has been able to run the full suite of TPC-H queries for at
least the last year, but recently we have implemented significant
improvements to this logic, sufficient to run almost all queries in
the TPC-DS benchmark as well.</p>

<h2 id="community-and-project-growth">Community and Project Growth</h2>

<p>The six months since <a href="https://arrow.apache.org/blog/2023/01/19/datafusion-16.0.0">our last update</a> saw significant growth in
the DataFusion community. Between versions <code class="language-plaintext highlighter-rouge">17.0.0</code> and <code class="language-plaintext highlighter-rouge">26.0.0</code>,
DataFusion merged 711 PRs from 107 distinct contributors, not
including all the work that goes into our core dependencies such as
<a href="https://crates.io/crates/arrow">arrow</a>,
<a href="https://crates.io/crates/parquet">parquet</a>, and
<a href="https://crates.io/crates/object_store">object_store</a>, that much of
the same community helps support.</p>

<p>In addition, we have added 7 new committers and 1 new PMC member to
the Apache Arrow project, largely focused on DataFusion, and we
learned about some of the cool <a href="https://arrow.apache.org/datafusion/user-guide/introduction.html#known-users">new systems</a> which are using
DataFusion. Given the growth of the community and interest in the
project, we also clarified the <a href="https://github.com/apache/arrow-datafusion/discussions/6441">mission statement</a> and are
<a href="https://github.com/apache/arrow-datafusion/discussions/6475">discussing</a> ‚Äúgraduate‚Äùing DataFusion to a new top level
Apache Software Foundation project.</p>

<!--
$ git log --pretty=oneline 17.0.0..26.0.0 . | wc -l
     711

$ git shortlog -sn 17.0.0..26.0.0 . | wc -l
      107
-->

<h1 id="how-to-get-involved">How to Get Involved</h1>

<p>Kudos to everyone in the community who has contributed ideas,
discussions, bug reports, documentation and code. It is exciting to be
innovating on the next generation of database architectures together!</p>

<p>If you are interested in contributing to DataFusion, we would love to
have you join us. You can try out DataFusion on some of your own
data and projects and let us know how it goes or contribute a PR with
documentation, tests or code. A list of open issues suitable for
beginners is <a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">here</a>.</p>

<p>Check out our <a href="https://arrow.apache.org/datafusion/contributor-guide/communication.html">Communication Doc</a> for more ways to engage with the
community.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Apache Arrow DataFusion 16.0.0 Project Update</title><link href="https://datafusion.apache.org/blog/2023/01/19/datafusion-16.0.0/" rel="alternate" type="text/html" title="Apache Arrow DataFusion 16.0.0 Project Update" /><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2023/01/19/datafusion-16.0.0</id><content type="html" xml:base="https://datafusion.apache.org/blog/2023/01/19/datafusion-16.0.0/"><![CDATA[<!--

-->

<h1 id="introduction">Introduction</h1>

<p><a href="https://arrow.apache.org/datafusion/">DataFusion</a> is an extensible
query execution framework, written in <a href="https://www.rust-lang.org/">Rust</a>,
that uses <a href="https://arrow.apache.org">Apache Arrow</a> as its
in-memory format. It is targeted primarily at developers creating data
intensive analytics, and offers mature
<a href="https://arrow.apache.org/datafusion/user-guide/sql/index.html">SQL support</a>,
a DataFrame API, and many extension points.</p>

<p>Systems based on DataFusion perform very well in benchmarks,
especially considering they operate directly on parquet files rather
than first loading into a specialized format.  Some recent highlights
include <a href="https://benchmark.clickhouse.com/">clickbench</a> and the
<a href="https://www.cloudfuse.io/dashboards/standalone-engines">Cloudfuse.io standalone query
engines</a> page.</p>

<p>DataFusion is also part of a longer term trend, articulated clearly by
<a href="http://www.cs.cmu.edu/~pavlo/">Andy Pavlo</a> in his <a href="https://ottertune.com/blog/2022-databases-retrospective/">2022 Databases
Retrospective</a>.
Database frameworks are proliferating and it is likely that all OLAP
DBMSs and other data heavy applications, such as machine learning,
will <strong>require</strong> a vectorized, highly performant query engine in the next
5 years to remain relevant.  The only practical way to make such
technology so widely available without many millions of dollars of
investment is though open source engine such as DataFusion or
<a href="https://github.com/facebookincubator/velox">Velox</a>.</p>

<p>The rest of this post describes the improvements made to DataFusion
over the last three months and some hints of where we are heading.</p>

<h2 id="community-growth">Community Growth</h2>

<p>We again saw significant growth in the DataFusion community since <a href="https://arrow.apache.org/blog/2022/10/25/datafusion-13.0.0/">our last update</a>. There are some interesting metrics on <a href="https://ossrank.com/p/1573-apache-arrow-datafusion">OSSRank</a>.</p>

<p>The DataFusion 16.0.0 release consists of 543 PRs from 73 distinct contributors, not including all the work that goes into dependencies such as <a href="https://crates.io/crates/arrow">arrow</a>, <a href="https://crates.io/crates/parquet">parquet</a>, and <a href="https://crates.io/crates/object_store">object_store</a>, that much of the same community helps support. Thank you all for your help</p>

<!--
$ git log --pretty=oneline 13.0.0..16.0.0 . | wc -l
     543

$ git shortlog -sn 13.0.0..16.0.0 . | wc -l
      73
-->
<p>Several <a href="https://github.com/apache/arrow-datafusion#known-uses">new systems based on DataFusion</a> were recently added:</p>

<ul>
  <li><a href="https://github.com/GreptimeTeam/greptimedb">Greptime DB</a></li>
  <li><a href="https://synnada.ai/">Synnada</a></li>
  <li><a href="https://github.com/PRQL/prql-query">PRQL</a></li>
  <li><a href="https://github.com/parseablehq/parseable">Parseable</a></li>
  <li><a href="https://github.com/splitgraph/seafowl">SeaFowl</a></li>
</ul>

<h2 id="performance-">Performance üöÄ</h2>

<p>Performance and efficiency are core values for
DataFusion. While there is still a gap between DataFusion and the best of
breed, tightly integrated systems such as <a href="https://duckdb.org">DuckDB</a>
and <a href="https://www.pola.rs/">Polars</a>, DataFusion is
closing the gap quickly. Performance highlights from the last three
months:</p>

<ul>
  <li>Up to 30% Faster Sorting and Merging using the new <a href="https://arrow.apache.org/blog/2022/11/07/multi-column-sorts-in-arrow-rust-part-1/">Row Format</a></li>
  <li><a href="https://arrow.apache.org/blog/2022/12/26/querying-parquet-with-millisecond-latency/">Advanced predicate pushdown</a>, directly on parquet, directly from object storage, enabling sub millisecond filtering. <!-- Andrew nots: we should really get this turned on by default --></li>
  <li><code class="language-plaintext highlighter-rouge">70%</code> faster <code class="language-plaintext highlighter-rouge">IN</code> expressions evaluation (<a href="https://github.com/apache/arrow-datafusion/issues/4057">#4057</a>)</li>
  <li>Sort and partition aware optimizations (<a href="https://github.com/apache/arrow-datafusion/issues/3969">#3969</a> and  <a href="https://github.com/apache/arrow-datafusion/issues/4691">#4691</a>)</li>
  <li>Filter selectivity analysis (<a href="https://github.com/apache/arrow-datafusion/issues/3868">#3868</a>)</li>
</ul>

<h2 id="runtime-resource-limits">Runtime Resource Limits</h2>

<p>Previously, DataFusion could potentially use unbounded amounts of memory for certain queries that included Sorts, Grouping or Joins.</p>

<p>In version 16.0.0, it is possible to limit DataFusion‚Äôs memory usage for Sorting and Grouping. We are looking for help adding similar limiting for Joins as well as expanding our algorithms to optionally spill to secondary storage. See <a href="https://github.com/apache/arrow-datafusion/issues/3941">#3941</a> for more detail.</p>

<h2 id="sql-window-functions">SQL Window Functions</h2>

<p><a href="https://en.wikipedia.org/wiki/Window_function_(SQL)">SQL Window Functions</a> are useful for a variety of analysis and DataFusion‚Äôs implementation support expanded significantly:</p>

<ul>
  <li>Custom window frames such as <code class="language-plaintext highlighter-rouge">... OVER (ORDER BY ... RANGE BETWEEN 0.2 PRECEDING AND 0.2 FOLLOWING)</code></li>
  <li>Unbounded window frames such as <code class="language-plaintext highlighter-rouge">... OVER (ORDER BY ... RANGE UNBOUNDED ROWS PRECEDING)</code></li>
  <li>Support for the <code class="language-plaintext highlighter-rouge">NTILE</code> window function (<a href="https://github.com/apache/arrow-datafusion/issues/4676">#4676</a>)</li>
  <li>Support for <code class="language-plaintext highlighter-rouge">GROUPS</code> mode (<a href="https://github.com/apache/arrow-datafusion/issues/4155">#4155</a>)</li>
</ul>

<h1 id="improved-joins">Improved Joins</h1>

<p>Joins are often the most complicated operations to handle well in
analytics systems and DataFusion 16.0.0 offers significant improvements
such as</p>

<ul>
  <li>Cost based optimizer (CBO) automatically reorders join evaluations, selects algorithms (Merge / Hash), and pick build side based on available statistics and join type (<code class="language-plaintext highlighter-rouge">INNER</code>, <code class="language-plaintext highlighter-rouge">LEFT</code>, etc) (<a href="https://github.com/apache/arrow-datafusion/issues/4219">#4219</a>)</li>
  <li>Fast non <code class="language-plaintext highlighter-rouge">column=column</code> equijoins such as <code class="language-plaintext highlighter-rouge">JOIN ON a.x + 5 = b.y</code></li>
  <li>Better performance on non-equijoins (<a href="https://github.com/apache/arrow-datafusion/issues/4562">#4562</a>) <!-- TODO is this a good thing to mention as any time this is usd the query is going to go slow or the data size is small --></li>
</ul>

<h1 id="streaming-execution">Streaming Execution</h1>

<p>One emerging use case for Datafusion is as a foundation for
streaming-first data platforms. An important prerequisite
is support for incremental execution for queries that can be computed
incrementally.</p>

<p>With this release, DataFusion now supports the following streaming features:</p>

<ul>
  <li>Data ingestion from infinite files such as FIFOs (<a href="https://github.com/apache/arrow-datafusion/issues/4694">#4694</a>),</li>
  <li>Detection of pipeline-breaking queries in streaming use cases (<a href="https://github.com/apache/arrow-datafusion/issues/4694">#4694</a>),</li>
  <li>Automatic input swapping for joins so probe side is a data stream (<a href="https://github.com/apache/arrow-datafusion/issues/4694">#4694</a>),</li>
  <li>Intelligent elision of pipeline-breaking sort operations whenever possible (<a href="https://github.com/apache/arrow-datafusion/issues/4691">#4691</a>),</li>
  <li>Incremental execution for more types of queries; e.g. queries involving finite window frames (<a href="https://github.com/apache/arrow-datafusion/issues/4777">#4777</a>).</li>
</ul>

<p>These are a major steps forward, and we plan even more improvements over the next few releases.</p>

<h1 id="better-support-for-distributed-catalogs">Better Support for Distributed Catalogs</h1>

<p>16.0.0 has been enhanced support for asynchronous catalogs (<a href="https://github.com/apache/arrow-datafusion/issues/4607">#4607</a>)
to better support distributed metadata stores such as
<a href="https://delta.io/">Delta.io</a> and <a href="https://iceberg.apache.org/">Apache
Iceberg</a> which require asynchronous I/O
during planning to access remote catalogs. Previously, DataFusion
required synchronous access to all relevant catalog information.</p>

<h1 id="additional-sql-support">Additional SQL Support</h1>
<p>SQL support continues to improve, including some of these highlights:</p>

<ul>
  <li>Add TPC-DS query planning regression tests <a href="https://github.com/apache/arrow-datafusion/issues/4719">#4719</a></li>
  <li>Support for <code class="language-plaintext highlighter-rouge">PREPARE</code> statement <a href="https://github.com/apache/arrow-datafusion/issues/4490">#4490</a></li>
  <li>Automatic coercions ast between Date and Timestamp <a href="https://github.com/apache/arrow-datafusion/issues/4726">#4726</a></li>
  <li>Support type coercion for timestamp and utf8 <a href="https://github.com/apache/arrow-datafusion/issues/4312">#4312</a></li>
  <li>Full support for time32 and time64 literal values (<code class="language-plaintext highlighter-rouge">ScalarValue</code>) <a href="https://github.com/apache/arrow-datafusion/issues/4156">#4156</a></li>
  <li>New functions, incuding <code class="language-plaintext highlighter-rouge">uuid()</code>  <a href="https://github.com/apache/arrow-datafusion/issues/4041">#4041</a>, <code class="language-plaintext highlighter-rouge">current_time</code>  <a href="https://github.com/apache/arrow-datafusion/issues/4054">#4054</a>, <code class="language-plaintext highlighter-rouge">current_date</code> <a href="https://github.com/apache/arrow-datafusion/issues/4022">#4022</a></li>
  <li>Compressed CSV/JSON support <a href="https://github.com/apache/arrow-datafusion/issues/3642">#3642</a></li>
</ul>

<p>The community has also invested in new <a href="https://github.com/apache/arrow-datafusion/blob/master/datafusion/core/tests/sqllogictests/README.md">sqllogic based</a> tests to keep improving DataFusion‚Äôs quality with less effort.</p>

<h1 id="plan-serialization-and-substrait">Plan Serialization and Substrait</h1>

<p>DataFusion now supports serialization of physical plans, with a custom protocol buffers format. In addition, we are adding initial support for <a href="https://substrait.io/">Substrait</a>, a Cross-Language Serialization for Relational Algebra</p>

<h1 id="how-to-get-involved">How to Get Involved</h1>

<p>Kudos to everyone in the community who contributed ideas, discussions, bug reports, documentation and code. It is exciting to be building something so cool together!</p>

<p>If you are interested in contributing to DataFusion, we would love to
have you join us. You can try out DataFusion on some of your own
data and projects and let us know how it goes or contribute a PR with
documentation, tests or code. A list of open issues suitable for
beginners is
<a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">here</a>.</p>

<p>Check out our <a href="https://arrow.apache.org/datafusion/community/communication.html">Communication Doc</a> on more
ways to engage with the community.</p>

<h2 id="appendix-contributor-shoutout">Appendix: Contributor Shoutout</h2>

<p>Here is a list of people who have contributed PRs to this project over the last three releases, derived from <code class="language-plaintext highlighter-rouge">git shortlog -sn 13.0.0..16.0.0 .</code> Thank you all!</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   113	Andrew Lamb
    58	jakevin
    46	Raphael Taylor-Davies
    30	Andy Grove
    19	Batuhan Taskaya
    19	Remzi Yang
    17	ygf11
    16	Burak
    16	Jeffrey
    16	Marco Neumann
    14	Kun Liu
    12	Yang Jiang
    10	mingmwang
     9	Dani√´l Heres
     9	Mustafa akur
     9	comphead
     9	mvanschellebeeck
     9	xudong.w
     7	dependabot[bot]
     7	yahoNanJing
     6	Brent Gardner
     5	AssHero
     4	Jiayu Liu
     4	Wei-Ting Kuo
     4	askoa
     3	Andr√© Calado Coroado
     3	Jie Han
     3	Jon Mease
     3	Metehan Yƒ±ldƒ±rƒ±m
     3	Nga Tran
     3	Ruihang Xia
     3	baishen
     2	Berkay ≈ûahin
     2	Dan Harris
     2	Dongyan Zhou
     2	Eduard Karacharov
     2	Kikkon
     2	Liang-Chi Hsieh
     2	Marko Milenkoviƒá
     2	Martin Grigorov
     2	Roman Nozdrin
     2	Tim Van Wassenhove
     2	r.4ntix
     2	unconsolable
     2	unvalley
     1	Ajaya Agrawal
     1	Alexander Spies
     1	ArkashaJavelin
     1	Artjoms Iskovs
     1	BoredPerson
     1	Christian Salvati
     1	Creampanda
     1	Data Psycho
     1	Francis Du
     1	Francis Le Roy
     1	LFC
     1	Marko Grujic
     1	Matt Willian
     1	Matthijs Brobbel
     1	Max Burke
     1	Mehmet Ozan Kabak
     1	Rito Takeuchi
     1	Roman Zeyde
     1	Vrishabh
     1	Zhang Li
     1	ZuoTiJia
     1	byteink
     1	cfraz89
     1	nbr
     1	xxchan
     1	yujie.zhang
     1	zembunia
     1	ÂìáÂëúÂìáÂëúÂëÄÂí¶ËÄ∂
</code></pre></div></div>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Apache Arrow Ballista 0.9.0 Release</title><link href="https://datafusion.apache.org/blog/2022/10/28/ballista-0.9.0/" rel="alternate" type="text/html" title="Apache Arrow Ballista 0.9.0 Release" /><published>2022-10-28T00:00:00+00:00</published><updated>2022-10-28T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2022/10/28/ballista-0.9.0</id><content type="html" xml:base="https://datafusion.apache.org/blog/2022/10/28/ballista-0.9.0/"><![CDATA[<!--

-->

<h1 id="introduction">Introduction</h1>

<p><a href="https://github.com/apache/arrow-ballista">Ballista</a> is an Arrow-native distributed SQL query engine implemented in Rust.</p>

<p>Ballista 0.9.0 is now available and is the most significant release since the project was <a href="http://arrow.apache.org/blog/2021/04/12/ballista-donation/">donated</a> to Apache
Arrow in 2021.</p>

<p>This release represents 4 weeks of work, with 66 commits from 14 contributors:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    22  Andy Grove
    12  yahoNanJing
     6  Dani√´l Heres
     4  Brent Gardner
     4  dependabot[bot]
     4  r.4ntix
     3  Stefan Stanciulescu
     3  mingmwang
     2  Ken Suenobu
     2  Yang Jiang
     1  Metehan Yƒ±ldƒ±rƒ±m
     1  Trent Feda
     1  askoa
     1  yangzhong
</code></pre></div></div>

<h2 id="release-highlights">Release Highlights</h2>

<p>The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes
and improvements have been made: we refer you to the <a href="https://github.com/apache/arrow-ballista/blob/0.9.0-rc2/ballista/CHANGELOG.md">complete changelog</a>.</p>

<h3 id="support-for-cloud-object-stores-and-distributed-file-systems">Support for Cloud Object Stores and Distributed File Systems</h3>

<p>This is the first release of Ballista to have documented support for querying data from distributed file systems and
object stores. Currently, S3 and HDFS are supported. Support for Google Cloud Storage and Azure Blob Storage is planned
for the next release.</p>

<h3 id="flight-sql--jdbc-support">Flight SQL &amp; JDBC support</h3>

<p>The Ballista scheduler now implements the <a href="https://arrow.apache.org/blog/2022/02/16/introducing-arrow-flight-sql/">Flight SQL protocol</a>, enabling any compliant Flight SQL client
to connect to and run queries against a Ballista cluster.</p>

<p>The Apache Arrow Flight SQL JDBC driver can be used to connect Business Intelligence tools to a Ballista cluster.</p>

<h3 id="python-bindings">Python Bindings</h3>

<p>It is now possible to connect to a Ballista cluster from Python and execute queries using both the DataFrame and SQL
interfaces.</p>

<h3 id="scheduler-web-user-interface-and-rest-api">Scheduler Web User Interface and REST API</h3>

<p>The scheduler now has a web user interface for monitoring queries. It is also possible to view graphical query plans
that show how the query was executed, along with metrics.</p>

<p><img src="/blog/img/2022-10-28-ballista-web-ui.png" width="800" /></p>

<p>The REST API that powers the user interface can also be accessed directly.</p>

<h3 id="simplified-kubernetes-deployment">Simplified Kubernetes Deployment</h3>

<p>Ballista now provides a <a href="https://github.com/apache/arrow-ballista/tree/master/helm">Helm chart</a> for simplified Kubernetes deployment.</p>

<h3 id="user-guide">User Guide</h3>

<p>The user guide is published at <a href="https://arrow.apache.org/ballista/">https://arrow.apache.org/ballista/</a> and provides
deployment instructions for Docker, Docker Compose, and Kubernetes, as well as references for configuring and
tuning Ballista.</p>

<h2 id="roadmap">Roadmap</h2>

<p>The Ballista community is currently focused on the following tasks for the next release:</p>

<ul>
  <li>Support for Azure Blob Storage and Google Cloud Storage</li>
  <li>Improve benchmark performance by implementing more query optimizations</li>
  <li>Improve scheduler web user interface</li>
  <li>Publish Docker images to GitHub Container Registry</li>
</ul>

<p>The detailed list of issues planned for the 0.10.0 release can be found in the <a href="https://github.com/apache/arrow-ballista/issues/361">tracking issue</a>.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>Ballista has a friendly community and we welcome contributions. A good place to start is to following the instructions
in the <a href="https://arrow.apache.org/ballista/">user guide</a> and try using Ballista with your own SQL queries and ETL pipelines, and file issues
for any bugs or feature suggestions.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry><entry><title type="html">Apache Arrow DataFusion 13.0.0 Project Update</title><link href="https://datafusion.apache.org/blog/2022/10/25/datafusion-13.0.0/" rel="alternate" type="text/html" title="Apache Arrow DataFusion 13.0.0 Project Update" /><published>2022-10-25T00:00:00+00:00</published><updated>2022-10-25T00:00:00+00:00</updated><id>https://datafusion.apache.org/blog/2022/10/25/datafusion-13.0.0</id><content type="html" xml:base="https://datafusion.apache.org/blog/2022/10/25/datafusion-13.0.0/"><![CDATA[<!--

-->

<h1 id="introduction">Introduction</h1>

<p><a href="https://arrow.apache.org/datafusion/">Apache Arrow DataFusion</a> <a href="https://crates.io/crates/datafusion"><code class="language-plaintext highlighter-rouge">13.0.0</code></a> is released, and this blog contains an update on the project for the 5 months since our <a href="https://arrow.apache.org/blog/2022/05/16/datafusion-8.0.0/">last update in May 2022</a>.</p>

<p>DataFusion is an extensible and embeddable query engine, written in Rust used to create modern, fast and efficient data pipelines, ETL processes, and database systems. You may want to check out DataFusion to extend your Rust project to:</p>

<ul>
  <li>Support <a href="https://arrow.apache.org/datafusion/user-guide/sql/sql_status.html">SQL support</a></li>
  <li>Support <a href="https://docs.rs/datafusion/13.0.0/datafusion/dataframe/struct.DataFrame.html">DataFrame API</a></li>
  <li>Support a Domain Specific Query Language</li>
  <li>Easily and quickly read and process Parquet, JSON, Avro or CSV data.</li>
  <li>Read from remote object stores such as AWS S3, Azure Blob Storage, GCP.</li>
</ul>

<p>Even though DataFusion is 4 years ‚Äúyoung,‚Äù it has seen significant community growth in the last few months and the momentum continues to accelerate.</p>

<h1 id="background">Background</h1>

<p>DataFusion is used as the engine in <a href="https://github.com/apache/arrow-datafusion#known-uses">many open source and commercial projects</a> and was one of the early open source projects to provide this capability. 2022 has validated our belief in the need for such a <a href="https://docs.google.com/presentation/d/1iNX_35sWUakee2q3zMFPyHE4IV2nC3lkCK_H6Y2qK84/edit#slide=id.p">‚ÄúLLVM for database and AI systems‚Äù</a><a href="https://www.slideshare.net/AndrewLamb32/20220623-apache-arrow-and-datafusion-changing-the-game-for-implementing-database-systemspdf">(alternate link)</a> with announcements such as the <a href="https://engineering.fb.com/2022/08/31/open-source/velox/">release of FaceBook‚Äôs Velox</a> engine, the major investments in <a href="https://arrow.apache.org/docs/cpp/streaming_execution.html">Acero</a> as well as the continued popularity of <a href="https://calcite.apache.org/">Apache Calcite</a> and other similar technologies.</p>

<p>While Velox and Acero focus on execution engines, DataFusion provides the entire suite of components needed to build most analytic systems, including a SQL frontend, a dataframe API, and  extension points for just about everything. Some <a href="https://github.com/apache/arrow-datafusion#known-uses">DataFusion users</a> use a subset of the features such as the frontend (e.g. <a href="https://dask-sql.readthedocs.io/en/latest/">dask-sql</a>) or the execution engine, (e.g.  <a href="https://github.com/blaze-init/blaze">Blaze</a>), and some use many different components to build both SQL based and customized DSL based systems such as <a href="https://github.com/influxdata/influxdb_iox/pulls">InfluxDB IOx</a> and <a href="https://github.com/vegafusion/vegafusion">VegaFusion</a>.</p>

<p>One of DataFusion‚Äôs advantages is its implementation in <a href="https://www.rust-lang.org/">Rust</a> and thus its easy integration with the broader Rust ecosystem. Rust continues to be a major source of benefit, from the <a href="https://www.influxdata.com/blog/using-rustlangs-async-tokio-runtime-for-cpu-bound-tasks/">ease of parallelization with the high quality and standardized <code class="language-plaintext highlighter-rouge">async</code> ecosystem</a> , as well as its modern dependency management system and wonderful performance. <!-- I wonder if we should link to clickbench?? -->
<!--While we haven‚Äôt invested in the benchmarking ratings game datafusion continues to be quite speedy (todo quantity this, with some evidence) ‚Äì maybe clickbench?--></p>

<!--
Maybe we can do this un a future post
# DataFusion in Action

While DataFusion really shines as an embeddable query engine, if you want to try it out and get a feel for its power, you can use the basic[`datafusion-cli`](https://docs.rs/datafusion-cli/13.0.0/datafusion_cli/) tool to get a sense for what is possible to add in your application

(TODO example here of using datafusion-cli to query from local parquet files on disk)

TODO: also mention you can use the same thing to query data from S3
-->

<h1 id="summary">Summary</h1>

<p>We have increased the frequency of DataFusion releases to monthly instead of quarterly. This
makes it easier for the increasing number of projects that now depend on DataFusion.</p>

<p>We have also completed the ‚Äúgraduation‚Äù of <a href="https://github.com/apache/arrow-ballista">Ballista to its own top-level arrow-ballista repository</a>
which decouples the two projects and allows each project to move even faster.</p>

<p>Along with numerous other bug fixes and smaller improvements, here are some of the major advances:</p>

<h1 id="improved-support-for-cloud-object-stores">Improved Support for Cloud Object Stores</h1>

<p>DataFusion now supports many major cloud object stores (Amazon S3, Azure Blob Storage, and Google Cloud Storage) ‚Äúout of the box‚Äù via the <a href="https://crates.io/crates/object_store">object_store</a> crate. Using this integration, DataFusion optimizes reading parquet files by reading only the parts of the files that are needed.</p>

<h2 id="advanced-sql">Advanced SQL</h2>

<p>DataFusion now supports correlated subqueries, by rewriting them as joins. See the <a href="https://arrow.apache.org/datafusion/user-guide/sql/subqueries.html">Subquery</a> page in the User Guide for more information.</p>

<p>In addition to numerous other small improvements, the following SQL features are now supported:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ROWS</code>, <code class="language-plaintext highlighter-rouge">RANGE</code>, <code class="language-plaintext highlighter-rouge">PRECEDING</code> and <code class="language-plaintext highlighter-rouge">FOLLOWING</code> in <code class="language-plaintext highlighter-rouge">OVER</code> clauses <a href="https://github.com/apache/arrow-datafusion/issues/3570">#3570</a></li>
  <li><code class="language-plaintext highlighter-rouge">ROLLUP</code> and <code class="language-plaintext highlighter-rouge">CUBE</code> grouping set expressions  <a href="https://github.com/apache/arrow-datafusion/issues/2446">#2446</a></li>
  <li><code class="language-plaintext highlighter-rouge">SUM DISTINCT</code> aggregate support  <a href="https://github.com/apache/arrow-datafusion/issues/2405">#2405</a></li>
  <li><code class="language-plaintext highlighter-rouge">IN</code> and <code class="language-plaintext highlighter-rouge">NOT IN</code> Subqueries by rewriting them to <code class="language-plaintext highlighter-rouge">SEMI</code> / <code class="language-plaintext highlighter-rouge">ANTI</code> <a href="https://github.com/apache/arrow-datafusion/issues/2885">#2421</a></li>
  <li>Non equality predicates in  <code class="language-plaintext highlighter-rouge">ON</code> clause of  <code class="language-plaintext highlighter-rouge">LEFT</code>, <code class="language-plaintext highlighter-rouge">RIGHT, </code>and <code class="language-plaintext highlighter-rouge">FULL</code> joins <a href="https://github.com/apache/arrow-datafusion/issues/2591">#2591</a></li>
  <li>Exact <code class="language-plaintext highlighter-rouge">MEDIAN</code> <a href="https://github.com/apache/arrow-datafusion/issues/3009">#3009</a></li>
  <li><code class="language-plaintext highlighter-rouge">GROUPING SETS</code>/<code class="language-plaintext highlighter-rouge">CUBE</code>/<code class="language-plaintext highlighter-rouge">ROLLUP</code> <a href="https://github.com/apache/arrow-datafusion/issues/2716">#2716</a></li>
</ul>

<h1 id="more-ddl-support">More DDL Support</h1>

<p>Just as it is important to query, it is also important to give users the ability to define their data sources. We have added:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">CREATE VIEW</code> <a href="https://github.com/apache/arrow-datafusion/issues/2279">#2279</a></li>
  <li><code class="language-plaintext highlighter-rouge">DESCRIBE &lt;table&gt;</code> <a href="https://github.com/apache/arrow-datafusion/issues/2642">#2642</a></li>
  <li>Custom / Dynamic table provider factories <a href="https://github.com/apache/arrow-datafusion/issues/3311">#3311</a></li>
  <li><code class="language-plaintext highlighter-rouge">SHOW CREATE TABLE</code> for support for views <a href="https://github.com/apache/arrow-datafusion/issues/2830">#2830</a></li>
</ul>

<h1 id="faster-execution">Faster Execution</h1>
<p>Performance is always an important goal for DataFusion, and there are a number of significant new optimizations such as</p>

<ul>
  <li>Optimizations of TopK (queries with a <code class="language-plaintext highlighter-rouge">LIMIT</code> or <code class="language-plaintext highlighter-rouge">OFFSET</code> clause):  <a href="https://github.com/apache/arrow-datafusion/issues/3527">#3527</a>, <a href="https://github.com/apache/arrow-datafusion/issues/2521">#2521</a></li>
  <li>Reduce <code class="language-plaintext highlighter-rouge">left</code>/<code class="language-plaintext highlighter-rouge">right</code>/<code class="language-plaintext highlighter-rouge">full</code> joins to <code class="language-plaintext highlighter-rouge">inner</code> join <a href="https://github.com/apache/arrow-datafusion/issues/2750">#2750</a></li>
  <li>Convert  cross joins to inner joins when possible <a href="https://github.com/apache/arrow-datafusion/issues/3482">#3482</a></li>
  <li>Sort preserving <code class="language-plaintext highlighter-rouge">SortMergeJoin</code> <a href="https://github.com/apache/arrow-datafusion/issues/2699">#2699</a></li>
  <li>Improvements in group by and sort performance <a href="https://github.com/apache/arrow-datafusion/issues/2375">#2375</a></li>
  <li>Adaptive <code class="language-plaintext highlighter-rouge">regex_replace</code> implementation <a href="https://github.com/apache/arrow-datafusion/issues/3518">#3518</a></li>
</ul>

<h1 id="optimizer-enhancements">Optimizer Enhancements</h1>
<p>Internally the optimizer has been significantly enhanced as well.</p>

<ul>
  <li>Casting / coercion now happens during logical planning <a href="https://github.com/apache/arrow-datafusion/issues/3396">#3185</a> <a href="https://github.com/apache/arrow-datafusion/issues/3636">#3636</a></li>
  <li>More sophisticated expression analysis and simplification is available</li>
</ul>

<h1 id="parquet">Parquet</h1>
<ul>
  <li>The parquet reader can now read directly from parquet files on remote object storage <a href="https://github.com/apache/arrow-datafusion/issues/2677">#2489</a> <a href="https://github.com/apache/arrow-datafusion/issues/3051">#3051</a></li>
  <li>Experimental support for ‚Äúpredicate pushdown‚Äù with late materialization after filtering during the scan (another blog post on this topic is coming soon).</li>
  <li>Support reading directly from AWS S3 and other object stores via <code class="language-plaintext highlighter-rouge">datafusion-cli </code> <a href="https://github.com/apache/arrow-datafusion/issues/3631">#3631</a></li>
</ul>

<h1 id="datatype-support">DataType Support</h1>
<ul>
  <li>Support for <code class="language-plaintext highlighter-rouge">TimestampTz</code> <a href="https://github.com/apache/arrow-datafusion/issues/3660">#3660</a></li>
  <li>Expanded support for the <code class="language-plaintext highlighter-rouge">Decimal</code> type, including  <code class="language-plaintext highlighter-rouge">IN</code> list and better built in coercion.</li>
  <li>Expanded support for date/time manipulation such as  <code class="language-plaintext highlighter-rouge">date_bin</code> built-in function , timestamp <code class="language-plaintext highlighter-rouge">+/-</code> interval, <code class="language-plaintext highlighter-rouge">TIME</code> literal values <a href="https://github.com/apache/arrow-datafusion/issues/3010">#3010</a>, <a href="https://github.com/apache/arrow-datafusion/issues/3110">#3110</a>, <a href="https://github.com/apache/arrow-datafusion/issues/3034">#3034</a></li>
  <li>Binary operations (<code class="language-plaintext highlighter-rouge">AND</code>, <code class="language-plaintext highlighter-rouge">XOR</code>, etc):  <a href="https://github.com/apache/arrow-datafusion/issues/1619">#3037</a> <a href="https://github.com/apache/arrow-datafusion/issues/3430">#3420</a></li>
  <li><code class="language-plaintext highlighter-rouge">IS TRUE/FALSE</code> and <code class="language-plaintext highlighter-rouge">IS [NOT] UNKNOWN</code> <a href="https://github.com/apache/arrow-datafusion/issues/3235">#3235</a>, <a href="https://github.com/apache/arrow-datafusion/issues/3246">#3246</a></li>
</ul>

<h2 id="upcoming-work">Upcoming Work</h2>
<p>With the community growing and code accelerating, there is so much great stuff on the horizon. Some features we expect to land in the next few months:</p>

<ul>
  <li><a href="https://github.com/apache/arrow-datafusion/issues/3462">Complete Parquet Pushdown</a></li>
  <li><a href="https://github.com/apache/arrow-datafusion/issues/3148">Additional date/time support</a></li>
  <li>Cost models, Nested Join Optimizations, analysis framework <a href="https://github.com/apache/arrow-datafusion/issues/128">#128</a>, <a href="https://github.com/apache/arrow-datafusion/issues/3843">#3843</a>, <a href="https://github.com/apache/arrow-datafusion/issues/3845">#3845</a></li>
</ul>

<h1 id="community-growth">Community Growth</h1>

<p>The DataFusion 9.0.0 and 13.0.0 releases consists of 433 PRs from 64 distinct contributors. This does not count all the work that goes into our dependencies such as <a href="https://crates.io/crates/arrow">arrow</a>,  <a href="https://crates.io/crates/parquet">parquet</a>, and <a href="https://crates.io/crates/object_store">object_store</a>, that much of the same community helps nurture.</p>

<!--
$ git log --pretty=oneline 9.0.0..13.0.0 . | wc -l
433

$ git shortlog -sn 9.0.0..13.0.0 . | wc -l
65
-->

<h1 id="how-to-get-involved">How to Get Involved</h1>

<p>Kudos to everyone in the community who contributed ideas, discussions, bug reports, documentation and code. It is exciting to be building something so cool together!</p>

<p>If you are interested in contributing to DataFusion, we would love to
have you join us on our journey to create the most advanced open
source query engine. You can try out DataFusion on some of your own
data and projects and let us know how it goes or contribute a PR with
documentation, tests or code. A list of open issues suitable for
beginners is
<a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">here</a>.</p>

<p>Check out our <a href="https://arrow.apache.org/datafusion/community/communication.html">Communication Doc</a> on more
ways to engage with the community.</p>

<h2 id="appendix-contributor-shoutout">Appendix: Contributor Shoutout</h2>

<p>To give a sense of the number of people who contribute to this project regularly, we present for your consideration the following list derived from <code class="language-plaintext highlighter-rouge">git shortlog -sn 9.0.0..13.0.0 .</code> Thank you all again!</p>

<!-- Note: combined kmitchener and Kirk Mitchener -->

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    87	Andy Grove
    71	Andrew Lamb
    29	Kun Liu
    29	Kirk Mitchener
    17	Wei-Ting Kuo
    14	Yang Jiang
    12	Raphael Taylor-Davies
    11	Batuhan Taskaya
    10	Brent Gardner
    10	Remzi Yang
    10	comphead
    10	xudong.w
     8	AssHero
     7	Ruihang Xia
     6	Dan Harris
     6	Dani√´l Heres
     6	Ian Alexander Joiner
     6	Mike Roberts
     6	askoa
     4	BaymaxHWY
     4	gorkem
     4	jakevin
     3	George Andronchik
     3	Sarah Yurick
     3	Stuart Carnie
     2	Dalton Modlin
     2	Dmitry Patsura
     2	JasonLi
     2	Jon Mease
     2	Marco Neumann
     2	yahoNanJing
     1	Adilet Sarsembayev
     1	Ayush Dattagupta
     1	Dezhi Wu
     1	Dhamotharan Sritharan
     1	Eduard Karacharov
     1	Francis Du
     1	Harbour Zheng
     1	Isma√´l Mej√≠a
     1	Jack Klamer
     1	Jeremy Dyer
     1	Jiayu Liu
     1	Kamil Konior
     1	Liang-Chi Hsieh
     1	Martin Grigorov
     1	Matthijs Brobbel
     1	Mehmet Ozan Kabak
     1	Metehan Yƒ±ldƒ±rƒ±m
     1	Morgan Cassels
     1	Nitish Tiwari
     1	Renjie Liu
     1	Rito Takeuchi
     1	Robert Pack
     1	Thomas Cameron
     1	Vrishabh
     1	Xin Hao
     1	Yijie Shen
     1	byteink
     1	kamille
     1	mateuszkj
     1	nvartolomei
     1	yourenawo
     1	√ñzg√ºr Akkurt
</code></pre></div></div>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[&lt;!‚Äì]]></summary></entry></feed>