<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Apache DataFusion Blog - blog</title><link href="https://datafusion.apache.org/blog/" rel="alternate"></link><link href="https://datafusion.apache.org/blog/feeds/blog.atom.xml" rel="self"></link><id>https://datafusion.apache.org/blog/</id><updated>2024-11-20T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Apache DataFusion Comet 0.4.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2024/11/20/datafusion-comet-0.4.0" rel="alternate"></link><published>2024-11-20T00:00:00+00:00</published><updated>2024-11-20T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2024-11-20:/blog/blog/2024/11/20/datafusion-comet-0.4.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache DataFusion PMC is pleased to announce version 0.4.0 of the &lt;a href="https://datafusion.apache.org/comet/"&gt;Comet&lt;/a&gt; subproject.&lt;/p&gt;
&lt;p&gt;Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.&lt;/p&gt;
&lt;p&gt;Comet runs on commodity hardware and aims to …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache DataFusion PMC is pleased to announce version 0.4.0 of the &lt;a href="https://datafusion.apache.org/comet/"&gt;Comet&lt;/a&gt; subproject.&lt;/p&gt;
&lt;p&gt;Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.&lt;/p&gt;
&lt;p&gt;Comet runs on commodity hardware and aims to provide 100% compatibility with Apache Spark. Any operators or
expressions that are not fully compatible will fall back to Spark unless explicitly enabled by the user. Refer
to the &lt;a href="https://datafusion.apache.org/comet/user-guide/compatibility.html"&gt;compatibility guide&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;This release covers approximately six weeks of development work and is the result of merging 51 PRs from 10
contributors. See the &lt;a href="https://github.com/apache/datafusion-comet/blob/main/dev/changelog/0.4.0.md"&gt;change log&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2&gt;Release Highlights&lt;/h2&gt;
&lt;h3&gt;Performance &amp;amp; Stability&lt;/h3&gt;
&lt;p&gt;There are a number of performance and stability improvements in this release. Here is a summary of some of the
larger changes. Current benchmarking results can be found in the &lt;a href="https://datafusion.apache.org/comet/contributor-guide/benchmarking.html"&gt;Comet Benchmarking Guide&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Unified Memory Management&lt;/h4&gt;
&lt;p&gt;Comet now uses a unified memory management approach that shares an off-heap memory pool with Apache Spark, resulting
in a much simpler configuration. Comet now requires &lt;code&gt;spark.memory.offHeap.enabled=true&lt;/code&gt;. This approach provides a
holistic view of memory usage in Spark and Comet and makes it easier to optimize system performance.&lt;/p&gt;
&lt;h4&gt;Faster Joins&lt;/h4&gt;
&lt;p&gt;Apache Spark supports sort-merge and hash joins, which have similar performance characteristics. Spark defaults to
using sort-merge joins because they are less likely to result in OutOfMemory exceptions. In vectorized query
engines such as DataFusion, hash joins outperform sort-merge joins. Comet now has an experimental feature to
replace Spark sort-merge joins with hash joins for improved performance. This feature is experimental because
there is currently no spill-to-disk support in the hash join implementation. This feature can be enabled by
setting &lt;code&gt;spark.comet.exec.replaceSortMergeJoin=true&lt;/code&gt;.&lt;/p&gt;
&lt;h4&gt;Bloom Filter Aggregates&lt;/h4&gt;
&lt;p&gt;Spark&amp;rsquo;s optimizer can insert Bloom filter aggregations and filters to prune large result sets before a shuffle. However,
Comet would fall back to Spark for the aggregation. Comet now has native support for Bloom filter aggregations
after previously supporting Bloom filter testing. Users no longer need to set
&lt;code&gt;spark.sql.optimizer.runtime.bloomFilter.enabled=false&lt;/code&gt; when using Comet.&lt;/p&gt;
&lt;h4&gt;Complex Type support&lt;/h4&gt;
&lt;p&gt;This release has the following improvements to complex type support:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implemented &lt;code&gt;ArrayAppend&lt;/code&gt; and &lt;code&gt;GetArrayStructFields&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Implemented native cast between structs&lt;/li&gt;
&lt;li&gt;Implemented native cast from structs to string&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Roadmap&lt;/h2&gt;
&lt;p&gt;One of the highest priority items on the roadmap is to add support for reading complex types (maps, structs, and arrays)
from Parquet sources, both when reading Parquet directly and from Iceberg.&lt;/p&gt;
&lt;p&gt;Comet currently has proprietary native code for decoding Parquet pages, native column readers for all of Spark&amp;rsquo;s
primitive types, and special handling for Spark-specific use cases such as timestamp rebasing and decimal type
promotion. This implementation does not yet support complex types. File IO, decryption, and decompression are handled
in JVM code, and Parquet pages are passed on to native code for decoding.&lt;/p&gt;
&lt;p&gt;Rather than add complex type support to this existing code, we are exploring two main options to allow us to
leverage more of the upstream Arrow and DataFusion code.&lt;/p&gt;
&lt;h3&gt;Use DataFusion&amp;rsquo;s ParquetExec&lt;/h3&gt;
&lt;p&gt;For use cases where DataFusion can support reading a Parquet source, Comet could create a native plan that uses
DataFusion&amp;rsquo;s ParquetExec. We are investigating using DataFusion&amp;rsquo;s SchemaAdapter to handle some Spark-specific
handling of timestamps and decimals.&lt;/p&gt;
&lt;h3&gt;Use Arrow&amp;rsquo;s Parquet Batch Reader&lt;/h3&gt;
&lt;p&gt;For use cases not supported by DataFusion&amp;rsquo;s ParquetExec, such as integrating with Iceberg, we are exploring
replacing our current native Parquet decoding logic with the Arrow readers provided by the Parquet crate.&lt;/p&gt;
&lt;p&gt;Iceberg already provides a vectorized Spark reader for Parquet. A &lt;a href="https://github.com/apache/iceberg/pull/9841"&gt;PR&lt;/a&gt; is open against Iceberg for adding a native
version based on Comet, and we hope to update this to leverage the improvements outlined above.&lt;/p&gt;
&lt;h2&gt;Getting Involved&lt;/h2&gt;
&lt;p&gt;The Comet project welcomes new contributors. We use the same &lt;a href="https://datafusion.apache.org/contributor-guide/communication.html#slack-and-discord"&gt;Slack and Discord&lt;/a&gt; channels as the main DataFusion
project and have a weekly &lt;a href="https://docs.google.com/document/d/1NBpkIAuU7O9h8Br5CbFksDhX-L9TyO9wmGLPMe0Plc8/edit?usp=sharing"&gt;DataFusion video call&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The easiest way to get involved is to test Comet with your current Spark jobs and file issues for any bugs or
performance regressions that you find. See the &lt;a href="https://datafusion.apache.org/comet/user-guide/installation.html"&gt;Getting Started&lt;/a&gt; guide for instructions on downloading and installing
Comet.&lt;/p&gt;
&lt;p&gt;There are also many &lt;a href="https://github.com/apache/datafusion-comet/contribute"&gt;good first issues&lt;/a&gt; waiting for contributions.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Comparing approaches to User Defined Functions in Apache DataFusion using Python</title><link href="https://datafusion.apache.org/blog/blog/2024/11/19/datafusion-python-udf-comparisons" rel="alternate"></link><published>2024-11-19T00:00:00+00:00</published><updated>2024-11-19T00:00:00+00:00</updated><author><name>timsaucer</name></author><id>tag:datafusion.apache.org,2024-11-19:/blog/blog/2024/11/19/datafusion-python-udf-comparisons</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h2&gt;Personal Context&lt;/h2&gt;
&lt;p&gt;For a few months now I&amp;rsquo;ve been working with &lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt;, a
fast query engine written in Rust. From my experience the language that nearly all data scientists
are working in is Python. In general, data scientists often use &lt;a href="https://pandas.pydata.org/"&gt;Pandas&lt;/a&gt;
for in-memory tasks and &lt;a href="https://spark.apache.org/"&gt;PySpark&lt;/a&gt; for larger …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h2&gt;Personal Context&lt;/h2&gt;
&lt;p&gt;For a few months now I&amp;rsquo;ve been working with &lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt;, a
fast query engine written in Rust. From my experience the language that nearly all data scientists
are working in is Python. In general, data scientists often use &lt;a href="https://pandas.pydata.org/"&gt;Pandas&lt;/a&gt;
for in-memory tasks and &lt;a href="https://spark.apache.org/"&gt;PySpark&lt;/a&gt; for larger tasks that require
distributed processing.&lt;/p&gt;
&lt;p&gt;In addition to DataFusion, there is another Rust based newcomer to the DataFrame world,
&lt;a href="https://pola.rs/"&gt;Polars&lt;/a&gt;. The latter is growing extremely fast, and it serves many of the same
use cases as DataFusion. For my use cases, I'm interested in DataFusion because I want to be able
to build small scale tests rapidly and then scale them up to larger distributed systems with ease.
I do recommend evaluating Polars for in-memory work.&lt;/p&gt;
&lt;p&gt;Personally, I would love a single query approach that is fast for both in-memory usage and can
extend to large batch processing to exploit parallelization. I think DataFusion, coupled with
&lt;a href="https://datafusion.apache.org/ballista/"&gt;Ballista&lt;/a&gt; or
&lt;a href="https://github.com/apache/datafusion-ray"&gt;DataFusion-Ray&lt;/a&gt;, may provide this solution.&lt;/p&gt;
&lt;p&gt;As I&amp;rsquo;m testing, I&amp;rsquo;m primarily limiting my work to the
&lt;a href="https://datafusion.apache.org/python/"&gt;datafusion-python&lt;/a&gt; project, a wrapper around the Rust
DataFusion library. This wrapper gives you the speed advantages of keeping all of the data in the
Rust implementation and the ergonomics of working in Python. Personally, I would prefer to work
purely in Rust, but I also recognize that since the industry works in Python we should meet the
people where they are.&lt;/p&gt;
&lt;h2&gt;User-Defined Functions&lt;/h2&gt;
&lt;p&gt;The focus of this post is User-Defined Functions (UDFs). The DataFusion library gives a lot of
useful functions already for doing DataFrame manipulation. These are going to be similar to those
you find in other DataFrame libraries. You&amp;rsquo;ll be able to do simple arithmetic, create substrings of
columns, or find the average value across a group of rows. These cover most of the use cases
you&amp;rsquo;ll need in a DataFrame.&lt;/p&gt;
&lt;p&gt;However, there will always arise times when you want a custom function. With UDFs you open a
world of possibilities in your code. Sometimes there simply isn&amp;rsquo;t an easy way to use built-in
functions to achieve your goals.&lt;/p&gt;
&lt;p&gt;In the following, I&amp;rsquo;m going to demonstrate two example use cases. These are based on real world
problems I&amp;rsquo;ve encountered. Also I want to demonstrate the approach of &amp;ldquo;make it work, make it work
well, make it work fast&amp;rdquo; that is a motto I&amp;rsquo;ve seen thrown around in data science.&lt;/p&gt;
&lt;p&gt;I will demonstrate three approaches to writing UDFs. In order of increasing performance they are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Writing a pure Python function to do your computation&lt;/li&gt;
&lt;li&gt;Using the PyArrow libraries in Python to accelerate your processing&lt;/li&gt;
&lt;li&gt;Writing a UDF in Rust and exposing it to Python&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additionally I will demonstrate two variants of this. The first will be nearly identical to the
PyArrow library approach to simplify understanding how to connect the Rust code to Python. In the
second version we will do the iteration through the input arrays ourselves to give even greater
flexibility to the user.&lt;/p&gt;
&lt;p&gt;Here are the two example use cases, taken from my own work but generalized.&lt;/p&gt;
&lt;h3&gt;Use Case 1: Scalar Function&lt;/h3&gt;
&lt;p&gt;I have a DataFrame and a list of tuples that I&amp;rsquo;m interested in. I want to filter out the DataFrame
to only have values that match those tuples from certain columns in the DataFrame.&lt;/p&gt;
&lt;p&gt;To give a concrete example, we will use data generated for the &lt;a href="https://www.tpc.org/tpch/"&gt;TPC-H benchmarks&lt;/a&gt;.
Suppose I have a table of sales line items. There are many columns, but I am interested in three: a
part key (&lt;code&gt;p_partkey&lt;/code&gt;), supplier key (&lt;code&gt;p_suppkey&lt;/code&gt;), and return status (&lt;code&gt;p_returnflag&lt;/code&gt;). I want
only to return a DataFrame with a specific combination of these three values. That is, I want
to know if part number 1530 from supplier 4031 was sold (not returned), so I want a specific
combination of &lt;code&gt;p_partkey = 1530&lt;/code&gt;, &lt;code&gt;p_suppkey = 4031&lt;/code&gt;, and &lt;code&gt;p_returnflag = 'N'&lt;/code&gt;. I have a small
handful of these combinations I want to return.&lt;/p&gt;
&lt;p&gt;Probably the most ergonomic way to do this without UDF is to turn that list of tuples into a
DataFrame itself, perform a join, and select the columns from the original DataFrame. If we were
working in PySpark we would probably broadcast join the DataFrame created from the tuple list since
it is tiny. In practice, I have found that with some DataFrame libraries performing a filter rather
than a join can be significantly faster. This is worth profiling for your specific use case.&lt;/p&gt;
&lt;h3&gt;Use Case 2: Aggregate Function&lt;/h3&gt;
&lt;p&gt;I have a DataFrame with many values that I want to aggregate. I have already analyzed it and
determined there is a noise level below which I do not want to include in my analysis. I want to
compute a sum of only values that are above my noise threshold.&lt;/p&gt;
&lt;p&gt;This can be done fairly easy without leaning on a User Defined Aggegate Function (UDAF). You can
simply filter the DataFrame and then aggregate using the built-in &lt;code&gt;sum&lt;/code&gt; function. Here, we
demonstrate doing this as a UDF primarily as an example of how to write UDAFs. We will use the
PyArrow compute approach.&lt;/p&gt;
&lt;h2&gt;Pure Python approach&lt;/h2&gt;
&lt;p&gt;The fastest way (developer time, not code time) for me to implement the scalar problem solution
was to do something along the lines of &amp;ldquo;for each row, check the values of interest contains that
tuple&amp;rdquo;. I&amp;rsquo;ve published this as
&lt;a href="https://github.com/apache/datafusion-python/blob/main/examples/python-udf-comparisons.py"&gt;an example&lt;/a&gt;
in the &lt;a href="https://github.com/apache/datafusion-python"&gt;datafusion-python repository&lt;/a&gt;. Here is an
example of how this can be done:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1530&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4031&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"N"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;6530&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1531&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"N"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5618&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;619&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"N"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8118&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8119&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"N"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_of_interest_impl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;partkey_arr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;partkey&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partkey_arr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;partkey&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partkey&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_py&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;suppkey&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_py&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;returnflag&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_py&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partkey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;suppkey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;returnflag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Wrap our custom function with `datafusion.udf`, annotating expected &lt;/span&gt;
&lt;span class="c1"&gt;# parameter and return types&lt;/span&gt;
&lt;span class="n"&gt;is_of_interest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;udf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;is_of_interest_impl&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utf8&lt;/span&gt;&lt;span class="p"&gt;()],&lt;/span&gt;
    &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bool_&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="s2"&gt;"stable"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df_udf_filter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_lineitem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;is_of_interest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_partkey"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_suppkey"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_returnflag"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When working with a DataFusion UDF in Python, you define your function to take in some number of
expressions. During the evaluation, these will get computed into their corresponding values and
passed to your UDF as a PyArrow Array. We must return an Array also with the same number of
elements (rows). So the UDF example just iterates through all of the arrays and checks to see if
the tuple created from these columns matches any of those that we&amp;rsquo;re looking for.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll repeat because this is something that tripped me up the first time I wrote a UDF for
datafusion: &lt;strong&gt;DataFusion UDFs, even scalar UDFs, process an array of values at a time not a single
row.&lt;/strong&gt; This is different from some other DataFrame libraries and you may need to recognize a slight
change in mentality.&lt;/p&gt;
&lt;p&gt;Some important lines here are the lines like &lt;code&gt;partkey = partkey.as_py()&lt;/code&gt;. When we do this, we pay a
heavy cost. Now instead of keeping the analysis in the Rust code, we have to take the values in the
array and convert them over to Python objects. In this case we end up getting two numbers and a
string as real Python objects, complete with reference counting and all. Also we are iterating
through the array in Python rather than Rust native. These will &lt;strong&gt;significantly&lt;/strong&gt; slow down your
code. Any time you have to cross the barrier where you change values inside the Rust arrays into
Python objects or vice versa you will pay &lt;strong&gt;heavy&lt;/strong&gt; cost in that transformation. You will want to
design your UDFs to avoid this as much as possible.&lt;/p&gt;
&lt;h2&gt;Python approach using PyArrow compute&lt;/h2&gt;
&lt;p&gt;DataFusion uses &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; as its in-memory data format. This can
be seen in the way that Arrow Arrays are passed into the UDFs. We can take advantage of the fact
that &lt;a href="https://arrow.apache.org/docs/python/"&gt;PyArrow&lt;/a&gt;, the canonical Python Arrow implementation,
provides a variety of
useful functions. In the example below, we are only using a few of the boolean functions and the
equality function. Each of these functions takes two arrays and analyzes them row by row. In the
below example, we shift the logic around a little since we are now operating on an entire array of
values instead of checking a single row ourselves.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyarrow.compute&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pc&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;udf_using_pyarrow_compute_impl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;partkey_arr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;partkey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;suppkey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;returnflag&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;filtered_partkey_arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;partkey&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;filtered_suppkey_arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;suppkey&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;filtered_returnflag_arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;returnflag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;resultant_arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;and_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filtered_partkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filtered_suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;resultant_arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;and_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;resultant_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filtered_returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;resultant_arr&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;or_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;resultant_arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;


&lt;span class="n"&gt;udf_using_pyarrow_compute&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;udf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;udf_using_pyarrow_compute_impl&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utf8&lt;/span&gt;&lt;span class="p"&gt;()],&lt;/span&gt;
    &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bool_&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="s2"&gt;"stable"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df_udf_pyarrow_compute&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_lineitem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;udf_using_pyarrow_compute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_partkey"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_suppkey"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_returnflag"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The idea in the code above is that we will iterate through each of the values of interest, which we
expect to be small. For each of the columns, we compare the value of interest to it&amp;rsquo;s corresponding
array using &lt;code&gt;pyarrow.compute.equal&lt;/code&gt;. This will give use three boolean arrays. We have a match to
the tuple if we have a row in all three arrays that is true, so we use &lt;code&gt;pyarrow.compute.and_&lt;/code&gt;. Now
our return value from the UDF needs to include arrays for which any of the values of interest list
of tuples exists, so we take the result from the current loop and perform a &lt;code&gt;pyarrow.compute.or_&lt;/code&gt;
on it.&lt;/p&gt;
&lt;p&gt;From my benchmarking, switching from approach of converting values into Python objects to this
approach of using the PyArrow built-in functions leads to about a 10x speed improvement in this
simple problem.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s worth noting that almost all of the PyArrow compute functions expect to take one or two arrays
as their arguments. If you need to write a UDF that is evaluating three or more columns, you&amp;rsquo;ll
need to do something akin to what we&amp;rsquo;ve shown here.&lt;/p&gt;
&lt;h2&gt;Rust UDF with Python wrapper&lt;/h2&gt;
&lt;p&gt;This is the most complicated approach, but has the potential to be the most performant. What we
will do here is write a Rust function to perform our computation and then expose that function to
Python. I know of two use cases where I would recommend this approach. The first is the case when
the PyArrow compute functions are insufficient for your needs. Perhaps your code is too complex or
could be greatly simplified if you pulled in some outside dependency. The second use case is when
you have written a UDF that you&amp;rsquo;re sharing across multiple projects and have hardened the approach.
It is possible that you can implement your function in Rust to give a speed improvement and then
every project that is using this shared UDF will benefit from those updates.&lt;/p&gt;
&lt;p&gt;When deciding to use this approach, it&amp;rsquo;s worth considering how much you think you&amp;rsquo;ll actually
benefit from the Rust implementation to decide if it&amp;rsquo;s worth the additional effort to maintain and
deploy the Python wheels you generate. It is certainly not necessary for every use case.&lt;/p&gt;
&lt;p&gt;Due to the excellent work by the Python arrow team, we can simplify our work to needing only two
dependencies on the Rust side, &lt;a href="https://github.com/apache/arrow-rs"&gt;arrow-rs&lt;/a&gt; and
&lt;a href="https://pyo3.rs/"&gt;pyo3&lt;/a&gt;. I have posted a &lt;a href="https://github.com/timsaucer/tuple_filter_example"&gt;minimal example&lt;/a&gt;.
You&amp;rsquo;ll need &lt;a href="https://github.com/PyO3/maturin"&gt;maturin&lt;/a&gt; to build the project, and you must use
release mode when building to get the expected performance.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;maturin develop --release
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When you write your UDF in Rust you generally will need to take these steps&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write a function description that takes in some number of Python generic objects.&lt;/li&gt;
&lt;li&gt;Convert these objects to Arrow Arrays of the appropriate type(s).&lt;/li&gt;
&lt;li&gt;Perform your computation and create a resultant Array.&lt;/li&gt;
&lt;li&gt;Convert the array into a Python generic object.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the conversion to and from Python objects, we can take advantage of the
&lt;code&gt;ArrayData::from_pyarrow_bound&lt;/code&gt; and &lt;code&gt;ArrayData::to_pyarrow&lt;/code&gt; functions.  All that remains is to
perform your computation.&lt;/p&gt;
&lt;p&gt;We are going to demonstrate doing this computation in two ways. The first is to mimic what we&amp;rsquo;ve
done in the above approach using PyArrow. In the second we demonstrate iterating through the three
arrays ourselves.&lt;/p&gt;
&lt;p&gt;In our first approach, we can expect the performance to be nearly identical to when we used the
PyArrow compute functions. On the Rust side we will have slightly less overhead but the heavy
lifting portions of the code are essentially the same between this Rust implementation and the
PyArrow approach above.&lt;/p&gt;
&lt;p&gt;The reason for demonstrating this, even though it doesn&amp;rsquo;t provide a significant speedup over
Python, is to primarily demonstrate how to make the Python to Rust with Python wrapper
transition. In the second implementation you can see how we can iterate through all of the arrays
ourselves.&lt;/p&gt;
&lt;p&gt;In this first example, we are hard coding the values of interest, but in the following section
we demonstrate passing these in during initalization.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="cp"&gt;#[pyfunction]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;pub&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;tuple_filter_fn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;: &lt;span class="nc"&gt;Python&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;partkey_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;suppkey_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;returnflag_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt; &lt;span class="nc"&gt;PyResult&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Py&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;partkey_arr&lt;/span&gt;: &lt;span class="nc"&gt;PrimitiveArray&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Int64Type&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partkey_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;suppkey_arr&lt;/span&gt;: &lt;span class="nc"&gt;PrimitiveArray&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Int64Type&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suppkey_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;returnflag_arr&lt;/span&gt;: &lt;span class="nc"&gt;StringArray&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;returnflag_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;vec&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1530&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4031&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"N"&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;6530&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1531&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"N"&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5618&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;619&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"N"&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8118&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8119&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"N"&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;mut&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;: &lt;span class="nb"&gt;Option&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;BooleanArray&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;None&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partkey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;suppkey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;returnflag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;filtered_partkey_arr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;BooleanArray&lt;/span&gt;::&lt;span class="n"&gt;from_unary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;partkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;partkey&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;filtered_suppkey_arr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;BooleanArray&lt;/span&gt;::&lt;span class="n"&gt;from_unary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;suppkey&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;filtered_returnflag_arr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;BooleanArray&lt;/span&gt;::&lt;span class="n"&gt;from_unary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;returnflag&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;part_and_supp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;::&lt;span class="n"&gt;and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;filtered_partkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;filtered_suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map_err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyValueError&lt;/span&gt;::&lt;span class="n"&gt;new_err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;resultant_arr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;::&lt;span class="n"&gt;and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;part_and_supp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;filtered_returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map_err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyValueError&lt;/span&gt;::&lt;span class="n"&gt;new_err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;match&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="nb"&gt;Some&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;::&lt;span class="n"&gt;or&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;resultant_arr&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;ok&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="nb"&gt;None&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;Some&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;resultant_arr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;into_data&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;to_pyarrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;


&lt;span class="cp"&gt;#[pymodule]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;tuple_filter_example&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyModule&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt; &lt;span class="nc"&gt;PyResult&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wrap_pyfunction&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tuple_filter_fn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;Ok&lt;/span&gt;&lt;span class="p"&gt;(())&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To use this we use the &lt;code&gt;udf&lt;/code&gt; function in &lt;code&gt;datafusion-python&lt;/code&gt; just as before.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datafusion&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;udf&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyarrow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pa&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tuple_filter_example&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tuple_filter_fn&lt;/span&gt;

&lt;span class="n"&gt;udf_using_custom_rust_fn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;udf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tuple_filter_fn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utf8&lt;/span&gt;&lt;span class="p"&gt;()],&lt;/span&gt;
    &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bool_&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="s2"&gt;"stable"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's it! We've now got a third party Rust UDF with Python wrappers working with DataFusion's
Python bindings!&lt;/p&gt;
&lt;h3&gt;Rust UDF with initialization&lt;/h3&gt;
&lt;p&gt;Looking at the code above, you can see that it is hard coding the values we're interested in. There
are many types of UDFs that don't require any additional data provided to them before they start
the computation. The code above is sloppy, so let's clean it up.&lt;/p&gt;
&lt;p&gt;We want to write the function to take some additional data. A limitation of the UDFs we create is
that they expect to operate on entire arrays of data at a time. We can get around this problem by
creating an initializer for our UDF. We do this by defining a Rust struct that contains the data we
need and implement two methods on this struct, &lt;code&gt;new&lt;/code&gt; and &lt;code&gt;__call__&lt;/code&gt;. By doing this we will create a
Python object that is callable, so it can be the function we provide to &lt;code&gt;udf&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="cp"&gt;#[pyclass]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;pub&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nc"&gt;TupleFilterClass&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;: &lt;span class="nb"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;String&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="cp"&gt;#[pymethods]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;impl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;TupleFilterClass&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="cp"&gt;#[new]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;: &lt;span class="nb"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;String&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt; &lt;span class="nc"&gt;Self&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="bp"&gt;Self&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;__call__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;: &lt;span class="nc"&gt;Python&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;partkey_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;suppkey_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;returnflag_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt; &lt;span class="nc"&gt;PyResult&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Py&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;partkey_arr&lt;/span&gt;: &lt;span class="nc"&gt;PrimitiveArray&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Int64Type&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partkey_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;suppkey_arr&lt;/span&gt;: &lt;span class="nc"&gt;PrimitiveArray&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Int64Type&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suppkey_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;returnflag_arr&lt;/span&gt;: &lt;span class="nc"&gt;StringArray&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;returnflag_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;mut&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;: &lt;span class="nb"&gt;Option&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;BooleanArray&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;None&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partkey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;suppkey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;returnflag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;filtered_partkey_arr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;BooleanArray&lt;/span&gt;::&lt;span class="n"&gt;from_unary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;partkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;partkey&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;filtered_suppkey_arr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;BooleanArray&lt;/span&gt;::&lt;span class="n"&gt;from_unary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;suppkey&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;filtered_returnflag_arr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;BooleanArray&lt;/span&gt;::&lt;span class="n"&gt;from_unary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;returnflag&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;part_and_supp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;::&lt;span class="n"&gt;and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;filtered_partkey_arr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;filtered_suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map_err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyValueError&lt;/span&gt;::&lt;span class="n"&gt;new_err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;resultant_arr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;::&lt;span class="n"&gt;and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;part_and_supp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;filtered_returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map_err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyValueError&lt;/span&gt;::&lt;span class="n"&gt;new_err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;match&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="nb"&gt;Some&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;::&lt;span class="n"&gt;or&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;resultant_arr&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;ok&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="nb"&gt;None&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;Some&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;resultant_arr&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;into_data&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;to_pyarrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="cp"&gt;#[pymodule]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;tuple_filter_example&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyModule&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt; &lt;span class="nc"&gt;PyResult&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_class&lt;/span&gt;::&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;TupleFilterClass&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;Ok&lt;/span&gt;&lt;span class="p"&gt;(())&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When you write this, you don't have to call your constructor &lt;code&gt;new&lt;/code&gt;. The more important part is that
you have &lt;code&gt;#[new]&lt;/code&gt; designated on the function. With this you can provide any kinds of data you need
during processing. Using this initializer in Python is fairly straightforward.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datafusion&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;udf&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyarrow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pa&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tuple_filter_example&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TupleFilterClass&lt;/span&gt;

&lt;span class="n"&gt;tuple_filter_class&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TupleFilterClass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;udf_using_custom_rust_fn_with_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;udf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tuple_filter_class&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utf8&lt;/span&gt;&lt;span class="p"&gt;()],&lt;/span&gt;
    &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bool_&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="s2"&gt;"stable"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"tuple_filter_with_data"&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When you use this approach you will need to provide a &lt;code&gt;name&lt;/code&gt; argument to &lt;code&gt;udf&lt;/code&gt;. This is because our
class/struct does not get the &lt;code&gt;__qualname__&lt;/code&gt; attribute that the &lt;code&gt;udf&lt;/code&gt; function is looking for. You
can give this udf any name you choose.&lt;/p&gt;
&lt;h3&gt;Rust UDF with direct iteration&lt;/h3&gt;
&lt;p&gt;The final version of our scalar UDF is one where we implement it in Rust and iterate through all of
the arrays ourselves. If you are iterating through more than 3 arrays at a time I recommend looking
at &lt;a href="https://docs.rs/itertools/latest/itertools/macro.izip.html"&gt;izip&lt;/a&gt; in the
&lt;a href="https://crates.io/crates/itertools"&gt;itertools crate&lt;/a&gt;. For ease of understanding and since we only
have 3 arrays here I will just explicitly create my own tuple here.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="cp"&gt;#[pyclass]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;pub&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nc"&gt;TupleFilterDirectIterationClass&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;: &lt;span class="nb"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;String&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="cp"&gt;#[pymethods]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;impl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;TupleFilterDirectIterationClass&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="cp"&gt;#[new]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;: &lt;span class="nb"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;String&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt; &lt;span class="nc"&gt;Self&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="bp"&gt;Self&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;__call__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;: &lt;span class="nc"&gt;Python&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;partkey_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;suppkey_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;returnflag_expr&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;Bound&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;'_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt; &lt;span class="nc"&gt;PyResult&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Py&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;PyAny&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;partkey_arr&lt;/span&gt;: &lt;span class="nc"&gt;PrimitiveArray&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Int64Type&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partkey_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;suppkey_arr&lt;/span&gt;: &lt;span class="nc"&gt;PrimitiveArray&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Int64Type&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suppkey_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;returnflag_arr&lt;/span&gt;: &lt;span class="nc"&gt;StringArray&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ArrayData&lt;/span&gt;::&lt;span class="n"&gt;from_pyarrow_bound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;returnflag_expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;values_to_search&lt;/span&gt;: &lt;span class="nb"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="kt"&gt;i64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="kt"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values_of_interest&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_str&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collect&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;partkey_arr&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suppkey_arr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;returnflag_arr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unwrap_or_default&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;values_to_search&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;contains&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;: &lt;span class="nc"&gt;BooleanArray&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;BooleanBuffer&lt;/span&gt;::&lt;span class="n"&gt;from_iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;into&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;into_data&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;to_pyarrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We convert the &lt;code&gt;values_of_interest&lt;/code&gt; into a vector of borrowed types so that we can do a fast search
without creating additional memory. The other option is to turn the &lt;code&gt;returnflag&lt;/code&gt; into a &lt;code&gt;String&lt;/code&gt;
but that memory allocation is unnecessary. After that we use two &lt;code&gt;zip&lt;/code&gt; operations so that we can
iterate over all three columns in a single pass. Since each &lt;code&gt;zip&lt;/code&gt; will return a tuple of two
elements, a quick &lt;code&gt;map&lt;/code&gt; turns them into the tuple format we need. Also, &lt;code&gt;StringArray&lt;/code&gt; is a little
different in the buffer it uses, so it is treated slightly differently from the others.&lt;/p&gt;
&lt;h2&gt;User Defined Aggregate Function&lt;/h2&gt;
&lt;p&gt;Writing a user defined aggregate function or user defined window function is slightly more complex
than scalar functions. This is because we must accumulate values and there is no guarantee that one
batch will contain all the values we are aggregating over. For this we need to define an
&lt;code&gt;Accumulator&lt;/code&gt; which will do a few things.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Process a batch and compute an internal state&lt;/li&gt;
&lt;li&gt;Share the state so that we can combine multiple batches&lt;/li&gt;
&lt;li&gt;Merge the results across multiple batches&lt;/li&gt;
&lt;li&gt;Return the final result&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the example below, we're going to look at customer orders and we want to know per customer ID,
how much they have ordered total. We want to ignore small orders, which we define as anything under
5000.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datafusion&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Accumulator&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;udaf&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyarrow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pa&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyarrow.compute&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pc&lt;/span&gt;

&lt;span class="n"&gt;IGNORE_THESHOLD&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;5000.0&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;AboveThresholdAccum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Accumulator&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;over_threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;greater&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IGNORE_THESHOLD&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;sum_above&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;over_threshold&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_py&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sum_above&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sum_above&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_sum&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;sum_above&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;states&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_sum&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;states&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_py&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;state&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_sum&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_sum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;sum_above_threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;udaf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AboveThresholdAccum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="p"&gt;()],&lt;/span&gt; &lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="p"&gt;()],&lt;/span&gt; &lt;span class="s1"&gt;'stable'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df_orders&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;aggregate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"o_custkey"&lt;/span&gt;&lt;span class="p"&gt;)],[&lt;/span&gt;&lt;span class="n"&gt;sum_above_threshold&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"o_totalprice"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;alias&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"sales"&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since we are doing a &lt;code&gt;sum&lt;/code&gt; we can keep a single value as our internal state. When we call &lt;code&gt;update()&lt;/code&gt;
we will process a single array and update the internal state, which we share with the &lt;code&gt;state()&lt;/code&gt;
function. For larger batches we may &lt;code&gt;merge()&lt;/code&gt; these states. It is important to note that the
&lt;code&gt;states&lt;/code&gt; in the &lt;code&gt;merge()&lt;/code&gt; function are an array of the values returned from &lt;code&gt;state()&lt;/code&gt;. It is
entirely possible that the &lt;code&gt;merge&lt;/code&gt; function is significantly different than the &lt;code&gt;update&lt;/code&gt;, though in
our example they are very similar.&lt;/p&gt;
&lt;p&gt;One example of implementing a user defined aggregate function where the &lt;code&gt;update()&lt;/code&gt; and &lt;code&gt;merge()&lt;/code&gt;
operations are different is computing an average. In &lt;code&gt;update()&lt;/code&gt; we would create a state that is both
a sum and a count. &lt;code&gt;state()&lt;/code&gt; would return a list of these two values, and &lt;code&gt;merge()&lt;/code&gt; would compute
the final result.&lt;/p&gt;
&lt;h2&gt;User Defined Window Functions&lt;/h2&gt;
&lt;p&gt;Writing a user defined window function is slightly more complex than an aggregate function due
to the variety of ways that window functions are called. I recommend reviewing the
&lt;a href="https://datafusion.apache.org/python/user-guide/common-operations/udf-and-udfa.html"&gt;online documentation&lt;/a&gt;
for a description of which functions need to be implemented. The details of how to implement
these generally follow the same patterns as described above for aggregate functions.&lt;/p&gt;
&lt;h2&gt;Performance Comparison&lt;/h2&gt;
&lt;p&gt;For the scalar functions above, we performed a timing evaluation, repeating the operation 100
times. For this simple example these are our results.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;+-----------------------------+--------------+---------+&lt;/span&gt;
&lt;span class="err"&gt;| approach                    | Average Time | Std Dev |&lt;/span&gt;
&lt;span class="err"&gt;+-----------------------------+--------------+---------+&lt;/span&gt;
&lt;span class="err"&gt;| python udf                  | 4.969        | 0.062   |&lt;/span&gt;
&lt;span class="err"&gt;| simple filter               | 1.075        | 0.022   |&lt;/span&gt;
&lt;span class="err"&gt;| explicit filter             | 0.685        | 0.063   |&lt;/span&gt;
&lt;span class="err"&gt;| pyarrow compute             | 0.529        | 0.017   |&lt;/span&gt;
&lt;span class="err"&gt;| arrow rust compute          | 0.511        | 0.034   |&lt;/span&gt;
&lt;span class="err"&gt;| arrow rust compute as class | 0.502        | 0.011   |&lt;/span&gt;
&lt;span class="err"&gt;| rust custom iterator        | 0.478        | 0.009   |&lt;/span&gt;
&lt;span class="err"&gt;+-----------------------------+--------------+---------+&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As expected, the conversion to Python objects is by far the worst performance. As soon as we drop
into using any functions that keep the data entirely on the Native (Rust or C/C++) side we see a
near 10x speed improvement. Then as we increase our complexity from using PyArrow compute functions
to implementing the UDF in Rust we see incremental improvements. Our fastest approach - iterating
through the arrays ourselves does operate nearly 10% faster than the PyArrow compute approach.&lt;/p&gt;
&lt;h2&gt;Final Thoughts and Recommendations&lt;/h2&gt;
&lt;p&gt;For anyone who is curious about &lt;a href="https://datafusion.apache.org/"&gt;DataFusion&lt;/a&gt; I highly recommend
giving it a try. This post was designed to make it easier for new users to the Python implementation
to work with User Defined Functions by giving a few examples of how one might implement these.&lt;/p&gt;
&lt;p&gt;When it comes to designing UDFs, I strongly recommend seeing if you can write your UDF using
&lt;a href="https://arrow.apache.org/docs/python/api/compute.html"&gt;PyArrow functions&lt;/a&gt; rather than pure Python
objects. As shown in the scalar example above, you can achieve a 10x speedup by using PyArrow
functions. If you must do something that isn't well represented by the PyArrow compute functions,
then I would consider using a Rust based UDF in the manner shown above.&lt;/p&gt;
&lt;p&gt;I would like to thank &lt;a href="https://github.com/alamb"&gt;@alamb&lt;/a&gt;, &lt;a href="https://github.com/andygrove"&gt;@andygrove&lt;/a&gt;, &lt;a href="https://github.com/comphead"&gt;@comphead&lt;/a&gt;, &lt;a href="https://github.com/emgeee"&gt;@emgeee&lt;/a&gt;, &lt;a href="https://github.com/kylebarron"&gt;@kylebarron&lt;/a&gt;, and &lt;a href="https://github.com/Omega359"&gt;@Omega359&lt;/a&gt;
for their helpful reviews and feedback.&lt;/p&gt;
&lt;p&gt;Lastly, the Apache Arrow and DataFusion community is an active group of very helpful people working
to make a great tool. If you want to get involved, please take a look at the
&lt;a href="https://datafusion.apache.org/python/"&gt;online documentation&lt;/a&gt; and jump in to help with one of the
&lt;a href="https://github.com/apache/datafusion-python/issues"&gt;open issues&lt;/a&gt;.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache DataFusion is now the fastest single node engine for querying Apache Parquet files</title><link href="https://datafusion.apache.org/blog/blog/2024/11/18/datafusion-fastest-single-node-parquet-clickbench" rel="alternate"></link><published>2024-11-18T00:00:00+00:00</published><updated>2024-11-18T00:00:00+00:00</updated><author><name>Andrew Lamb, Staff Engineer at InfluxData</name></author><id>tag:datafusion.apache.org,2024-11-18:/blog/blog/2024/11/18/datafusion-fastest-single-node-parquet-clickbench</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;I am extremely excited to announce that &lt;a href="https://crates.io/crates/datafusion"&gt;Apache DataFusion&lt;/a&gt;  is the
fastest engine for querying Apache Parquet files in &lt;a href="https://benchmark.clickhouse.com/"&gt;ClickBench&lt;/a&gt;. It is faster
than &lt;a href="https://duckdb.org/"&gt;DuckDB&lt;/a&gt;, &lt;a href="https://clickhouse.com/chdb"&gt;chDB&lt;/a&gt; and &lt;a href="https://clickhouse.com/"&gt;Clickhouse&lt;/a&gt; using the same hardware. It also marks
the first time a &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;-based engine holds the top spot, which has previously
been …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;I am extremely excited to announce that &lt;a href="https://crates.io/crates/datafusion"&gt;Apache DataFusion&lt;/a&gt;  is the
fastest engine for querying Apache Parquet files in &lt;a href="https://benchmark.clickhouse.com/"&gt;ClickBench&lt;/a&gt;. It is faster
than &lt;a href="https://duckdb.org/"&gt;DuckDB&lt;/a&gt;, &lt;a href="https://clickhouse.com/chdb"&gt;chDB&lt;/a&gt; and &lt;a href="https://clickhouse.com/"&gt;Clickhouse&lt;/a&gt; using the same hardware. It also marks
the first time a &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;-based engine holds the top spot, which has previously
been held by traditional C/C++-based engines.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Apache DataFusion Logo" class="img-responsive" src="../images/2x_bgwhite_original.png" width="80%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="ClickBench performance for DataFusion 43.0.0" class="img-responsive" src="../images/clickbench-datafusion-43/perf.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;: 2024-11-16 &lt;a href="https://benchmark.clickhouse.com/#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"&gt;ClickBench Results&lt;/a&gt; for the  &amp;lsquo;hot&amp;rsquo;[^1] run against the
partitioned 14 GB Parquet dataset (100 files, each ~140MB) on a &lt;code&gt;c6a.4xlarge&lt;/code&gt; (16
CPU / 32 GB  RAM) VM. Measurements are relative (&lt;code&gt;1.x&lt;/code&gt;) to results using
different hardware.&lt;/p&gt;
&lt;p&gt;Best in class performance on Parquet is now available to anyone. DataFusion&amp;rsquo;s
open design lets you start quickly with a full featured Query Engine, including
SQL, data formats, catalogs, and more, and then customize any behavior you need.
I predict the continued emergence of new classes of data systems now that
creators can focus the bulk of their innovation on areas such as query
languages, system integrations, and data formats rather than trying to play
catchup with core engine performance.&lt;/p&gt;
&lt;p&gt;ClickBench also includes results for proprietary storage formats, which require
costly load / export steps, making them useful in fewer use cases and thus much
less important than open formats (though the idea of use case specific formats
is interesting[^2]).&lt;/p&gt;
&lt;p&gt;This blog post highlights some of the techniques we used to achieve this
performance, and celebrates the teamwork involved.&lt;/p&gt;
&lt;h1&gt;A Strong History of Performance Improvements&lt;/h1&gt;
&lt;p&gt;Performance has long been a core focus for DataFusion's community, and 
speed attracts users and contributors. Recently, we seem to have been
even more focused on performance, including in July, 2024 when &lt;a href="https://www.linkedin.com/in/mehmet-ozan-kabak/"&gt;Mehmet Ozan
Kabak&lt;/a&gt;, CEO of &lt;a href="https://www.synnada.ai/"&gt;Synnada&lt;/a&gt;, again &lt;a href="https://github.com/apache/datafusion/issues/11442#issuecomment-2226834443"&gt;suggested focusing on performance&lt;/a&gt;. This
got many of us excited (who doesn&amp;rsquo;t love a challenge!), and we have subsequently
rallied to steadily improve the performance release on release as shown in
Figure 2.&lt;/p&gt;
&lt;p&gt;&lt;img alt="ClickBench performance results over time for DataFusion" class="img-responsive" src="../images/clickbench-datafusion-43/perf-over-time.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt;: ClickBench performance improved over 30% between DataFusion 34
(released Dec. 2023) and DataFusion 43 (released Nov. 2024).&lt;/p&gt;
&lt;p&gt;Like all good optimization efforts, ours took sustained effort as DataFusion ran
out of &lt;a href="https://www.influxdata.com/blog/aggregating-millions-groups-fast-apache-arrow-datafusion"&gt;single 2x performance improvements&lt;/a&gt; several years ago. Working together our
community of engineers from around the world[^3] and all experience levels[^4]
pulled it off (check out &lt;a href="https://github.com/apache/datafusion/issues/12821"&gt;this discussion&lt;/a&gt; to get a sense). It may be a "&lt;a href="https://db.cs.cmu.edu/seminar2024/"&gt;hobo
sandwich&lt;/a&gt;" [^5], but it is a tasty one!&lt;/p&gt;
&lt;p&gt;Of course, most of these techniques have been implemented and described before,
but until now they were only available in proprietary systems such as
&lt;a href="https://www.vertica.com/"&gt;Vertica&lt;/a&gt;, &lt;a href="https://www.databricks.com/product/photon"&gt;DataBricks
Photon&lt;/a&gt;, or
&lt;a href="https://www.snowflake.com/en/"&gt;Snowflake&lt;/a&gt; or in tightly integrated open source
systems such as &lt;a href="https://duckdb.org/"&gt;DuckDB&lt;/a&gt; or
&lt;a href="https://clickhouse.com/"&gt;ClickHouse&lt;/a&gt; which were not designed to be extended.&lt;/p&gt;
&lt;h2&gt;StringView&lt;/h2&gt;
&lt;p&gt;Performance improved for all queries when DataFusion switched to using Arrow
&lt;code&gt;StringView&lt;/code&gt;. Using &lt;code&gt;StringView&lt;/code&gt; &amp;ldquo;just&amp;rdquo; saves some copies and avoids one memory
access for certain comparisons. However, these copies and comparisons happen to
occur in many of the hottest loops during query processing, so optimizing them
resulted in measurable performance improvements.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Illustration of how take works with StringView" class="img-responsive" src="../images/clickbench-datafusion-43/string-view-take.png" width="80%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; Figure from &lt;a href="https://www.influxdata.com/blog/faster-queries-with-stringview-part-one-influxdb/"&gt;Using StringView / German Style Strings to Make
Queries Faster: Part 1&lt;/a&gt; showing how &lt;code&gt;StringView&lt;/code&gt; saves copying data in many cases.&lt;/p&gt;
&lt;p&gt;Using StringView to make DataFusion faster for ClickBench required substantial
careful, low level optimization work described in &lt;a href="https://www.influxdata.com/blog/faster-queries-with-stringview-part-one-influxdb/"&gt;Using StringView / German
Style Strings to Make Queries Faster: Part 1&lt;/a&gt; and &lt;a href="https://www.influxdata.com/blog/faster-queries-with-stringview-part-two-influxdb/"&gt;Part 2&lt;/a&gt;. However, it &lt;em&gt;also&lt;/em&gt;
required extending the rest of DataFusion&amp;rsquo;s operations to support the new type.
You can get a sense of the magnitude of the work required by looking at the 100+
pull requests linked to the epic in arrow-rs
(&lt;a href="https://github.com/apache/arrow-rs/issues/5374"&gt;here&lt;/a&gt;) and three major epics
(&lt;a href="https://github.com/apache/datafusion/issues/10918"&gt;here&lt;/a&gt;,
&lt;a href="https://github.com/apache/datafusion/issues/11790"&gt;here&lt;/a&gt; and
&lt;a href="https://github.com/apache/datafusion/issues/11752"&gt;here&lt;/a&gt;) in DataFusion.&lt;/p&gt;
&lt;p&gt;Here is a partial list of people involved in the project (I am sorry to those whom I forgot)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Arrow&lt;/strong&gt;:  &lt;a href="https://github.com/XiangpengHao"&gt;Xiangpeng Hao&lt;/a&gt; (InfluxData&amp;rsquo;s amazing 2024 summer intern and UW Madison PhD), &lt;a href="https://github.com/ariesdevil"&gt;Yijun Zhao&lt;/a&gt; from DataBend Labs, and &lt;a href="https://github.com/tustvold"&gt;Raphael Taylor-Davies&lt;/a&gt; laid the foundation.  &lt;a href="https://github.com/RinChanNOWWW"&gt;RinChanNOW&lt;/a&gt; from Tencent and &lt;a href="https://github.com/a10y"&gt;Andrew Duffy&lt;/a&gt; from SpiralDB helped push it along in the early days, and &lt;a href="https://github.com/viirya"&gt;Liang-Chi Hsieh&lt;/a&gt;, &lt;a href="https://github.com/Dandandan"&gt;Dani&amp;euml;l Heres&lt;/a&gt; reviewed and provided guidance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DataFusion&lt;/strong&gt;:  &lt;a href="https://github.com/XiangpengHao"&gt;Xiangpeng Hao&lt;/a&gt;, again charted the initial path and &lt;a href="https://github.com/Weijun-H"&gt;Weijun Huang&lt;/a&gt;, &lt;a href="https://github.com/dharanad"&gt;Dharan Aditya&lt;/a&gt; &lt;a href="https://github.com/Lordworms"&gt;Lordworms&lt;/a&gt;, &lt;a href="https://github.com/goldmedal"&gt;Jax Liu&lt;/a&gt;,  &lt;a href="https://github.com/wiedld"&gt;wiedld&lt;/a&gt;, &lt;a href="https://github.com/tlm365"&gt;Tai Le Manh&lt;/a&gt;, &lt;a href="https://github.com/my-vegetable-has-exploded"&gt;yi wang&lt;/a&gt;, &lt;a href="https://github.com/doupache"&gt;doupache&lt;/a&gt;, &lt;a href="https://github.com/jayzhan211"&gt;Jay Zhan&lt;/a&gt; , &lt;a href="https://github.com/xinlifoobar"&gt;Xin Li&lt;/a&gt;  and &lt;a href="https://github.com/Kev1n8"&gt;Kaifeng Zheng&lt;/a&gt; made it real.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DataFusion String Function Migration&lt;/strong&gt;:  &lt;a href="https://github.com/tshauck"&gt;Trent Hauck&lt;/a&gt; organized the effort and set the patterns, &lt;a href="https://github.com/goldmedal"&gt;Jax Liu&lt;/a&gt; made a clever testing framework, and &lt;a href="https://github.com/austin362667"&gt;Austin Liu&lt;/a&gt;, &lt;a href="https://github.com/demetribu"&gt;Dmitrii Bu&lt;/a&gt;, &lt;a href="https://github.com/tlm365"&gt;Tai Le Manh&lt;/a&gt;, &lt;a href="https://github.com/PsiACE"&gt;Chojan Shang&lt;/a&gt;, &lt;a href="https://github.com/devanbenz"&gt;WeblWabl&lt;/a&gt;, &lt;a href="https://github.com/Lordworms"&gt;Lordworms&lt;/a&gt;, &lt;a href="https://github.com/thinh2"&gt;iamthinh&lt;/a&gt;, &lt;a href="https://github.com/Omega359"&gt;Bruce Ritchie&lt;/a&gt;, &lt;a href="https://github.com/Kev1n8"&gt;Kaifeng Zheng&lt;/a&gt;, and &lt;a href="https://github.com/xinlifoobar"&gt;Xin Li&lt;/a&gt; bashed out the conversions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Parquet&lt;/h2&gt;
&lt;p&gt;Part of the reason for DataFusion's speed in ClickBench is reading Parquet files (really) quickly,
which reflects invested effort in the Parquet reading system (see &lt;a href="https://www.influxdata.com/blog/querying-parquet-millisecond-latency/"&gt;Querying
Parquet with Millisecond Latency&lt;/a&gt; )&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://docs.rs/datafusion/latest/datafusion/datasource/physical_plan/parquet/struct.ParquetExec.html"&gt;DataFusion ParquetExec&lt;/a&gt; (built on the &lt;a href="https://crates.io/crates/parquet"&gt;Rust Parquet Implementation&lt;/a&gt;) is now the most
sophisticated open source Parquet reader I know of. It has every optimization we
can think of for reading Parquet, including projection pushdown, predicate
pushdown (row group metadata, page index, and bloom filters), limit pushdown,
parallel reading, interleaved I/O, and late materialized filtering (coming soon &amp;trade;️
by default). Some recent work from &lt;a href="https://github.com/itsjunetime"&gt;June&lt;/a&gt;
&lt;a href="https://github.com/apache/datafusion/pull/12135"&gt;recently unblocked a remaining hurdle&lt;/a&gt; for enabling late materialized
filtering, and conveniently &lt;a href="https://github.com/XiangpengHao"&gt;Xiangpeng Hao&lt;/a&gt; is
working on the &lt;a href="https://github.com/apache/arrow-datafusion/issues/3463"&gt;final piece&lt;/a&gt; (no pressure😅)&lt;/p&gt;
&lt;h2&gt;Skipping Partial Aggregation When It Doesn't Help&lt;/h2&gt;
&lt;p&gt;Many ClickBench queries are aggregations that summarize millions of rows, a
common task for reporting and dashboarding. DataFusion uses state of the art
&lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/trait.Accumulator.html#tymethod.state"&gt;two phase aggregation&lt;/a&gt; plans. Normally, two phase aggregation works well as the
first phase consolidates many rows immediately after reading, while the data is
still in cache. However, for certain &amp;ldquo;high cardinality&amp;rdquo; aggregate queries (that
have large numbers of groups), &lt;a href="https://github.com/apache/datafusion/issues/6937"&gt;the two phase aggregation strategy used in
DataFusion was inefficient&lt;/a&gt;,
manifesting in relatively slower performance compared to other engines for
ClickBench queries such as&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="ss"&gt;"WatchID"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;"ClientIP"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; 
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;hits&lt;/span&gt; 
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="ss"&gt;"WatchID"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;"ClientIP"&lt;/span&gt; &lt;span class="cm"&gt;/* &amp;lt;----- 13M Distinct Groups!!! */&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt; 
&lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For such queries, the first aggregation phase does not significantly
reduce the number of rows, which wastes significant effort. &lt;a href="https://github.com/korowa"&gt;Eduard
Karacharov&lt;/a&gt; contributed a &lt;a href="https://github.com/apache/datafusion/pull/11627"&gt;dynamic strategy&lt;/a&gt; to
bypass the first phase when it is not working efficiently, shown in Figure 4.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Two phase aggregation diagram from DataFusion API docs annotated to show first phase not helping" class="img-responsive" src="../images/clickbench-datafusion-43/skipping-partial-aggregation.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt;: Diagram from &lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/trait.Accumulator.html#tymethod.state"&gt;DataFusion API docs&lt;/a&gt; showing when the multi-phase
grouping is not effective&lt;/p&gt;
&lt;h2&gt;Optimized Multi-Column Grouping&lt;/h2&gt;
&lt;p&gt;Another method for improving analytic database performance is specialized (aka
highly optimized) versions of operations for different data types, which the
system picks at runtime based on the query. Like other systems, DataFusion has
specialized code for handling different types of group columns. For example,
there is &lt;a href="https://github.com/apache/datafusion/blob/73507c307487708deb321e1ba4e0d302084ca27e/datafusion/physical-plan/src/aggregates/group_values/single_group_by/primitive.rs"&gt;special code&lt;/a&gt; that handles &lt;code&gt;GROUP BY int_id&lt;/code&gt;  and &lt;a href="https://github.com/apache/datafusion/blob/73507c307487708deb321e1ba4e0d302084ca27e/datafusion/physical-plan/src/aggregates/group_values/single_group_by/bytes.rs"&gt;different special
code&lt;/a&gt; that handles &lt;code&gt;GROUP BY string_id&lt;/code&gt; .&lt;/p&gt;
&lt;p&gt;When a query groups by multiple columns, it is tricker to apply this technique.
For example &lt;code&gt;GROUP BY string_id, int_id&lt;/code&gt; and &lt;code&gt;GROUP BY int_id, string_id&lt;/code&gt; have
different optimal structures, but it is not possible to include specialized
versions for all possible combinations of group column types.&lt;/p&gt;
&lt;p&gt;DataFusion includes &lt;a href="https://github.com/apache/datafusion/blob/73507c307487708deb321e1ba4e0d302084ca27e/datafusion/physical-plan/src/aggregates/group_values/row.rs#L33-L39"&gt;a general Row based mechanism&lt;/a&gt; that works for any
combination of column types, but this general mechanism copies each value twice
as shown in Figure 5. The cost of this copy &lt;a href="https://github.com/apache/datafusion/issues/9403"&gt;is especially high for variable
length strings and binary data&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Row based storage for multiple group columns" class="img-responsive" src="../images/clickbench-datafusion-43/row-based-storage.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 5&lt;/strong&gt;: Prior to DataFusion 43.0.0, queries with multiple group columns
used Row based group storage and copied each group value twice. This copy
consumes a substantial amount of the query time for queries with many distinct
groups, such as several of the queries in ClickBench.&lt;/p&gt;
&lt;p&gt;Many optimizations in Databases boil down to simply avoiding copies, and this
was no exception. The trick was to figure out how to avoid copies without
causing per-column comparison overhead to dominate or complexity to get out of
hand. In a great example of diligent and disciplined engineering, &lt;a href="https://github.com/jayzhan211"&gt;Jay
Zhan&lt;/a&gt; tried &lt;a href="https://github.com/apache/datafusion/pull/10937"&gt;several&lt;/a&gt;, &lt;a href="https://github.com/apache/datafusion/pull/10976"&gt;different&lt;/a&gt; approaches until arriving
at the [one shipped in DataFusion &lt;code&gt;43.0.0&lt;/code&gt;], shown in Figure 6.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Column based storage for multiple group columns" class="img-responsive" src="../images/clickbench-datafusion-43/column-based-storage.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 6&lt;/strong&gt;: DataFusion 43.0.0&amp;rsquo;s new columnar group storage copies each group
value exactly once, which is significantly faster when grouping by multiple
columns.&lt;/p&gt;
&lt;p&gt;Huge thanks as well to &lt;a href="https://github.com/eejbyfeldt"&gt;Emil Ejbyfeldt&lt;/a&gt; and
&lt;a href="https://github.com/Dandandan"&gt;Dani&amp;euml;l Heres&lt;/a&gt; for their help reviewing and to
&lt;a href="https://github.com/Rachelint"&gt;Rachelint (kamille&lt;/a&gt;) for reviewing and
contributing a faster &lt;a href="https://github.com/apache/datafusion/pull/12996"&gt;vectorized append and compare for multiple groups&lt;/a&gt; which
will be released in DataFusion 44. The discussion on &lt;a href="https://github.com/apache/datafusion/issues/9403"&gt;the ticket&lt;/a&gt; is another
great example of the power of the DataFusion community working together to build
great software.&lt;/p&gt;
&lt;h1&gt;What&amp;rsquo;s Next 🚀&lt;/h1&gt;
&lt;p&gt;Just as I expect the performance of other engines to improve, DataFusion has
several more performance improvements lined up itself:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/datafusion/pull/11943#top"&gt;Intermediate results blocked management&lt;/a&gt; (thanks again &lt;a href="https://github.com/Rachelint"&gt;Rachelint (kamille&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/datafusion/issues/3463"&gt;Enable parquet filter pushdown by default&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We are also talking about what to focus on over the &lt;a href="https://github.com/apache/datafusion/issues/13274"&gt;next three
months&lt;/a&gt; and are always
looking for people to help! If you want to geek out (obsess??) about performance
and other features with engineers from around the world, &lt;a href="https://datafusion.apache.org/contributor-guide/communication.html"&gt;we would love you to
join us&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Additional Thanks&lt;/h1&gt;
&lt;p&gt;In addition to the people called out above, thanks:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/pmcgleenon"&gt;Patrick McGleenon&lt;/a&gt; for running ClickBench and gathering this data (&lt;a href="https://github.com/apache/datafusion/issues/13099#issuecomment-2478314793"&gt;source&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Everyone I missed in the shoutouts &amp;ndash; there are so many of you. We appreciate everyone.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;I have dreamed about DataFusion being on top of the ClickBench leaderboard for
several years. I often watched with envy improvements in systems backed by large
VC investments, internet companies, or world class research institutions, and
doubted that we could pull off something similar in an open source project with
always limited time.&lt;/p&gt;
&lt;p&gt;The fact that we have now surpassed those other systems in query performance I
think speaks to the power and possibility of focusing on community and aligning
our collective enthusiasm and skills towards a common goal. Of course, being on
the top in any particular benchmark is likely fleeting as other engines will
improve, but so will DataFusion!&lt;/p&gt;
&lt;p&gt;I love working on DataFusion &amp;ndash; the people, the quality of the code, my
interactions and the results we have achieved together far surpass my
expectations as well as most of my other software development experiences. I
can&amp;rsquo;t wait to see what people will build next, and hope to &lt;a href="https://github.com/apache/datafusion"&gt;see you
online&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;p&gt;[^1]: Note that DuckDB is slightly faster on the &amp;lsquo;cold&amp;rsquo; run.&lt;/p&gt;
&lt;p&gt;[^2]: Want to try your hand at a custom format for ClickBench fame / glory?: &lt;a href="https://github.com/apache/datafusion/issues/13448"&gt;Make DataFusion the fastest engine in ClickBench with custom file format&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[^3]: We have contributors from North America, South American, Europe, Asia, Africa and Australia&lt;/p&gt;
&lt;p&gt;[^4]: Undergraduates, PhD, Junior engineers, and getting-kind-of-crotchety experienced engineers&lt;/p&gt;
&lt;p&gt;[^5]: Thanks to Andy Pavlo, I love that nomenclature&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache DataFusion Comet 0.3.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2024/09/27/datafusion-comet-0.3.0" rel="alternate"></link><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2024-09-27:/blog/blog/2024/09/27/datafusion-comet-0.3.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache DataFusion PMC is pleased to announce version 0.3.0 of the &lt;a href="https://datafusion.apache.org/comet/"&gt;Comet&lt;/a&gt; subproject.&lt;/p&gt;
&lt;p&gt;Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.&lt;/p&gt;
&lt;p&gt;Comet runs on commodity hardware and aims to …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache DataFusion PMC is pleased to announce version 0.3.0 of the &lt;a href="https://datafusion.apache.org/comet/"&gt;Comet&lt;/a&gt; subproject.&lt;/p&gt;
&lt;p&gt;Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.&lt;/p&gt;
&lt;p&gt;Comet runs on commodity hardware and aims to provide 100% compatibility with Apache Spark. Any operators or
expressions that are not fully compatible will fall back to Spark unless explicitly enabled by the user. Refer
to the &lt;a href="https://datafusion.apache.org/comet/user-guide/compatibility.html"&gt;compatibility guide&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;This release covers approximately four weeks of development work and is the result of merging 57 PRs from 12 
contributors. See the &lt;a href="https://github.com/apache/datafusion-comet/blob/main/dev/changelog/0.3.0.md"&gt;change log&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2&gt;Release Highlights&lt;/h2&gt;
&lt;h3&gt;Binary Releases&lt;/h3&gt;
&lt;p&gt;Comet jar files are now published to Maven central for amd64 and arm64 architectures (Linux only).&lt;/p&gt;
&lt;p&gt;Files can be found at https://central.sonatype.com/search?q=org.apache.datafusion&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark versions 3.3, 3.4, and 3.5 are supported.&lt;/li&gt;
&lt;li&gt;Scala versions 2.12 and 2.13 are supported.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;New Features&lt;/h3&gt;
&lt;p&gt;The following expressions are now supported natively:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;DateAdd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DateSub&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ElementAt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GetArrayElement&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ToJson&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Performance &amp;amp; Stability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Upgraded to DataFusion 42.0.0&lt;/li&gt;
&lt;li&gt;Reduced memory overhead due to some memory leaks being fixed&lt;/li&gt;
&lt;li&gt;Comet will now fall back to Spark for queries that use DPP, to avoid performance regressions because Comet does 
  not have native support for DPP yet&lt;/li&gt;
&lt;li&gt;Improved performance when converting Spark columnar data to Arrow format&lt;/li&gt;
&lt;li&gt;Faster decimal sum and avg functions &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Documentation Updates&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Improved documentation for deploying Comet with Kubernetes and Helm in the &lt;a href="https://datafusion.apache.org/comet/user-guide/kubernetes.html"&gt;Comet Kubernetes Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More detailed architectural overview of Comet scan and execution in the &lt;a href="https://datafusion.apache.org/comet/contributor-guide/plugin_overview.html"&gt;Comet Plugin Overview&lt;/a&gt; in the contributor guide&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Getting Involved&lt;/h2&gt;
&lt;p&gt;The Comet project welcomes new contributors. We use the same &lt;a href="https://datafusion.apache.org/contributor-guide/communication.html#slack-and-discord"&gt;Slack and Discord&lt;/a&gt; channels as the main DataFusion
project.&lt;/p&gt;
&lt;p&gt;The easiest way to get involved is to test Comet with your current Spark jobs and file issues for any bugs or
performance regressions that you find. See the &lt;a href="https://datafusion.apache.org/comet/user-guide/installation.html"&gt;Getting Started&lt;/a&gt; guide for instructions on downloading and installing
Comet.&lt;/p&gt;
&lt;p&gt;There are also many &lt;a href="https://github.com/apache/datafusion-comet/contribute"&gt;good first issues&lt;/a&gt; waiting for contributions.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Using StringView / German Style Strings to Make Queries Faster: Part 1- Reading Parquet</title><link href="https://datafusion.apache.org/blog/blog/2024/09/13/string-view-german-style-strings-part-1" rel="alternate"></link><published>2024-09-13T00:00:00+00:00</published><updated>2024-09-13T00:00:00+00:00</updated><author><name>Xiangpeng Hao, Andrew Lamb</name></author><id>tag:datafusion.apache.org,2024-09-13:/blog/blog/2024/09/13/string-view-german-style-strings-part-1</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;&lt;em&gt;Editor's Note: This is the first of a &lt;a href="../2024/09/13/string-view-german-style-strings-part-2/"&gt;two part&lt;/a&gt; blog series that was first published on the &lt;a href="https://www.influxdata.com/blog/faster-queries-with-stringview-part-one-influxdb/"&gt;InfluxData blog&lt;/a&gt;. Thanks to InfluxData for sponsoring this work as &lt;a href="https://haoxp.xyz/"&gt;Xiangpeng Hao&lt;/a&gt;'s summer intern project&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This blog describes our experience implementing &lt;a href="https://arrow.apache.org/docs/format/Columnar.html#variable-size-binary-view-layout"&gt;StringView&lt;/a&gt; in the &lt;a href="https://github.com/apache/arrow-rs"&gt;Rust implementation&lt;/a&gt; of &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt;, and integrating …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;&lt;em&gt;Editor's Note: This is the first of a &lt;a href="../2024/09/13/string-view-german-style-strings-part-2/"&gt;two part&lt;/a&gt; blog series that was first published on the &lt;a href="https://www.influxdata.com/blog/faster-queries-with-stringview-part-one-influxdb/"&gt;InfluxData blog&lt;/a&gt;. Thanks to InfluxData for sponsoring this work as &lt;a href="https://haoxp.xyz/"&gt;Xiangpeng Hao&lt;/a&gt;'s summer intern project&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This blog describes our experience implementing &lt;a href="https://arrow.apache.org/docs/format/Columnar.html#variable-size-binary-view-layout"&gt;StringView&lt;/a&gt; in the &lt;a href="https://github.com/apache/arrow-rs"&gt;Rust implementation&lt;/a&gt; of &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt;, and integrating it into &lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt;, significantly accelerating string-intensive queries in the &lt;a href="https://benchmark.clickhouse.com/"&gt;ClickBench&lt;/a&gt; benchmark by 20%- 200% (Figure 1[^1]).&lt;/p&gt;
&lt;p&gt;Getting significant end-to-end performance improvements was non-trivial. Implementing StringView itself was only a fraction of the effort required. Among other things, we had to optimize UTF-8 validation, implement unintuitive compiler optimizations, tune block sizes, and time GC to realize the &lt;a href="https://www.influxdata.com/blog/flight-datafusion-arrow-parquet-fdap-architecture-influxdb/"&gt;FDAP ecosystem&lt;/a&gt;&amp;rsquo;s benefit. With other members of the open source community, we were able to overcome performance bottlenecks that could have killed the project. We would like to contribute by explaining the challenges and solutions in more detail so that more of the community can learn from our experience.&lt;/p&gt;
&lt;p&gt;StringView is based on a simple idea: avoid some string copies and accelerate comparisons with inlined prefixes. Like most great ideas, it is &amp;ldquo;obvious&amp;rdquo; only after &lt;a href="https://db.in.tum.de/~freitag/papers/p29-neumann-cidr20.pdf"&gt;someone describes it clearly&lt;/a&gt;. Although simple, straightforward implementation actually &lt;em&gt;slows down performance for almost every query&lt;/em&gt;. We must, therefore, apply astute observations and diligent engineering to realize the actual benefits from StringView.&lt;/p&gt;
&lt;p&gt;Although this journey was successful, not all research ideas are as lucky. To accelerate the adoption of research into industry, it is valuable to integrate research prototypes with practical systems. Understanding the nuances of real-world systems makes it more likely that research designs[^2] will lead to practical system improvements.&lt;/p&gt;
&lt;p&gt;StringView support was released as part of &lt;a href="https://crates.io/crates/arrow/52.2.0"&gt;arrow-rs v52.2.0&lt;/a&gt; and &lt;a href="https://crates.io/crates/datafusion/41.0.0"&gt;DataFusion v41.0.0&lt;/a&gt;. You can try it by setting the &lt;code&gt;schema_force_view_types&lt;/code&gt; &lt;a href="https://datafusion.apache.org/user-guide/configs.html"&gt;DataFusion configuration option&lt;/a&gt;, and we are&lt;a href="https://github.com/apache/datafusion/issues/11682"&gt; hard at work with the community to &lt;/a&gt;make it the default. We invite everyone to try it out, take advantage of the effort invested so far, and contribute to making it better.&lt;/p&gt;
&lt;p&gt;&lt;img alt="End to end performance improvements for ClickBench queries" class="img-responsive" src="../images/string-view-1/figure1-performance.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Figure 1: StringView improves string-intensive ClickBench query performance by 20% - 200%&lt;/p&gt;
&lt;h2&gt;What is StringView?&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Diagram of using StringArray and StringViewArray to represent the same string content" class="img-responsive" src="../images/string-view-1/figure2-string-view.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Figure 2: Use StringArray and StringViewArray to represent the same string content.&lt;/p&gt;
&lt;p&gt;The concept of inlined strings with prefixes (called &amp;ldquo;German Strings&amp;rdquo; &lt;a href="https://x.com/andy_pavlo/status/1813258735965643203"&gt;by Andy Pavlo&lt;/a&gt;, in homage to &lt;a href="https://www.tum.de/"&gt;TUM&lt;/a&gt;, where the &lt;a href="https://db.in.tum.de/~freitag/papers/p29-neumann-cidr20.pdf"&gt;Umbra paper that describes&lt;/a&gt; them originated) 
has been used in many recent database systems (&lt;a href="https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/"&gt;Velox&lt;/a&gt;, &lt;a href="https://pola.rs/posts/polars-string-type/"&gt;Polars&lt;/a&gt;, &lt;a href="https://duckdb.org/2021/12/03/duck-arrow.html"&gt;DuckDB&lt;/a&gt;, &lt;a href="https://cedardb.com/blog/german_strings/"&gt;CedarDB&lt;/a&gt;, etc.) 
and was introduced to Arrow as a new &lt;a href="https://arrow.apache.org/docs/format/Columnar.html#variable-size-binary-view-layout"&gt;StringViewArray&lt;/a&gt;[^3] type. Arrow&amp;rsquo;s original &lt;a href="https://arrow.apache.org/docs/format/Columnar.html#variable-size-binary-layout"&gt;StringArray&lt;/a&gt; is very memory efficient but less effective for certain operations. 
StringViewArray accelerates string-intensive operations via prefix inlining and a more flexible and compact string representation.&lt;/p&gt;
&lt;p&gt;A StringViewArray consists of three components:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;code&gt;&lt;em&gt;view&lt;/em&gt;&lt;/code&gt; array&lt;/li&gt;
&lt;li&gt;The buffers&lt;/li&gt;
&lt;li&gt;The buffer pointers (IDs) that map buffer offsets to their physical locations&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each &lt;code&gt;view&lt;/code&gt; is 16 bytes long, and its contents differ based on the string&amp;rsquo;s length:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;string length &amp;lt; 12 bytes: the first four bytes store the string length, and the remaining 12 bytes store the inlined string.&lt;/li&gt;
&lt;li&gt;string length &amp;gt; 12 bytes: the string is stored in a separate buffer. The length is again stored in the first 4 bytes, followed by the buffer id (4 bytes), the buffer offset (4 bytes), and the prefix (first 4 bytes) of the string.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figure 2 shows an example of the same logical content (left) using StringArray (middle) and StringViewArray (right):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first string &amp;ndash; &lt;code&gt;"Apache DataFusion"&lt;/code&gt; &amp;ndash; is 17 bytes long, and both StringArray and StringViewArray store the string&amp;rsquo;s bytes at the beginning of the buffer. The StringViewArray also inlines the first 4 bytes &amp;ndash; &lt;code&gt;"Apac"&lt;/code&gt; &amp;ndash; in the view.&lt;/li&gt;
&lt;li&gt;The second string, &lt;code&gt;"InfluxDB"&lt;/code&gt; is only 8 bytes long, so StringViewArray completely inlines the string content in the &lt;code&gt;view&lt;/code&gt; struct while StringArray stores the string in the buffer as well.&lt;/li&gt;
&lt;li&gt;The third string &lt;code&gt;"Arrow Rust Impl"&lt;/code&gt; is 15 bytes long and cannot be fully inlined. StringViewArray stores this in the same form as the first string.&lt;/li&gt;
&lt;li&gt;The last string &lt;code&gt;"Apache DataFusion"&lt;/code&gt; has the same content as the first string. It&amp;rsquo;s possible to use StringViewArray to avoid this duplication and reuse the bytes by pointing the view to the previous location.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;StringViewArray provides three opportunities for outperforming StringArray:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Less copying via the offset + buffer format&lt;/li&gt;
&lt;li&gt;Faster comparisons using the inlined string prefix&lt;/li&gt;
&lt;li&gt;Reusing repeated string values with the flexible &lt;code&gt;view&lt;/code&gt; layout&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The rest of this blog post discusses how to apply these opportunities in real query scenarios to improve performance, what challenges we encountered along the way, and how we solved them.&lt;/p&gt;
&lt;h2&gt;Faster Parquet Loading&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://parquet.apache.org/"&gt;Apache Parquet&lt;/a&gt; is the de facto format for storing large-scale analytical data commonly stored LakeHouse-style, such as &lt;a href="https://iceberg.apache.org"&gt;Apache Iceberg&lt;/a&gt; and &lt;a href="https://delta.io"&gt;Delta Lake&lt;/a&gt;. Efficiently loading data from Parquet is thus critical to query performance in many important real-world workloads.&lt;/p&gt;
&lt;p&gt;Parquet encodes strings (i.e., &lt;a href="https://docs.rs/parquet/latest/parquet/data_type/struct.ByteArray.html"&gt;byte array&lt;/a&gt;) in a slightly different format than required for the original Arrow StringArray. The string length is encoded inline with the actual string data (as shown in Figure 4 left). As mentioned previously, StringArray requires the data buffer to be continuous and compact&amp;mdash;the strings have to follow one after another. This requirement means that reading Parquet string data into an Arrow StringArray requires copying and consolidating the string bytes to a new buffer and tracking offsets in a separate array. Copying these strings is often wasteful. Typical queries filter out most data immediately after loading, so most of the copied data is quickly discarded.&lt;/p&gt;
&lt;p&gt;On the other hand, reading Parquet data as a StringViewArray can re-use the same data buffer as storing the Parquet pages because StringViewArray does not require strings to be contiguous. For example, in Figure 4, the StringViewArray directly references the buffer with the decoded Parquet page. The string &lt;code&gt;"Arrow Rust Impl"&lt;/code&gt; is represented by a &lt;code&gt;view&lt;/code&gt; with offset 37 and length 15 into that buffer.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Diagram showing how StringViewArray can avoid copying by reusing decoded Parquet pages." class="img-responsive" src="../images/string-view-1/figure4-copying.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Figure 4: StringViewArray avoids copying by reusing decoded Parquet pages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mini benchmark&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Reusing Parquet buffers is great in theory, but how much does saving a copy actually matter? We can run the following benchmark in arrow-rs to find out:&lt;/p&gt;
&lt;p&gt;Our benchmarking machine shows that loading &lt;em&gt;BinaryViewArray&lt;/em&gt; is almost 2x faster than loading BinaryArray (see next section about why this isn&amp;rsquo;t &lt;em&gt;String&lt;/em&gt; ViewArray).&lt;/p&gt;
&lt;p&gt;You can read more on this arrow-rs issue: &lt;a href="https://github.com/apache/arrow-rs/issues/5904"&gt;https://github.com/apache/arrow-rs/issues/5904&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;From Binary to Strings&lt;/h1&gt;
&lt;p&gt;You may wonder why we reported performance for BinaryViewArray when this post is about StringViewArray. Surprisingly, initially, our implementation to read StringViewArray from Parquet was much &lt;em&gt;slower&lt;/em&gt; than StringArray. Why? TLDR: Although reading StringViewArray copied less data, the initial implementation also spent much more time validating &lt;a href="https://en.wikipedia.org/wiki/UTF-8#:~:text=UTF%2D8%20is%20a%20variable,Unicode%20Standard"&gt;UTF-8&lt;/a&gt; (as shown in Figure 5).&lt;/p&gt;
&lt;p&gt;Strings are stored as byte sequences. When reading data from (potentially untrusted) Parquet files, a Parquet decoder must ensure those byte sequences are valid UTF-8 strings, and most programming languages, including Rust, include highly&lt;a href="https://doc.rust-lang.org/std/str/fn.from_utf8.html"&gt; optimized routines&lt;/a&gt; for doing so.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Figure showing time to load strings from Parquet and the effect of optimized UTF-8 validation." class="img-responsive" src="../images/string-view-1/figure5-loading-strings.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Figure 5: Time to load strings from Parquet. The UTF-8 validation advantage initially eliminates the advantage of reduced copying for StringViewArray.&lt;/p&gt;
&lt;p&gt;A StringArray can be validated in a single call to the UTF-8 validation function as it has a continuous string buffer. As long as the underlying buffer is UTF-8[^4], all strings in the array must be UTF-8. The Rust parquet reader makes a single function call to validate the entire buffer.&lt;/p&gt;
&lt;p&gt;However, validating an arbitrary StringViewArray requires validating each string with a separate call to the validation function, as the underlying buffer may also contain non-string data (for example, the lengths in Parquet pages).&lt;/p&gt;
&lt;p&gt;UTF-8 validation in Rust is highly optimized and favors longer strings (as shown in Figure 6), likely because it leverages SIMD instructions to perform parallel validation. The benefit of a single function call to validate UTF-8 over a function call for each string more than eliminates the advantage of avoiding the copy for StringViewArray.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Figure showing UTF-8 validation throughput vs string length." class="img-responsive" src="../images/string-view-1/figure6-utf8-validation.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Figure 6: UTF-8 validation throughput vs string length&amp;mdash;StringArray&amp;rsquo;s contiguous buffer can be validated much faster than StringViewArray&amp;rsquo;s buffer.&lt;/p&gt;
&lt;p&gt;Does this mean we should only use StringArray? No! Thankfully, there&amp;rsquo;s a clever way out. The key observation is that in many real-world datasets,&lt;a href="https://www.vldb.org/pvldb/vol17/p148-zeng.pdf"&gt; 99% of strings are shorter than 128 bytes&lt;/a&gt;, meaning the encoded length values are smaller than 128, &lt;strong&gt;in which case the length itself is also valid UTF-8&lt;/strong&gt; (in fact, it is &lt;a href="https://en.wikipedia.org/wiki/ASCII"&gt;ASCII&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This observation means we can optimize validating UTF-8 strings in Parquet pages by treating the length bytes as part of a single large string as long as the length &lt;em&gt;value&lt;/em&gt; is less than 128. Put another way, prior to this optimization, the length bytes act as string boundaries, which require a UTF-8 validation on each string. After this optimization, only those strings with lengths larger than 128 bytes (less than 1% of the strings in the ClickBench dataset) are string boundaries, significantly increasing the UTF-8 validation chunk size and thus improving performance.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/apache/arrow-rs/pull/6009/files"&gt;actual implementation&lt;/a&gt; is only nine lines of Rust (with 30 lines of comments). You can find more details in the related arrow-rs issue:&lt;a href="https://github.com/apache/arrow-rs/issues/5995"&gt; https://github.com/apache/arrow-rs/issues/5995&lt;/a&gt;. As expected, with this optimization, loading StringViewArray is almost 2x faster than loading StringArray.&lt;/p&gt;
&lt;h1&gt;Be Careful About Implicit Copies&lt;/h1&gt;
&lt;p&gt;After all the work to avoid copying strings when loading from Parquet, performance was still not as good as expected. We tracked the problem to a few implicit data copies that we weren't aware of, as described in&lt;a href="https://github.com/apache/arrow-rs/issues/6033"&gt; this issue&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The copies we eventually identified come from the following innocent-looking line of Rust code, where &lt;code&gt;self.buf&lt;/code&gt; is a &lt;a href="https://en.wikipedia.org/wiki/Reference_counting"&gt;reference counted&lt;/a&gt; pointer that should transform without copying into a buffer for use in StringViewArray.&lt;/p&gt;
&lt;p&gt;However, Rust-type coercion rules favored a blanket implementation that &lt;em&gt;did&lt;/em&gt; copy data. This implementation is shown in the following code block where the &lt;code&gt;impl&amp;lt;T: AsRef&amp;lt;[u8]&amp;gt;&amp;gt;&lt;/code&gt; will accept any type that implements &lt;code&gt;AsRef&amp;lt;[u8]&amp;gt;&lt;/code&gt; and copies the data to create a new buffer. To avoid copying, users need to explicitly call &lt;code&gt;from_vec&lt;/code&gt;, which consumes the &lt;code&gt;Vec&lt;/code&gt; and transforms it into a buffer.&lt;/p&gt;
&lt;p&gt;Diagnosing this implicit copy was time-consuming as it relied on subtle Rust language semantics. We needed to track every step of the data flow to ensure every copy was necessary. To help other users and prevent future mistakes, we also &lt;a href="https://github.com/apache/arrow-rs/pull/6043"&gt;removed&lt;/a&gt; the implicit API from arrow-rs in favor of an explicit API. Using this approach, we found and fixed several &lt;a href="https://github.com/apache/arrow-rs/pull/6039"&gt;other unintentional copies&lt;/a&gt; in the code base&amp;mdash;hopefully, the change will help other &lt;a href="https://github.com/spiraldb/vortex/pull/504"&gt;downstream users&lt;/a&gt; avoid unnecessary copies.&lt;/p&gt;
&lt;h1&gt;Help the Compiler by Giving it More Information&lt;/h1&gt;
&lt;p&gt;The Rust compiler&amp;rsquo;s automatic optimizations mostly work very well for a wide variety of use cases, but sometimes, it needs additional hints to generate the most efficient code. When profiling the performance of &lt;code&gt;view&lt;/code&gt; construction, we found, counterintuitively, that constructing &lt;strong&gt;long&lt;/strong&gt; strings was 10x faster than constructing &lt;strong&gt;short&lt;/strong&gt; strings, which made short strings slower on StringViewArray than on StringArray!&lt;/p&gt;
&lt;p&gt;As described in the first section, StringViewArray treats long and short strings differently. Short strings (&amp;lt;12 bytes) directly inline to the &lt;code&gt;view&lt;/code&gt; struct, while long strings only inline the first 4 bytes. The code to construct a &lt;code&gt;view&lt;/code&gt; looks something like this:&lt;/p&gt;
&lt;p&gt;It appears that both branches of the code should be fast: they both involve copying at most 16 bytes of data and some memory shift/store operations. How could the branch for short strings be 10x slower?&lt;/p&gt;
&lt;p&gt;Looking at the assembly code using &lt;a href="https://godbolt.org/"&gt;Compiler Explorer&lt;/a&gt;, we (with help from &lt;a href="https://github.com/aoli-al"&gt;Ao Li&lt;/a&gt;) found the compiler used CPU &lt;strong&gt;load instructions&lt;/strong&gt; to copy the fixed-sized 4 bytes to the &lt;code&gt;view&lt;/code&gt; for long strings, but it calls a function, &lt;a href="https://doc.rust-lang.org/std/ptr/fn.copy_nonoverlapping.html"&gt;&lt;code&gt;ptr::copy_non_overlapping&lt;/code&gt;&lt;/a&gt;, to copy the inlined bytes to the &lt;code&gt;view&lt;/code&gt; for short strings. The difference is that long strings have a prefix size (4 bytes) known at compile time, so the compiler directly uses efficient CPU instructions. But, since the size of the short string is unknown to the compiler, it has to call the general-purpose function &lt;code&gt;ptr::copy_non_coverlapping&lt;/code&gt;. Making a function call is significant unnecessary overhead compared to a CPU copy instruction.&lt;/p&gt;
&lt;p&gt;However, we know something the compiler doesn&amp;rsquo;t know: the short string size is not arbitrary&amp;mdash;it must be between 0 and 12 bytes, and we can leverage this information to avoid the function call. Our solution generates 13 copies of the function using generics, one for each of the possible prefix lengths. The code looks as follows, and &lt;a href="https://godbolt.org/z/685YPsd5G"&gt;checking the assembly code&lt;/a&gt;, we confirmed there are no calls to &lt;code&gt;ptr::copy_non_overlapping&lt;/code&gt;, and only native CPU instructions are used. For more details, see &lt;a href="https://github.com/apache/arrow-rs/issues/6034"&gt;the ticket&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;End-to-End Query Performance&lt;/h1&gt;
&lt;p&gt;In the previous sections, we went out of our way to make sure loading StringViewArray is faster than StringArray. Before going further, we wanted to verify if obsessing about reducing copies and function calls has actually improved end-to-end performance in real-life queries. To do this, we evaluated a ClickBench query (Q20) in DataFusion that counts how many URLs contain the word &lt;code&gt;"google"&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;This is a relatively simple query; most of the time is spent on loading the &amp;ldquo;URL&amp;rdquo; column to find matching rows. The query plan looks like this:&lt;/p&gt;
&lt;p&gt;We ran the benchmark in the DataFusion repo like this:&lt;/p&gt;
&lt;p&gt;With StringViewArray we saw a 24% end-to-end performance improvement, as shown in Figure 7. With the &lt;code&gt;--string-view&lt;/code&gt; argument, the end-to-end query time is &lt;code&gt;944.3 ms, 869.6 ms, 861.9 ms&lt;/code&gt; (three iterations). Without &lt;code&gt;--string-view&lt;/code&gt;, the end-to-end query time is &lt;code&gt;1186.1 ms, 1126.1 ms, 1138.3 ms&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Figure showing StringView improves end to end performance by 24 percent." class="img-responsive" src="../images/string-view-1/figure7-end-to-end.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Figure 7: StringView reduces end-to-end query time by 24% on ClickBench Q20.&lt;/p&gt;
&lt;p&gt;We also double-checked with detailed profiling and verified that the time reduction is indeed due to faster Parquet loading.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this first blog post, we have described what it took to improve the
performance of simply reading strings from Parquet files using StringView. While
this resulted in real end-to-end query performance improvements, in our &lt;a href="https://datafusion.apache.org/blog/2024/09/13/using-stringview-to-make-queries-faster-part-2.html"&gt;next
post&lt;/a&gt;, we explore additional optimizations enabled by StringView in DataFusion,
along with some of the pitfalls we encountered while implementing them.&lt;/p&gt;
&lt;h1&gt;Footnotes&lt;/h1&gt;
&lt;p&gt;[^1]: Benchmarked with AMD Ryzen 7600x (12 core, 24 threads, 32 MiB L3), WD Black SN770 NVMe SSD (5150MB/4950MB seq RW bandwidth)&lt;/p&gt;
&lt;p&gt;[^2]: Xiangpeng is a PhD student at the University of Wisconsin-Madison&lt;/p&gt;
&lt;p&gt;[^3]: There is also a corresponding &lt;em&gt;BinaryViewArray&lt;/em&gt; which is similar except that the data is not constrained to be UTF-8 encoded strings.&lt;/p&gt;
&lt;p&gt;[^4]: We also make sure that offsets do not break a UTF-8 code point, which is &lt;a href="https://github.com/apache/arrow-rs/blob/master/parquet/src/arrow/buffer/offset_buffer.rs#L62-L71"&gt;cheaply validated&lt;/a&gt;.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Using StringView / German Style Strings to make Queries Faster: Part 2 - String Operations</title><link href="https://datafusion.apache.org/blog/blog/2024/09/13/string-view-german-style-strings-part-2" rel="alternate"></link><published>2024-09-13T00:00:00+00:00</published><updated>2024-09-13T00:00:00+00:00</updated><author><name>Xiangpeng Hao, Andrew Lamb</name></author><id>tag:datafusion.apache.org,2024-09-13:/blog/blog/2024/09/13/string-view-german-style-strings-part-2</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;&lt;em&gt;Editor's Note: This blog series was first published on the &lt;a href="https://www.influxdata.com/blog/faster-queries-with-stringview-part-two-influxdb/"&gt;InfluxData blog&lt;/a&gt;. Thanks to InfluxData for sponsoring this work as &lt;a href="https://haoxp.xyz/"&gt;Xiangpeng Hao&lt;/a&gt;'s summer intern project&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In the &lt;a href="https://datafusion.apache.org/blog/blog/2024/09/13/string-view-german-style-strings-part-1"&gt;first post&lt;/a&gt;, we discussed the nuances required to accelerate Parquet loading using StringViewArray by reusing buffers and reducing copies. 
In this second …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;&lt;em&gt;Editor's Note: This blog series was first published on the &lt;a href="https://www.influxdata.com/blog/faster-queries-with-stringview-part-two-influxdb/"&gt;InfluxData blog&lt;/a&gt;. Thanks to InfluxData for sponsoring this work as &lt;a href="https://haoxp.xyz/"&gt;Xiangpeng Hao&lt;/a&gt;'s summer intern project&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In the &lt;a href="https://datafusion.apache.org/blog/blog/2024/09/13/string-view-german-style-strings-part-1"&gt;first post&lt;/a&gt;, we discussed the nuances required to accelerate Parquet loading using StringViewArray by reusing buffers and reducing copies. 
In this second part of the post, we describe the rest of the journey: implementing additional efficient operations for real query processing.&lt;/p&gt;
&lt;h2&gt;Faster String Operations&lt;/h2&gt;
&lt;h1&gt;Faster comparison&lt;/h1&gt;
&lt;p&gt;String comparison is ubiquitous; it is the core of 
&lt;a href="https://docs.rs/arrow/latest/arrow/compute/kernels/cmp/index.html"&gt;&lt;code&gt;cmp&lt;/code&gt;&lt;/a&gt;, 
&lt;a href="https://docs.rs/arrow/latest/arrow/compute/fn.min.html"&gt;&lt;code&gt;min&lt;/code&gt;&lt;/a&gt;/&lt;a href="https://docs.rs/arrow/latest/arrow/compute/fn.max.html"&gt;&lt;code&gt;max&lt;/code&gt;&lt;/a&gt;, 
and &lt;a href="https://docs.rs/arrow/latest/arrow/compute/kernels/comparison/fn.like.html"&gt;&lt;code&gt;like&lt;/code&gt;&lt;/a&gt;/&lt;a href="https://docs.rs/arrow/latest/arrow/compute/kernels/comparison/fn.ilike.html"&gt;&lt;code&gt;ilike&lt;/code&gt;&lt;/a&gt; kernels. StringViewArray is designed to accelerate such comparisons using the inlined prefix&amp;mdash;the key observation is that, in many cases, only the first few bytes of the string determine the string comparison results.&lt;/p&gt;
&lt;p&gt;For example, to compare the strings &lt;code&gt;InfluxDB&lt;/code&gt; with &lt;code&gt;Apache DataFusion&lt;/code&gt;, we only need to look at the first byte to determine the string ordering or equality. In this case, since &lt;code&gt;A&lt;/code&gt; is earlier in the alphabet than &lt;code&gt;I,&lt;/code&gt; &lt;code&gt;Apache DataFusion&lt;/code&gt; sorts first, and we know the strings are not equal. Despite only needing the first byte, comparing these strings when stored as a StringArray requires two memory accesses: 1) load the string offset and 2) use the offset to locate the string bytes. For low-level operations such as &lt;code&gt;cmp&lt;/code&gt; that are invoked millions of times in the very hot paths of queries, avoiding this extra memory access can make a measurable difference in query performance.&lt;/p&gt;
&lt;p&gt;For StringViewArray, typically, only one memory access is needed to load the view struct. Only if the result can not be determined from the prefix is the second memory access required. For the example above, there is no need for the second access. This technique is very effective in practice: the second access is never necessary for the more than &lt;a href="https://www.vldb.org/pvldb/vol17/p148-zeng.pdf"&gt;60% of real-world strings which are shorter than 12 bytes&lt;/a&gt;, as they are stored completely in the prefix.&lt;/p&gt;
&lt;p&gt;However, functions that operate on strings must be specialized to take advantage of the inlined prefix. In addition to low-level comparison kernels, we implemented &lt;a href="https://github.com/apache/arrow-rs/issues/5374"&gt;a wide range&lt;/a&gt; of other StringViewArray operations that cover the functions and operations seen in ClickBench queries. Supporting StringViewArray in all string operations takes quite a bit of effort, and thankfully the Arrow and DataFusion communities are already hard at work doing so (see &lt;a href="https://github.com/apache/datafusion/issues/11752"&gt;https://github.com/apache/datafusion/issues/11752&lt;/a&gt; if you want to help out).&lt;/p&gt;
&lt;h1&gt;Faster &lt;code&gt;take&lt;/code&gt;and&lt;code&gt;filter&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;After a filter operation such as &lt;code&gt;WHERE url &amp;lt;&amp;gt; ''&lt;/code&gt; to avoid processing empty urls, DataFusion will often &lt;em&gt;coalesce&lt;/em&gt; results to form a new array with only the passing elements. 
This coalescing ensures the batches are sufficiently sized to benefit from &lt;a href="https://www.vldb.org/pvldb/vol11/p2209-kersten.pdf"&gt;vectorized processing&lt;/a&gt; in subsequent steps.&lt;/p&gt;
&lt;p&gt;The coalescing operation is implemented using the &lt;a href="https://docs.rs/arrow/latest/arrow/compute/fn.take.html"&gt;take&lt;/a&gt; and &lt;a href="https://arrow.apache.org/rust/arrow/compute/kernels/filter/fn.filter.html"&gt;filter&lt;/a&gt; kernels in arrow-rs. For StringArray, these kernels require copying the string contents to a new buffer without &amp;ldquo;holes&amp;rdquo; in between. This copy can be expensive especially when the new array is large.&lt;/p&gt;
&lt;p&gt;However, &lt;code&gt;take&lt;/code&gt; and &lt;code&gt;filter&lt;/code&gt; for StringViewArray can avoid the copy by reusing buffers from the old array. The kernels only need to create a new list of  &lt;code&gt;view&lt;/code&gt;s that point at the same strings within the old buffers. 
Figure 1 illustrates the difference between the output of both string representations. StringArray creates two new strings at offsets 0-17 and 17-32, while StringViewArray simply points to the original buffer at offsets 0 and 25.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Diagram showing Zero-copy &amp;lt;code&amp;gt;take&amp;lt;/code&amp;gt;/&amp;lt;code&amp;gt;filter&amp;lt;/code&amp;gt; for StringViewArray" class="img-responsive" src="../images/string-view-2/figure1-zero-copy-take.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Figure 1: Zero-copy &lt;code&gt;take&lt;/code&gt;/&lt;code&gt;filter&lt;/code&gt; for StringViewArray&lt;/p&gt;
&lt;h1&gt;When to GC?&lt;/h1&gt;
&lt;p&gt;Zero-copy &lt;code&gt;take/filter&lt;/code&gt; is great for generating large arrays quickly, but it is suboptimal for highly selective filters, where most of the strings are filtered out. When the cardinality drops, StringViewArray buffers become sparse&amp;mdash;only a small subset of the bytes in the buffer&amp;rsquo;s memory are referred to by any &lt;code&gt;view&lt;/code&gt;. This leads to excessive memory usage, especially in a &lt;a href="https://github.com/apache/datafusion/issues/11628"&gt;filter-then-coalesce scenario&lt;/a&gt;. For example, a StringViewArray with 10M strings may only refer to 1M strings after some filter operations; however, due to zero-copy take/filter, the (reused) 10M buffers can not be released/reused.&lt;/p&gt;
&lt;p&gt;To release unused memory, we implemented a &lt;a href="https://docs.rs/arrow/latest/arrow/array/struct.GenericByteViewArray.html#method.gc"&gt;garbage collection (GC)&lt;/a&gt; routine to consolidate the data into a new buffer to release the old sparse buffer(s). As the GC operation copies strings, similarly to StringArray, we must be careful about when to call it. If we call GC too early, we cause unnecessary copying, losing much of the benefit of StringViewArray. If we call GC too late, we hold large buffers for too long, increasing memory use and decreasing cache efficiency. The &lt;a href="https://pola.rs/posts/polars-string-type/"&gt;Polars blog&lt;/a&gt; on StringView also refers to the challenge presented by garbage collection timing.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;arrow-rs&lt;/code&gt; implements the GC process, but it is up to users to decide when to call it. We leverage the semantics of the query engine and observed that the &lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/coalesce_batches/struct.CoalesceBatchesExec.html"&gt;&lt;code&gt;CoalseceBatchesExec&lt;/code&gt;&lt;/a&gt; operator, which merge smaller batches to a larger batch, is often used after the record cardinality is expected to shrink, which aligns perfectly with the scenario of GC in StringViewArray. 
We, therefore,&lt;a href="https://github.com/apache/datafusion/pull/11587"&gt; implemented the GC procedure&lt;/a&gt; inside &lt;code&gt;CoalseceBatchesExec&lt;/code&gt;[^5] with a heuristic that estimates when the buffers are too sparse.&lt;/p&gt;
&lt;h2&gt;The art of function inlining: not too much, not too little&lt;/h2&gt;
&lt;p&gt;Like string inlining, &lt;em&gt;function&lt;/em&gt; inlining is the process of embedding a short function into the caller to avoid the overhead of function calls (caller/callee save). 
Usually, the Rust compiler does a good job of deciding when to inline. However, it is possible to override its default using the &lt;a href="https://doc.rust-lang.org/reference/attributes/codegen.html#the-inline-attribute"&gt;&lt;code&gt;#[inline(always)]&lt;/code&gt; directive&lt;/a&gt;. 
In performance-critical code, inlined code allows us to organize large functions into smaller ones without paying the runtime cost of function invocation.&lt;/p&gt;
&lt;p&gt;However, function inlining is &lt;strong&gt;&lt;em&gt;not&lt;/em&gt;&lt;/strong&gt; always better, as it leads to larger function bodies that are harder for LLVM to optimize (for example, suboptimal &lt;a href="https://en.wikipedia.org/wiki/Register_allocation"&gt;register spilling&lt;/a&gt;) and risk overflowing the CPU&amp;rsquo;s instruction cache. We observed several performance regressions where function inlining caused &lt;em&gt;slower&lt;/em&gt; performance when implementing the StringViewArray comparison kernels. Careful inspection and tuning of the code was required to aid the compiler in generating efficient code. More details can be found in this PR: &lt;a href="https://github.com/apache/arrow-rs/pull/5900"&gt;https://github.com/apache/arrow-rs/pull/5900&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Buffer size tuning&lt;/h2&gt;
&lt;p&gt;StringViewArray permits multiple buffers, which enables a flexible buffer layout and potentially reduces the need to copy data. However, a large number of buffers slows down the performance of other operations. 
For example, &lt;a href="https://docs.rs/arrow/latest/arrow/array/trait.Array.html#tymethod.get_array_memory_size"&gt;&lt;code&gt;get_array_memory_size&lt;/code&gt;&lt;/a&gt; needs to sum the memory size of each buffer, which takes a long time with thousands of small buffers. 
In certain cases, we found that multiple calls to &lt;a href="https://docs.rs/arrow/latest/arrow/compute/fn.concat_batches.html"&gt;&lt;code&gt;concat_batches&lt;/code&gt;&lt;/a&gt; lead to arrays with millions of buffers, which was prohibitively expensive.&lt;/p&gt;
&lt;p&gt;For example, consider a StringViewArray with the previous default buffer size of 8 KB. With this configuration, holding 4GB of string data requires almost half a million buffers! Larger buffer sizes are needed for larger arrays, but we cannot arbitrarily increase the default buffer size, as small arrays would consume too much memory (most arrays require at least one buffer). Buffer sizing is especially problematic in query processing, as we often need to construct small batches of string arrays, and the sizes are unknown at planning time.&lt;/p&gt;
&lt;p&gt;To balance the buffer size trade-off, we again leverage the query processing (DataFusion) semantics to decide when to use larger buffers. While coalescing batches, we combine multiple small string arrays and set a smaller buffer size to keep the total memory consumption low. In string aggregation, we aggregate over an entire Datafusion partition, which can generate a large number of strings, so we set a larger buffer size (2MB).&lt;/p&gt;
&lt;p&gt;To assist situations where the semantics are unknown, we also &lt;a href="https://github.com/apache/arrow-rs/pull/6136"&gt;implemented&lt;/a&gt; a classic dynamic exponential buffer size growth strategy, which starts with a small buffer size (8KB) and doubles the size of each new buffer up to 2MB. We implemented this strategy in arrow-rs and enabled it by default so that other users of StringViewArray can also benefit from this optimization. See this issue for more details: &lt;a href="https://github.com/apache/arrow-rs/issues/6094"&gt;https://github.com/apache/arrow-rs/issues/6094&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;End-to-end query performance&lt;/h2&gt;
&lt;p&gt;We have made significant progress in optimizing StringViewArray filtering operations. Now, let&amp;rsquo;s test it in the real world to see how it works!&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s consider ClickBench query 22, which selects multiple string fields (&lt;code&gt;URL&lt;/code&gt;, &lt;code&gt;Title&lt;/code&gt;, and &lt;code&gt;SearchPhase&lt;/code&gt;) and applies several filters.&lt;/p&gt;
&lt;p&gt;We ran the benchmark using the following command in the DataFusion repo. Again, the &lt;code&gt;--string-view&lt;/code&gt; option means we use StringViewArray instead of StringArray.&lt;/p&gt;
&lt;p&gt;To eliminate the impact of the faster Parquet reading using StringViewArray (see the first part of this blog), Figure 2 plots only the time spent in &lt;code&gt;FilterExec&lt;/code&gt;. Without StringViewArray, the filter takes 7.17s; with StringViewArray, the filter only takes 4.86s, a 32% reduction in time. Moreover, we see a 17% improvement in end-to-end query performance.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Figure showing StringViewArray reduces the filter time by 32% on ClickBench query 22." class="img-responsive" src="../images/string-view-2/figure2-filter-time.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Figure 2: StringViewArray reduces the filter time by 32% on ClickBench query 22.&lt;/p&gt;
&lt;h1&gt;Faster String Aggregation&lt;/h1&gt;
&lt;p&gt;So far, we have discussed how to exploit two StringViewArray features: reduced copy and faster filtering. This section focuses on reusing string bytes to repeat string values.&lt;/p&gt;
&lt;p&gt;As described in part one of this blog, if two strings have identical values, StringViewArray can use two different &lt;code&gt;view&lt;/code&gt;s pointing at the same buffer range, thus avoiding repeating the string bytes in the buffer. This makes StringViewArray similar to an Arrow &lt;a href="https://docs.rs/arrow/latest/arrow/array/struct.DictionaryArray.html"&gt;DictionaryArray&lt;/a&gt; that stores Strings&amp;mdash;both array types work well for strings with only a few distinct values.&lt;/p&gt;
&lt;p&gt;Deduplicating string values can significantly reduce memory consumption in StringViewArray. However, this process is expensive and involves hashing every string and maintaining a hash table, and so it cannot be done by default when creating a StringViewArray. We introduced an&lt;a href="https://docs.rs/arrow/latest/arrow/array/builder/struct.GenericByteViewBuilder.html#method.with_deduplicate_strings"&gt; opt-in string deduplication mode&lt;/a&gt; in arrow-rs for advanced users who know their data has a small number of distinct values, and where the benefits of reduced memory consumption outweigh the additional overhead of array construction.&lt;/p&gt;
&lt;p&gt;Once again, we leverage DataFusion query semantics to identify StringViewArray with duplicate values, such as aggregation queries with multiple group keys. For example, some &lt;a href="https://github.com/apache/datafusion/blob/main/benchmarks/queries/clickbench/queries.sql"&gt;ClickBench queries&lt;/a&gt; group by two columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;UserID&lt;/code&gt; (an integer with close to 1 M distinct values)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MobilePhoneModel&lt;/code&gt; (a string with less than a hundred distinct values)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this case, the output row count is&lt;code&gt;count(distinct UserID) * count(distinct MobilePhoneModel)&lt;/code&gt;,  which is 100M. Each string value of  &lt;code&gt;MobilePhoneModel&lt;/code&gt; is repeated 1M times. With StringViewArray, we can save space by pointing the repeating values to the same underlying buffer.&lt;/p&gt;
&lt;p&gt;Faster string aggregation with StringView is part of a larger project to &lt;a href="https://github.com/apache/datafusion/issues/7000"&gt;improve DataFusion aggregation performance&lt;/a&gt;. We have a &lt;a href="https://github.com/apache/datafusion/pull/11794"&gt;proof of concept implementation&lt;/a&gt; with StringView that can improve the multi-column string aggregation by 20%. We would love your help to get it production ready!&lt;/p&gt;
&lt;h1&gt;StringView Pitfalls&lt;/h1&gt;
&lt;p&gt;Most existing blog posts (including this one) focus on the benefits of using StringViewArray over other string representations such as StringArray. As we have discussed, even though it requires a significant engineering investment to realize, StringViewArray is a major improvement over StringArray in many cases.&lt;/p&gt;
&lt;p&gt;However, there are several cases where StringViewArray is slower than StringArray. For completeness, we have listed those instances here:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Tiny strings (when strings are shorter than 8 bytes)&lt;/strong&gt;: every element of the StringViewArray consumes at least 16 bytes of memory&amp;mdash;the size of the &lt;code&gt;view&lt;/code&gt; struct. For an array of tiny strings, StringViewArray consumes more memory than StringArray and thus can cause slower performance due to additional memory pressure on the CPU cache.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Many repeated short strings&lt;/strong&gt;: Similar to the first point, StringViewArray can be slower and require more memory than a DictionaryArray because 1) it can only reuse the bytes in the buffer when the strings are longer than 12 bytes and 2) 32-bit offsets are always used, even when a smaller size (8 bit or 16 bit) could represent all the distinct values.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Filtering:&lt;/strong&gt; As we mentioned above, StringViewArrays often consume more memory than the corresponding StringArray, and memory bloat quickly dominates the performance without GC. However, invoking GC also reduces the benefits of less copying so must be carefully tuned.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Conclusion and Takeaways&lt;/h1&gt;
&lt;p&gt;In these two blog posts, we discussed what it takes to implement StringViewArray in arrow-rs and then integrate it into DataFusion. Our evaluations on ClickBench queries show that StringView can improve the performance of string-intensive workloads by up to 2x.&lt;/p&gt;
&lt;p&gt;Given that DataFusion already &lt;a href="https://benchmark.clickhouse.com/#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"&gt;performs very well on ClickBench&lt;/a&gt;, the level of end-to-end performance improvement using StringViewArray shows the power of this technique and, of course, is a win for DataFusion and the systems that build upon it.&lt;/p&gt;
&lt;p&gt;StringView is a big project that has received tremendous community support. Specifically, we would like to thank &lt;a href="https://github.com/tustvold"&gt;@tustvold&lt;/a&gt;, &lt;a href="https://github.com/ariesdevil"&gt;@ariesdevil&lt;/a&gt;, &lt;a href="https://github.com/RinChanNOWWW"&gt;@RinChanNOWWW&lt;/a&gt;, &lt;a href="https://github.com/ClSlaid"&gt;@ClSlaid&lt;/a&gt;, &lt;a href="https://github.com/2010YOUY01"&gt;@2010YOUY01&lt;/a&gt;, &lt;a href="https://github.com/chloro-pn"&gt;@chloro-pn&lt;/a&gt;, &lt;a href="https://github.com/a10y"&gt;@a10y&lt;/a&gt;, &lt;a href="https://github.com/Kev1n8"&gt;@Kev1n8&lt;/a&gt;, &lt;a href="https://github.com/Weijun-H"&gt;@Weijun-H&lt;/a&gt;, &lt;a href="https://github.com/PsiACE"&gt;@PsiACE&lt;/a&gt;, &lt;a href="https://github.com/tshauck"&gt;@tshauck&lt;/a&gt;, and &lt;a href="https://github.com/xinlifoobar"&gt;@xinlifoobar&lt;/a&gt; for their valuable contributions!&lt;/p&gt;
&lt;p&gt;As the introduction states, &amp;ldquo;German Style Strings&amp;rdquo; is a relatively straightforward research idea that avoid some string copies and accelerates comparisons. However, applying this (great) idea in practice requires a significant investment in careful software engineering. Again, we encourage the research community to continue to help apply research ideas to industrial systems, such as DataFusion, as doing so provides valuable perspectives when evaluating future research questions for the greatest potential impact.&lt;/p&gt;
&lt;h3&gt;Footnotes&lt;/h3&gt;
&lt;p&gt;[^5]: There are additional optimizations possible in this operation that the community is working on, such as  &lt;a href="https://github.com/apache/datafusion/issues/7957"&gt;https://github.com/apache/datafusion/issues/7957&lt;/a&gt;.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache DataFusion Comet 0.2.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2024/08/28/datafusion-comet-0.2.0" rel="alternate"></link><published>2024-08-28T00:00:00+00:00</published><updated>2024-08-28T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2024-08-28:/blog/blog/2024/08/28/datafusion-comet-0.2.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache DataFusion PMC is pleased to announce version 0.2.0 of the &lt;a href="https://datafusion.apache.org/comet/"&gt;Comet&lt;/a&gt; subproject.&lt;/p&gt;
&lt;p&gt;Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.&lt;/p&gt;
&lt;p&gt;Comet runs on commodity hardware and aims to …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache DataFusion PMC is pleased to announce version 0.2.0 of the &lt;a href="https://datafusion.apache.org/comet/"&gt;Comet&lt;/a&gt; subproject.&lt;/p&gt;
&lt;p&gt;Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.&lt;/p&gt;
&lt;p&gt;Comet runs on commodity hardware and aims to provide 100% compatibility with Apache Spark. Any operators or
expressions that are not fully compatible will fall back to Spark unless explicitly enabled by the user. Refer
to the &lt;a href="https://datafusion.apache.org/comet/user-guide/compatibility.html"&gt;compatibility guide&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;This release covers approximately four weeks of development work and is the result of merging 87 PRs from 14 
contributors. See the &lt;a href="https://github.com/apache/datafusion-comet/blob/main/dev/changelog/0.2.0.md"&gt;change log&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2&gt;Release Highlights&lt;/h2&gt;
&lt;h3&gt;Docker Images&lt;/h3&gt;
&lt;p&gt;Docker images are now available from the &lt;a href="https://github.com/apache/datafusion-comet/pkgs/container/datafusion-comet/265110454?tag=spark-3.4-scala-2.12-0.2.0"&gt;GitHub Container Registry&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Performance improvements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Native shuffle is now enabled by default&lt;/li&gt;
&lt;li&gt;Improved handling of decimal types&lt;/li&gt;
&lt;li&gt;Reduced some redundant copying of batches in Filter/Scan operations&lt;/li&gt;
&lt;li&gt;Optimized performance of count aggregates&lt;/li&gt;
&lt;li&gt;Optimized performance of  CASE expressions for specific uses:&lt;/li&gt;
&lt;li&gt;CASE WHEN expr THEN column ELSE null END&lt;/li&gt;
&lt;li&gt;CASE WHEN expr THEN literal ELSE literal END&lt;/li&gt;
&lt;li&gt;Optimized performance of IS NOT NULL&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;New Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Window operations now support count and sum aggregates&lt;/li&gt;
&lt;li&gt;CreateArray&lt;/li&gt;
&lt;li&gt;GetStructField&lt;/li&gt;
&lt;li&gt;Support nested types in hash join&lt;/li&gt;
&lt;li&gt;Basic implementation of RLIKE expression&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Current Performance&lt;/h2&gt;
&lt;p&gt;We use benchmarks derived from the industry standard TPC-H and TPC-DS benchmarks for tracking progress with
performance. The following charts shows the time it takes to run the queries against 100 GB of data in
Parquet format using a single executor with eight cores. See the &lt;a href="https://datafusion.apache.org/comet/contributor-guide/benchmarking.html"&gt;Comet Benchmarking Guide&lt;/a&gt;
for details of the environment used for these benchmarks.&lt;/p&gt;
&lt;h3&gt;Benchmark derived from TPC-H&lt;/h3&gt;
&lt;p&gt;Comet 0.2.0 provides a 62% speedup compared to Spark. This is slightly better than the Comet 0.1.0 release.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Chart showing TPC-H benchmark results for Comet 0.2.0" class="img-responsive" src="../images/comet-0.2.0/tpch_allqueries.png" width="100%"/&gt;&lt;/p&gt;
&lt;h3&gt;Benchmark derived from TPC-DS&lt;/h3&gt;
&lt;p&gt;Comet 0.2.0 provides a 21% speedup compared to Spark, which is a significant improvement compared to 
Comet 0.1.0, which did not provide any speedup for this benchmark.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Chart showing TPC-DS benchmark results for Comet 0.2.0" class="img-responsive" src="../images/comet-0.2.0/tpcds_allqueries.png" width="100%"/&gt;&lt;/p&gt;
&lt;h2&gt;Getting Involved&lt;/h2&gt;
&lt;p&gt;The Comet project welcomes new contributors. We use the same &lt;a href="https://datafusion.apache.org/contributor-guide/communication.html#slack-and-discord"&gt;Slack and Discord&lt;/a&gt; channels as the main DataFusion
project.&lt;/p&gt;
&lt;p&gt;The easiest way to get involved is to test Comet with your current Spark jobs and file issues for any bugs or
performance regressions that you find. See the &lt;a href="https://datafusion.apache.org/comet/user-guide/installation.html"&gt;Getting Started&lt;/a&gt; guide for instructions on downloading and installing
Comet.&lt;/p&gt;
&lt;p&gt;There are also many &lt;a href="https://github.com/apache/datafusion-comet/contribute"&gt;good first issues&lt;/a&gt; waiting for contributions.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache DataFusion Python 40.1.0 Released, Significant usability updates</title><link href="https://datafusion.apache.org/blog/blog/2024/08/20/python-datafusion-40.0.0" rel="alternate"></link><published>2024-08-20T00:00:00+00:00</published><updated>2024-08-20T00:00:00+00:00</updated><author><name>timsaucer</name></author><id>tag:datafusion.apache.org,2024-08-20:/blog/blog/2024/08/20/python-datafusion-40.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;We are happy to announce that &lt;a href="https://pypi.org/project/datafusion/40.1.0/"&gt;DataFusion in Python 40.1.0&lt;/a&gt; has been released. In addition to
bringing in all of the new features of the core &lt;a href="https://datafusion.apache.org/blog/2024/07/24/datafusion-40.0.0/"&gt;DataFusion 40.0.0&lt;/a&gt; package, this release
contains &lt;em&gt;significant&lt;/em&gt; updates to the user interface and documentation. We listened to the python …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;We are happy to announce that &lt;a href="https://pypi.org/project/datafusion/40.1.0/"&gt;DataFusion in Python 40.1.0&lt;/a&gt; has been released. In addition to
bringing in all of the new features of the core &lt;a href="https://datafusion.apache.org/blog/2024/07/24/datafusion-40.0.0/"&gt;DataFusion 40.0.0&lt;/a&gt; package, this release
contains &lt;em&gt;significant&lt;/em&gt; updates to the user interface and documentation. We listened to the python
user community to create a more &lt;em&gt;pythonic&lt;/em&gt; experience. If you have not used the python interface to
DataFusion before, this is an excellent time to give it a try!&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Until now, the python bindings for DataFusion have primarily been a thin layer to expose the
underlying Rust functionality. This has been worked well for early adopters to use DataFusion
within their Python projects, but some users have found it difficult to work with. As compared to
other DataFrame libraries, these issues were raised:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Most of the functions had little or no documentation. Users often had to refer to the Rust
documentation or code to learn how to use DataFusion. This alienated some python users.&lt;/li&gt;
&lt;li&gt;Users could not take advantage of modern IDE features such as type hinting. These are valuable
tools for rapid testing and development.&lt;/li&gt;
&lt;li&gt;Some of the interfaces felt &amp;ldquo;clunky&amp;rdquo; to users since some Python concepts do not always map well
to their Rust counterparts.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This release aims to bring a better user experience to the DataFusion Python community.&lt;/p&gt;
&lt;h2&gt;What's Changed&lt;/h2&gt;
&lt;p&gt;The most significant difference is that we have added wrapper functions and classes for most of the
user facing interface. These wrappers, written in Python, contain both documentation and type
annotations.&lt;/p&gt;
&lt;p&gt;This documenation is now available on the &lt;a href="https://datafusion.apache.org/python/autoapi/datafusion/index.html"&gt;DataFusion in Python API&lt;/a&gt; website. There you can browse
the available functions and classes to see the breadth of available functionality.&lt;/p&gt;
&lt;p&gt;Modern IDEs use language servers such as
&lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-python.vscode-pylance"&gt;Pylance&lt;/a&gt; or
&lt;a href="https://jedi.readthedocs.io/en/latest/"&gt;Jedi&lt;/a&gt; to perform analysis of python code, provide useful
hints, and identify usage errors. These are major tools in the python user community. With this
release, users can fully use these tools in their workflow.&lt;/p&gt;
&lt;figure style="text-align: center;"&gt;
&lt;img alt="Fig 1: Enhanced tooltips in an IDE." class="img-responsive" src="../images/python-datafusion-40.0.0/vscode_hover_tooltip.png" width="100%"/&gt;
&lt;figcaption&gt;
&lt;b&gt;Figure 1&lt;/b&gt;: With the enhanced python wrappers, users can see helpful tool tips with
   type annotations directly in modern IDEs.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;By having the type annotations, these IDEs can also identify quickly when a user has incorrectly
used a function's arguments as shown in Figure 2.&lt;/p&gt;
&lt;figure style="text-align: center;"&gt;
&lt;img alt="Fig 2: Error checking in static analysis" class="img-responsive" src="../images/python-datafusion-40.0.0/pylance_error_checking.png" width="100%"/&gt;
&lt;figcaption&gt;
&lt;b&gt;Figure 2&lt;/b&gt;: Modern Python language servers can perform static analysis and quickly find
   errors in the arguments to functions.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;In addition to these wrapper libraries, we have enhancements to some of the functions to feel more
easy to use.&lt;/p&gt;
&lt;h3&gt;Improved DataFrame filter arguments&lt;/h3&gt;
&lt;p&gt;You can now apply multiple &lt;code&gt;filter&lt;/code&gt; statements in a single step. When using &lt;code&gt;DataFrame.filter&lt;/code&gt; you
can pass in multiple arguments, separated by a comma. These will act as a logical &lt;code&gt;AND&lt;/code&gt; of all of
the filter arguments. The following two statements are equivalent:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"size"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"max_size"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"color"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"green"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"size"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"max_size"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"color"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"green"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Comparison against literal values&lt;/h3&gt;
&lt;p&gt;It is very common to write DataFrame operations that compare an expression to some fixed value.
For example, filtering a DataFrame might have an operation such as &lt;code&gt;df.filter(col("size") &amp;lt; lit(16))&lt;/code&gt;.
To make these common operations more ergonomic, you can now simply use &lt;code&gt;df.filter(col("size") &amp;lt; 16)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For the right hand side of the comparison operator, you can now use any Python value that can be
coerced into a &lt;code&gt;Literal&lt;/code&gt;. This gives an easy to ready expression. For example, consider these few
lines from one of the
&lt;a href="https://github.com/apache/datafusion-python/tree/main/examples/tpch"&gt;TPC-H examples&lt;/a&gt; provided in
the DataFusion Python repository.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;df_lineitem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_shipdate"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_discount"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DISCOUNT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DELTA&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_discount"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DISCOUNT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DELTA&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_quantity"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;QUANTITY&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above code mirrors closely how these filters would need to be applied in rust. With this new
release, the user can simplify these lines. Also shown in the example below is that &lt;code&gt;filter()&lt;/code&gt;
now accepts a variable number of arguments and filters on all such arguments (boolean AND).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_lineitem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_shipdate"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_discount"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;DISCOUNT&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;DELTA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_discount"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;DISCOUNT&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;DELTA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"l_quantity"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;QUANTITY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Select columns by name&lt;/h3&gt;
&lt;p&gt;It is very common for users to perform &lt;code&gt;DataFrame&lt;/code&gt; selection where they simply want a column. For
this we have had the function &lt;code&gt;select_columns("a", "b")&lt;/code&gt; or the user could perform
&lt;code&gt;select(col("a"), col("b"))&lt;/code&gt;. In the new release, we accept either full expressions in &lt;code&gt;select()&lt;/code&gt;
or strings of the column names. You can mix these as well.&lt;/p&gt;
&lt;p&gt;Where before you may have to do an operation like&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df_subset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"c"&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can now simplify this to&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df_subset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"c"&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Creating named structs&lt;/h3&gt;
&lt;p&gt;Creating a &lt;code&gt;struct&lt;/code&gt; with named fields was previously difficult to use and allowed for potential
user errors when specifying the name of each field. Now we have a cleaner interface where the
user passes a list of tuples containing the name of the field and the expression to create.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;named_struct&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;While most of the user facing classes and functions have been exposed, there are a few that require
exposure. Namely the classes in &lt;code&gt;datafusion.object_store&lt;/code&gt; and the logical plans used by
&lt;code&gt;datafusion.substrait&lt;/code&gt;. The team is working on
&lt;a href="https://github.com/apache/datafusion-python/issues/767"&gt;these issues&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, in the next release of DataFusion there have been improvements made to the user-defined
aggregate and window functions to make them easier to use. We plan on
&lt;a href="https://github.com/apache/datafusion-python/issues/780"&gt;bringing these enhancements&lt;/a&gt; to this project.&lt;/p&gt;
&lt;h2&gt;Thank You&lt;/h2&gt;
&lt;p&gt;We would like to thank the following members for their very helpful discussions regarding these
updates: &lt;a href="https://github.com/andygrove"&gt;@andygrove&lt;/a&gt;, &lt;a href="https://github.com/max-muoto"&gt;@max-muoto&lt;/a&gt;, &lt;a href="https://github.com/slyons"&gt;@slyons&lt;/a&gt;, &lt;a href="https://github.com/Throne3d"&gt;@Throne3d&lt;/a&gt;, &lt;a href="https://github.com/Michael-J-Ward"&gt;@Michael-J-Ward&lt;/a&gt;, &lt;a href="https://github.com/datapythonista"&gt;@datapythonista&lt;/a&gt;,
&lt;a href="https://github.com/austin362667"&gt;@austin362667&lt;/a&gt;, &lt;a href="https://github.com/kylebarron"&gt;@kylebarron&lt;/a&gt;, &lt;a href="https://github.com/simicd"&gt;@simicd&lt;/a&gt;. The &lt;a href="https://github.com/apache/datafusion-python/pull/750"&gt;primary PR (#750)&lt;/a&gt; that includes these updates
had an extensive conversation, leading to a significantly improved end product. Again, thank you
to all who provided input!&lt;/p&gt;
&lt;p&gt;We would like to give an special thank you to &lt;a href="https://github.com/3ok"&gt;@3ok&lt;/a&gt; who created the initial version of the wrapper
definitions. The work they did was time consuming and required exceptional attention to detail. It
provided enormous value to starting this project. Thank you!&lt;/p&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;The DataFusion Python team is an active and engaging community and we would love
to have you join us and help the project.&lt;/p&gt;
&lt;p&gt;Here are some ways to get involved:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Learn more by visiting the &lt;a href="https://datafusion.apache.org/python/index.html"&gt;DataFusion Python project&lt;/a&gt;
page.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Try out the project and provide feedback, file issues, and contribute code.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="blog"></category></entry><entry><title>Apache DataFusion 40.0.0 Released</title><link href="https://datafusion.apache.org/blog/blog/2024/07/24/datafusion-40.0.0" rel="alternate"></link><published>2024-07-24T00:00:00+00:00</published><updated>2024-07-24T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2024-07-24:/blog/blog/2024/07/24/datafusion-40.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;!-- see https://github.com/apache/datafusion/issues/9602 for details --&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;We are proud to announce &lt;a href="https://crates.io/crates/datafusion/40.0.0"&gt;DataFusion 40.0.0&lt;/a&gt;. This blog highlights some of the
many major improvements since we released &lt;a href="https://datafusion.apache.org/blog/2024/01/19/datafusion-34.0.0/"&gt;DataFusion 34.0.0&lt;/a&gt; and a preview of
what the community is thinking about in the next 6 months. We are hoping to make
more regular blog posts …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;!-- see https://github.com/apache/datafusion/issues/9602 for details --&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;We are proud to announce &lt;a href="https://crates.io/crates/datafusion/40.0.0"&gt;DataFusion 40.0.0&lt;/a&gt;. This blog highlights some of the
many major improvements since we released &lt;a href="https://datafusion.apache.org/blog/2024/01/19/datafusion-34.0.0/"&gt;DataFusion 34.0.0&lt;/a&gt; and a preview of
what the community is thinking about in the next 6 months. We are hoping to make
more regular blog posts -- if you are interested in helping write them, please
reach out!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt; is an extensible query engine, written in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, that
uses &lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt; as its in-memory format. DataFusion is used by developers to
create new, fast data centric systems such as databases, dataframe libraries,
machine learning and streaming applications. While &lt;a href="https://datafusion.apache.org/user-guide/introduction.html#project-goals"&gt;DataFusion&amp;rsquo;s primary design
goal&lt;/a&gt; is to accelerate the creation of other data centric systems, it has a
reasonable experience directly out of the box as a &lt;a href="https://datafusion.apache.org/python/"&gt;dataframe library&lt;/a&gt; and
&lt;a href="https://datafusion.apache.org/user-guide/cli/"&gt;command line SQL tool&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;DataFusion's core thesis is that as a community, together we can build much more
advanced technology than any of us as individuals or companies could do alone. 
Without DataFusion, highly performant vectorized query engines would remain
the domain of a few large companies and world-class research institutions. 
With DataFusion, we can all build on top of a shared foundation, and focus on
what makes our projects unique.&lt;/p&gt;
&lt;h2&gt;Community Growth  📈&lt;/h2&gt;
&lt;p&gt;In the last 6 months, between &lt;code&gt;34.0.0&lt;/code&gt; and &lt;code&gt;40.0.0&lt;/code&gt;, our community continues to
grow in new and exciting ways.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DataFusion became a top level Apache Software Foundation project (read the
   &lt;a href="https://news.apache.org/foundation/entry/apache-software-foundation-announces-new-top-level-project-apache-datafusion"&gt;press release&lt;/a&gt; and &lt;a href="https://datafusion.apache.org/blog/2024/05/07/datafusion-tlp/"&gt;blog post&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;We added several PMC members and new
   committers: &lt;a href="https://github.com/comphead"&gt;@comphead&lt;/a&gt;, &lt;a href="https://github.com/mustafasrepo"&gt;@mustafasrepo&lt;/a&gt;, &lt;a href="https://github.com/ozankabak"&gt;@ozankabak&lt;/a&gt;, and &lt;a href="https://github.com/waynexia"&gt;@waynexia&lt;/a&gt; joined the PMC,
   &lt;a href="https://github.com/jonahgao"&gt;@jonahgao&lt;/a&gt; and &lt;a href="https://github.com/lewiszlw"&gt;@lewiszlw&lt;/a&gt; joined as committers. See the &lt;a href="https://lists.apache.org/list.html?dev@datafusion.apache.org"&gt;mailing list&lt;/a&gt; for
   more details.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datafusion.apache.org/comet/"&gt;DataFusion Comet&lt;/a&gt; was &lt;a href="https://arrow.apache.org/blog/2024/03/06/comet-donation/"&gt;donated&lt;/a&gt; and is nearing its first release.&lt;/li&gt;
&lt;li&gt;In the &lt;a href="https://github.com/apache/arrow-datafusion"&gt;core DataFusion repo&lt;/a&gt; alone we reviewed and accepted almost 1500 PRs from 182 different
   committers, created over 1000 issues and closed 781 of them 🚀. This is up
   almost 50% from our last post (1000 PRs from 124 committers with 650 issues
   created in our last post) 🤯. All changes are listed in the detailed
   &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;DataFusion focused meetups happened or are happening in multiple cities 
   around the world: &lt;a href="https://github.com/apache/datafusion/discussions/8522"&gt;Austin&lt;/a&gt;, &lt;a href="https://github.com/apache/datafusion/discussions/10800"&gt;San Francisco&lt;/a&gt;, &lt;a href="https://www.huodongxing.com/event/5761971909400?td=1965290734055"&gt;Hangzhou&lt;/a&gt;, &lt;a href="https://github.com/apache/datafusion/discussions/11213"&gt;New York&lt;/a&gt;, and
   &lt;a href="https://github.com/apache/datafusion/discussions/11431"&gt;Belgrade&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Many new projects started in the &lt;a href="https://github.com/datafusion-contrib"&gt;datafusion-contrib&lt;/a&gt; organization, including
   &lt;a href="https://github.com/datafusion-contrib/datafusion-table-providers"&gt;Table Providers&lt;/a&gt;, &lt;a href="https://github.com/datafusion-contrib/datafusion-sqlancer"&gt;SQLancer&lt;/a&gt;, &lt;a href="https://github.com/datafusion-contrib/datafusion-functions-variant"&gt;Open Variant&lt;/a&gt;, &lt;a href="https://github.com/datafusion-contrib/datafusion-functions-json"&gt;JSON&lt;/a&gt;, and &lt;a href="https://github.com/datafusion-contrib/datafusion-orc"&gt;ORC&lt;/a&gt;.  &lt;/li&gt;
&lt;/ol&gt;
&lt;!--
$ git log --pretty=oneline 34.0.0..40.0.0 . | wc -l
     1453 (up from 1009)

$ git shortlog -sn 34.0.0..40.0.0 . | wc -l
      182 (up from 124)

https://crates.io/crates/datafusion/34.0.0
DataFusion 34 released Dec 17, 2023

https://crates.io/crates/datafusion/40.0.0
DataFusion 34 released July 12, 2024

Issues created in this time: 321 open, 781 closed (up from 214 open, 437 closed)
https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+created%3A2023-12-17..2024-07-12

Issues closed: 911 (up from 517)
https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+closed%3A2023-12-17..2024-07-12

PRs merged in this time 1490 (up from 908)
https://github.com/apache/arrow-datafusion/pulls?q=is%3Apr+merged%3A2023-12-17..2024-07-12

--&gt;
&lt;p&gt;In addition, DataFusion has been appearing publicly more and more, both online and offline. Here are some highlights:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://dl.acm.org/doi/10.1145/3626246.3653368"&gt;Apache Arrow DataFusion: A Fast, Embeddable, Modular Analytic Query Engine&lt;/a&gt;, was presented in &lt;a href="https://2024.sigmod.org/"&gt;SIGMOD '24&lt;/a&gt;, one of the major database conferences&lt;/li&gt;
&lt;li&gt;As part of the trend to define "the POSIX of databases" in &lt;a href="https://db.cs.cmu.edu/papers/2024/whatgoesaround-sigmodrec2024.pdf"&gt;"What Goes Around Comes Around... And Around..."&lt;/a&gt; from Andy Pavlo and Mike Stonebraker&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cpard.xyz/posts/datafusion/"&gt;"Why you should keep an eye on Apache DataFusion and its community"&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tisonkun.org/2024/07/15/datafusion-meetup-san-francisco/"&gt;Apache DataFusion offline meetup in the Bay Area&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Improved Performance 🚀&lt;/h2&gt;
&lt;p&gt;Performance is a key feature of DataFusion, and the community continues to work
to keep DataFusion state of the art in this area. One major area DataFusion
improved is the time it takes to convert a SQL query into a plan that can be
executed. Planning is now almost 2x faster for TPC-DS and TPC-H queries, and
over 10x faster for some queries with many columns.&lt;/p&gt;
&lt;p&gt;Here is a chart showing the improvement due to the concerted effort of many
contributors including &lt;a href="https://github.com/jackwener"&gt;@jackwener&lt;/a&gt;, &lt;a href="https://github.com/alamb"&gt;@alamb&lt;/a&gt;, &lt;a href="https://github.com/Lordworms"&gt;@Lordworms&lt;/a&gt;, &lt;a href="https://github.com/dmitrybugakov"&gt;@dmitrybugakov&lt;/a&gt;,
&lt;a href="https://github.com/appletreeisyellow"&gt;@appletreeisyellow&lt;/a&gt;, &lt;a href="https://github.com/ClSlaid"&gt;@ClSlaid&lt;/a&gt;, &lt;a href="https://github.com/rohitrastogi"&gt;@rohitrastogi&lt;/a&gt;, &lt;a href="https://github.com/emgeee"&gt;@emgeee&lt;/a&gt;, &lt;a href="https://github.com/kevinmingtarja"&gt;@kevinmingtarja&lt;/a&gt;,
and &lt;a href="https://github.com/peter-toth"&gt;@peter-toth&lt;/a&gt; over several months (see &lt;a href="https://github.com/apache/arrow-datafusion/issues/8045"&gt;ticket&lt;/a&gt; for more details)&lt;/p&gt;
&lt;p&gt;&lt;img src="../images/datafusion-40.0.0/improved-planning-time.png" width="700"/&gt;&lt;/p&gt;
&lt;p&gt;DataFusion is now up to 40% faster for queries that &lt;code&gt;GROUP BY&lt;/code&gt; a single string
or binary column due to a &lt;a href="https://github.com/apache/datafusion/pull/8827"&gt;specialization for single
Uft8/LargeUtf8/Binary/LargeBinary&lt;/a&gt;. We are working on improving performance when
there are [multiple variable length columns in the &lt;code&gt;GROUP BY&lt;/code&gt; clause].&lt;/p&gt;
&lt;p&gt;We are also in the final phases of &lt;a href="https://github.com/apache/datafusion/issues/10918"&gt;integrating&lt;/a&gt; the new &lt;a href="https://docs.rs/arrow/latest/arrow/array/struct.GenericByteViewArray.html"&gt;Arrow StringView&lt;/a&gt;
which significantly improves performance for workloads that scan, filter and
group by variable length string and binary data. We expect the improvement to be
especially pronounced for Parquet files due to &lt;a href="https://github.com/apache/arrow-rs/issues/5530"&gt;upstream work in the parquet
reader&lt;/a&gt;. Kudos to &lt;a href="https://github.com/XiangpengHong"&gt;@XiangpengHong&lt;/a&gt;, &lt;a href="https://github.com/AriesDevil"&gt;@AriesDevil&lt;/a&gt;, &lt;a href="https://github.com/PsiACE"&gt;@PsiACE&lt;/a&gt;, &lt;a href="https://github.com/Weijun-H"&gt;@Weijun-H&lt;/a&gt;,
&lt;a href="https://github.com/a10y"&gt;@a10y&lt;/a&gt;, and &lt;a href="https://github.com/RinChanNOWWW"&gt;@RinChanNOWWW&lt;/a&gt; for driving this project.&lt;/p&gt;
&lt;h2&gt;Improved Quality 📋&lt;/h2&gt;
&lt;p&gt;DataFusion continues to improve overall in quality. In addition to ongoing bug
fixes, one of the most exciting improvements is the addition of a new &lt;a href="https://github.com/datafusion-contrib/datafusion-sqlancer"&gt;SQLancer&lt;/a&gt;
based &lt;a href="https://github.com/apache/datafusion/issues/11030"&gt;DataFusion Fuzzing&lt;/a&gt; suite thanks to &lt;a href="https://github.com/2010YOUY01"&gt;@2010YOUY01&lt;/a&gt; that has already found
several bugs and thanks to &lt;a href="https://github.com/jonahgao"&gt;@jonahgao&lt;/a&gt;, &lt;a href="https://github.com/tshauck"&gt;@tshauck&lt;/a&gt;, &lt;a href="https://github.com/xinlifoobar"&gt;@xinlifoobar&lt;/a&gt;,
&lt;a href="https://github.com/LorrensP-2158466"&gt;@LorrensP-2158466&lt;/a&gt; for fixing them so fast.&lt;/p&gt;
&lt;h2&gt;Improved Documentation 📚&lt;/h2&gt;
&lt;p&gt;We continue to improve the documentation to make it easier to get started using DataFusion with
the &lt;a href="https://datafusion.apache.org/library-user-guide/index.html"&gt;Library Users Guide&lt;/a&gt;, &lt;a href="https://docs.rs/datafusion/latest/datafusion/index.html"&gt;API documentation&lt;/a&gt;, and &lt;a href="https://github.com/apache/datafusion/tree/main/datafusion-examples"&gt;Examples&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Some notable new examples include:
* &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/sql_analysis.rs"&gt;sql_analysis.rs&lt;/a&gt; to analyse SQL queries with DataFusion structures (thanks &lt;a href="https://github.com/LorrensP-2158466"&gt;@LorrensP-2158466&lt;/a&gt;)
* &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/function_factory.rs"&gt;function_factory.rs&lt;/a&gt; to create custom functions via SQL (thanks &lt;a href="https://github.com/milenkovicm"&gt;@milenkovicm&lt;/a&gt;)
* &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/plan_to_sql.rs"&gt;plan_to_sql.rs&lt;/a&gt; to generate SQL from DataFusion Expr and LogicalPlan (thanks &lt;a href="https://github.com/edmondop"&gt;@edmondop&lt;/a&gt;)
* &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/parquet_index.rs"&gt;parquet_index.rs&lt;/a&gt; and &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/advanced_parquet_index.rs"&gt;advanced_parquet_index.rs&lt;/a&gt; for parquet indexing, described more below (thanks &lt;a href="https://github.com/alamb"&gt;@alamb&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;New Features ✨&lt;/h2&gt;
&lt;p&gt;There are too many new features in the last 6 months to list them all, but here
are some highlights:&lt;/p&gt;
&lt;h1&gt;SQL&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Support for &lt;code&gt;UNNEST&lt;/code&gt; (thanks &lt;a href="https://github.com/duongcongtoai"&gt;@duongcongtoai&lt;/a&gt;, &lt;a href="https://github.com/JasonLi-cn"&gt;@JasonLi-cn&lt;/a&gt; and &lt;a href="https://github.com/jayzhan211"&gt;@jayzhan211&lt;/a&gt;) &lt;/li&gt;
&lt;li&gt;Support for &lt;a href="https://github.com/apache/datafusion/issues/462"&gt;Recursive CTEs&lt;/a&gt; (thanks &lt;a href="https://github.com/jonahgao"&gt;@jonahgao&lt;/a&gt; and &lt;a href="https://github.com/matthewgapp"&gt;@matthewgapp&lt;/a&gt;) &lt;/li&gt;
&lt;li&gt;Support for &lt;code&gt;CREATE FUNCTION&lt;/code&gt; (see below) &lt;/li&gt;
&lt;li&gt;Many new SQL functions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DataFusion now has much improved support for structured types such &lt;code&gt;STRUCT&lt;/code&gt;,
&lt;code&gt;LIST&lt;/code&gt;/&lt;code&gt;ARRAY&lt;/code&gt; and &lt;code&gt;MAP&lt;/code&gt;. For example, you can now create &lt;code&gt;STRUCT&lt;/code&gt; literals 
in SQL like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="na"&gt;'foo&lt;/span&gt;&lt;span class="err"&gt;'&lt;/span&gt;: &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="na"&gt;'bar&lt;/span&gt;&lt;span class="err"&gt;'&lt;/span&gt;: &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;}};&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;+--------------------------------------------------------------+&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;named_struct&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"foo"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;named_struct&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"bar"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;Int64&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;+--------------------------------------------------------------+&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;: &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;: &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;}}&lt;/span&gt;&lt;span class="w"&gt;                                              &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;+--------------------------------------------------------------+&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;fetched&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Elapsed&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.002&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;SQL Unparser (SQL Formatter)&lt;/h1&gt;
&lt;p&gt;DataFusion now supports converting &lt;code&gt;Expr&lt;/code&gt;s and &lt;code&gt;LogicalPlan&lt;/code&gt;s BACK to SQL text.
This can be useful in query federation to push predicates down into other
systems that only accept SQL, and for building systems that generate SQL.&lt;/p&gt;
&lt;p&gt;For example, you can now convert a logical expression back to SQL text:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// Form a logical expression that represents the SQL "a &amp;lt; 5 OR a = 8"&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;lt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt;&lt;span class="n"&gt;or&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;eq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;// convert the expression back to SQL text&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expr_to_sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;assert_eq&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"a &amp;lt; 5 OR a = 8"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can also do complex things like parsing SQL, modifying the plan, and convert
it back to SQL:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;// Use SQL to read some data from the parquet file&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"SELECT int_col, double_col, CAST(date_string_col as VARCHAR) FROM alltypes_plain"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;await&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;// Programmatically add new filters `id &amp;gt; 1 and tinyint_col &amp;lt; double_col`&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"id"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;gt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt;&lt;span class="n"&gt;and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"tinyint_col"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;lt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"double_col"&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;// Convert the new logical plan back to SQL&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;plan_to_sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logical_plan&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_string&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;assert_eq&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;           &lt;/span&gt;&lt;span class="s"&gt;"SELECT alltypes_plain.int_col, alltypes_plain.double_col, CAST(alltypes_plain.date_string_col AS VARCHAR) \&lt;/span&gt;
&lt;span class="s"&gt;           FROM alltypes_plain WHERE ((alltypes_plain.id &amp;gt; 1) AND (alltypes_plain.tinyint_col &amp;lt; alltypes_plain.double_col))"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See the &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/plan_to_sql.rs"&gt;Plan to SQL example&lt;/a&gt; or the APIs &lt;a href="https://docs.rs/datafusion/latest/datafusion/sql/unparser/fn.expr_to_sql.html"&gt;expr_to_sql&lt;/a&gt; and &lt;a href="https://docs.rs/datafusion/latest/datafusion/sql/unparser/fn.plan_to_sql.html"&gt;plan_to_sql&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h1&gt;Low Level APIs for Fast Parquet Access (indexing)&lt;/h1&gt;
&lt;p&gt;With their rising prevalence, supporting efficient access to Parquet files
stored remotely on object storage is important. Part of doing this efficiently
is minimizing the number of object store requests made by caching metadata and
skipping over parts of the file that are not needed (e.g. via an index).&lt;/p&gt;
&lt;p&gt;DataFusion's Parquet reader has long internally supported &lt;a href="https://arrow.apache.org/blog/2022/12/26/querying-parquet-with-millisecond-latency/"&gt;advanced predicate
pushdown&lt;/a&gt; by reading the parquet metadata from the file footer and pruning based
on row group and data page statistics. DataFusion now also supports users
supplying their own low level pruning information via the [&lt;code&gt;ParquetAccessPlan&lt;/code&gt;]
API.&lt;/p&gt;
&lt;p&gt;This API can be used along with index information to selectively skip decoding
parts of the file. For example, Spice AI used this feature to add &lt;a href="https://github.com/spiceai/spiceai/pull/1891"&gt;efficient
support&lt;/a&gt; for reading from DeltaLake tables and handling &lt;a href="https://docs.delta.io/latest/delta-deletion-vectors.html"&gt;deletion vectors&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;        &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;   If the RowSelection does not include any
        &amp;boxv;          ...          &amp;boxv;   rows from a particular Data Page, that
        &amp;boxv;                       &amp;boxv;   Data Page is not fetched or decoded.
        &amp;boxv; &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl; &amp;boxv;   Note this requires a PageIndex
        &amp;boxv; &amp;boxv;     &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;  &amp;boxv; &amp;boxv;
Row     &amp;boxv; &amp;boxv;     &amp;boxv;DataPage 0&amp;boxv;  &amp;boxv; &amp;boxv;                 &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
Groups  &amp;boxv; &amp;boxv;     &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;  &amp;boxv; &amp;boxv;                 &amp;boxv;                    &amp;boxv;
        &amp;boxv; &amp;boxv;     &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;  &amp;boxv; &amp;boxv;                 &amp;boxv;    ParquetExec     &amp;boxv;
        &amp;boxv; &amp;boxv; ... &amp;boxv;DataPage 1&amp;boxv; ◀&amp;boxvh; &amp;boxvh; &amp;boxh; &amp;boxh; &amp;boxh;           &amp;boxv;  (Parquet Reader)  &amp;boxv;
        &amp;boxv; &amp;boxv;     &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;  &amp;boxv; &amp;boxv;      &amp;boxur; &amp;boxh; &amp;boxh; &amp;boxh; &amp;boxh; &amp;boxh;&amp;boxv;                    &amp;boxv;
        &amp;boxv; &amp;boxv;     &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;  &amp;boxv; &amp;boxv;                 &amp;boxv; &amp;boxDR;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxDL;  &amp;boxv;
        &amp;boxv; &amp;boxv;     &amp;boxv;DataPage 2&amp;boxv;  &amp;boxv; &amp;boxv; If only rows    &amp;boxv; &amp;boxV;ParquetMetadata&amp;boxV;  &amp;boxv;
        &amp;boxv; &amp;boxv;     &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;  &amp;boxv; &amp;boxv; from DataPage 1 &amp;boxv; &amp;boxUR;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxUL;  &amp;boxv;
        &amp;boxv; &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul; &amp;boxv; are selected,   &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
        &amp;boxv;                       &amp;boxv; only DataPage 1
        &amp;boxv;          ...          &amp;boxv; is fetched and
        &amp;boxv;                       &amp;boxv; decoded
        &amp;boxv; &amp;boxDR;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxDL; &amp;boxv;
        &amp;boxv; &amp;boxV;  Thrift metadata  &amp;boxV; &amp;boxv;
        &amp;boxv; &amp;boxUR;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxH;&amp;boxUL; &amp;boxv;
        &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
         Parquet File
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See the &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/parquet_index.rs"&gt;parquet_index.rs&lt;/a&gt; and &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/advanced_parquet_index.rs"&gt;advanced_parquet_index.rs&lt;/a&gt; examples for more details. &lt;/p&gt;
&lt;p&gt;Thanks to &lt;a href="https://github.com/alamb"&gt;@alamb&lt;/a&gt; and &lt;a href="https://github.com/Ted-Jiang"&gt;@Ted-Jiang&lt;/a&gt; for this feature.  &lt;/p&gt;
&lt;h2&gt;Building Systems is Easier with DataFusion 🛠️&lt;/h2&gt;
&lt;p&gt;In addition to many incremental API improvements, there are several new APIs that make
it easier to build systems on top of DataFusion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faster and easier to use &lt;a href="https://docs.rs/datafusion/latest/datafusion/common/tree_node/trait.TreeNode.html#overview"&gt;TreeNode API&lt;/a&gt; for traversing and manipulating plans and expressions.&lt;/li&gt;
&lt;li&gt;All functions now use the same &lt;a href="https://docs.rs/datafusion/latest/datafusion/logical_expr/trait.ScalarUDFImpl.html"&gt;Scalar User Defined Function API&lt;/a&gt;, making it easier to customize
  DataFusion's behavior without sacrificing performance. See &lt;a href="https://github.com/apache/arrow-datafusion/issues/8045"&gt;ticket&lt;/a&gt; for more details.&lt;/li&gt;
&lt;li&gt;DataFusion can now be compiled to &lt;a href="https://github.com/apache/datafusion/discussions/9834"&gt;WASM&lt;/a&gt;. &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;User Defined SQL Parsing Extensions&lt;/h1&gt;
&lt;p&gt;As of DataFusion 40.0.0, you can use the [&lt;code&gt;ExprPlanner&lt;/code&gt;] trait to extend
DataFusion's SQL planner to support custom operators or syntax.&lt;/p&gt;
&lt;p&gt;For example the &lt;a href="https://github.com/datafusion-contrib/datafusion-functions-json"&gt;datafusion-functions-json&lt;/a&gt; project uses this API to support
JSON operators in SQL queries. It provides a custom implementation for
planning JSON operators such as &lt;code&gt;-&amp;gt;&lt;/code&gt; and &lt;code&gt;-&amp;gt;&amp;gt;&lt;/code&gt; with code like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nc"&gt;MyCustomPlanner&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;impl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ExprPlanner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MyCustomPlanner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Provide custom implementation for planning a binary operators&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// such as `-&amp;gt;` and `-&amp;gt;&amp;gt;`&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;plan_binary_op&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;: &lt;span class="nc"&gt;RawBinaryExpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;_schema&lt;/span&gt;: &lt;span class="kp"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nc"&gt;DFSchema&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt; &lt;span class="nb"&gt;Result&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;PlannerResult&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;RawBinaryExpr&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;match&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;           &lt;/span&gt;&lt;span class="n"&gt;BinaryOperator&lt;/span&gt;::&lt;span class="n"&gt;Arrow&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/* plan -&amp;gt; operator */&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;           &lt;/span&gt;&lt;span class="n"&gt;BinaryOperator&lt;/span&gt;::&lt;span class="n"&gt;LongArrow&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/* plan -&amp;gt;&amp;gt; operator */&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;           &lt;/span&gt;&lt;span class="o"&gt;..&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Thanks to &lt;a href="https://github.com/samuelcolvin"&gt;@samuelcolvin&lt;/a&gt;, &lt;a href="https://github.com/jayzhan211"&gt;@jayzhan211&lt;/a&gt; and &lt;a href="https://github.com/dharanad"&gt;@dharanad&lt;/a&gt; for helping make this
feature happen.&lt;/p&gt;
&lt;h1&gt;Pluggable Support for &lt;code&gt;CREATE FUNCTION&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;DataFusion's new [&lt;code&gt;FunctionFactory&lt;/code&gt;] API let's users provide a handler for
&lt;code&gt;CREATE FUNCTION&lt;/code&gt; SQL statements. This feature lets you build systems that
support defining functions in SQL such as&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;-- SQL based functions&lt;/span&gt;
&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;FUNCTION&lt;/span&gt; &lt;span class="n"&gt;my_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DOUBLE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DOUBLE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;RETURNS&lt;/span&gt; &lt;span class="n"&gt;DOUBLE&lt;/span&gt;
    &lt;span class="k"&gt;RETURN&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="c1"&gt;-- ML Models&lt;/span&gt;
&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;FUNCTION&lt;/span&gt; &lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;FLOAT&lt;/span&gt;&lt;span class="p"&gt;[])&lt;/span&gt; &lt;span class="k"&gt;RETURNS&lt;/span&gt; &lt;span class="nb"&gt;FLOAT&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; 
&lt;span class="k"&gt;LANGUAGE&lt;/span&gt; &lt;span class="n"&gt;TORCH&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="s1"&gt;'models:/iris@champion'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="c1"&gt;-- WebAssembly&lt;/span&gt;
&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;FUNCTION&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;FLOAT&lt;/span&gt;&lt;span class="p"&gt;[])&lt;/span&gt; &lt;span class="k"&gt;RETURNS&lt;/span&gt; &lt;span class="nb"&gt;FLOAT&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; 
&lt;span class="k"&gt;LANGUAGE&lt;/span&gt; &lt;span class="n"&gt;WASM&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="s1"&gt;'func.wasm'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Huge thanks to &lt;a href="https://github.com/milenkovicm"&gt;@milenkovicm&lt;/a&gt; for this feature. There is an example of how to
make macro like functions in &lt;a href="https://github.com/apache/datafusion/blob/main/datafusion-examples/examples/function_factory.rs"&gt;function_factory.rs&lt;/a&gt;. It would be
great if &lt;a href="https://github.com/apache/datafusion/issues/9326"&gt;someone made a demo&lt;/a&gt; showing how to create WASMs 🎣.&lt;/p&gt;
&lt;h2&gt;Looking Ahead: The Next Six Months 🔭&lt;/h2&gt;
&lt;p&gt;The community has been &lt;a href="https://github.com/apache/datafusion/issues/11442"&gt;discussing what we will work on in the next six months&lt;/a&gt;.
Some major initiatives from that discussion are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Performance&lt;/em&gt;: Improve the speed of &lt;a href="https://github.com/apache/arrow-datafusion/issues/7000"&gt;aggregating "high cardinality"&lt;/a&gt;
  data when there are many (e.g. millions) of distinct groups as well as additional
  ideas to improve parquet performance. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Modularity&lt;/em&gt;: Make DataFusion even more modular, by completely unifying
   built in and user &lt;a href="https://github.com/apache/datafusion/issues/8708"&gt;aggregate functions&lt;/a&gt; and &lt;a href="https://github.com/apache/datafusion/issues/8709"&gt;window functions&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;LogicalTypes&lt;/em&gt;: &lt;a href="https://github.com/apache/datafusion/issues/11513"&gt;Introduce Logical Types&lt;/a&gt; to make it easier to use
   different encodings like &lt;code&gt;StringView&lt;/code&gt;, &lt;code&gt;RunEnd&lt;/code&gt; and &lt;code&gt;Dictionary&lt;/code&gt; arrays as well
   as user defined types. Thanks &lt;a href="https://github.com/notfilippo"&gt;@notfilippo&lt;/a&gt; for driving this. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Improved Documentation&lt;/em&gt;: Write blog posts and videos explaining
   how to use DataFusion for real-world use cases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Testing&lt;/em&gt;: Improve CI infrastructure and test coverage, more fuzz
   testing, and better functional and performance regression testing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;DataFusion is not a project built or driven by a single person, company, or
foundation. Rather, our community of users and contributors work together to
build a shared technology that none of us could have built alone.&lt;/p&gt;
&lt;p&gt;If you are interested in joining us we would love to have you. You can try out
DataFusion on some of your own data and projects and let us know how it goes,
contribute suggestions, documentation, bug reports, or a PR with documentation,
tests or code. A list of open issues suitable for beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt; and you
can find how to reach us on the &lt;a href="https://datafusion.apache.org/contributor-guide/communication.html"&gt;communication doc&lt;/a&gt;.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache DataFusion Comet 0.1.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2024/07/20/datafusion-comet-0.1.0" rel="alternate"></link><published>2024-07-20T00:00:00+00:00</published><updated>2024-07-20T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2024-07-20:/blog/blog/2024/07/20/datafusion-comet-0.1.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache DataFusion PMC is pleased to announce the first official source release of the &lt;a href="https://datafusion.apache.org/comet/"&gt;Comet&lt;/a&gt; subproject.&lt;/p&gt;
&lt;p&gt;Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.&lt;/p&gt;
&lt;p&gt;Comet runs on commodity hardware and aims …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache DataFusion PMC is pleased to announce the first official source release of the &lt;a href="https://datafusion.apache.org/comet/"&gt;Comet&lt;/a&gt; subproject.&lt;/p&gt;
&lt;p&gt;Comet is an accelerator for Apache Spark that translates Spark physical plans to DataFusion physical plans for
improved performance and efficiency without requiring any code changes.&lt;/p&gt;
&lt;p&gt;Comet runs on commodity hardware and aims to provide 100% compatibility with Apache Spark. Any operators or
expressions that are not fully compatible will fall back to Spark unless explicitly enabled by the user. Refer
to the &lt;a href="https://datafusion.apache.org/comet/user-guide/compatibility.html"&gt;compatibility guide&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;This release covers five months of development work since the project was &lt;a href="https://datafusion.apache.org/blog/2024/03/06/comet-donation/"&gt;donated&lt;/a&gt; to the Apache DataFusion
project and is the result of merging 343 PRs from 41 contributors. See the &lt;a href="https://github.com/apache/datafusion-comet/blob/main/dev/changelog/0.1.0.md"&gt;change log&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;This first release supports 15 &lt;a href="https://datafusion.apache.org/comet/user-guide/datatypes.html#"&gt;data types&lt;/a&gt;, 13 &lt;a href="https://datafusion.apache.org/comet/user-guide/operators.html#"&gt;operators&lt;/a&gt;, and 106 &lt;a href="https://datafusion.apache.org/comet/user-guide/expressions.html#"&gt;expressions&lt;/a&gt;. Comet is compatible with Apache
Spark versions 3.3, 3.4, and 3.5. There is also experimental support for preview versions of Spark 4.0.&lt;/p&gt;
&lt;h2&gt;Project Status&lt;/h2&gt;
&lt;p&gt;The project's recent focus has been on fixing correctness and stability issues and implementing additional
native operators and expressions so that a broader range of queries can be executed natively.&lt;/p&gt;
&lt;p&gt;Here are some of the highlights since the project was donated:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implemented native support for:&lt;/li&gt;
&lt;li&gt;SortMergeJoin&lt;/li&gt;
&lt;li&gt;HashJoin&lt;/li&gt;
&lt;li&gt;BroadcastHashJoin&lt;/li&gt;
&lt;li&gt;Columnar Shuffle&lt;/li&gt;
&lt;li&gt;More aggregate expressions&lt;/li&gt;
&lt;li&gt;Window aggregates&lt;/li&gt;
&lt;li&gt;Many Spark-compatible CAST expressions&lt;/li&gt;
&lt;li&gt;Implemented a simple Spark Fuzz Testing utility to find correctness issues&lt;/li&gt;
&lt;li&gt;Published a &lt;a href="https://datafusion.apache.org/comet/user-guide/overview.html"&gt;User Guide&lt;/a&gt; and &lt;a href="https://datafusion.apache.org/comet/contributor-guide/contributing.html"&gt;Contributors Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Created a &lt;a href="https://github.com/apache/datafusion-benchmarks"&gt;DataFusion Benchmarks&lt;/a&gt; repository with scripts and documentation for running benchmarks derived&lt;br/&gt;
  from TPC-H and TPC-DS with DataFusion and Comet&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Current Performance&lt;/h2&gt;
&lt;p&gt;Comet already delivers a modest performance speedup for many queries, enabling faster data processing and
shorter time-to-insights.&lt;/p&gt;
&lt;p&gt;We use benchmarks derived from the industry standard TPC-H and TPC-DS benchmarks for tracking progress with
performance. The following chart shows the time it takes to run the 22 TPC-H queries against 100 GB of data in
Parquet format using a single executor with eight cores. See the &lt;a href="https://datafusion.apache.org/comet/contributor-guide/benchmarking.html"&gt;Comet Benchmarking Guide&lt;/a&gt;
for details of the environment used for these benchmarks.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Chart showing TPC-H benchmark results for Comet 0.1.0" class="img-responsive" src="../images/comet-0.1.0/tpch_allqueries.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;Comet reduces the overall execution time from 626 seconds to 407 seconds, a 54% speedup (1.54x faster).&lt;/p&gt;
&lt;p&gt;Running the same queries with DataFusion standalone using the same number of cores results in a 3.9x speedup
compared to Spark. Although this isn&amp;rsquo;t a fair comparison (DataFusion does not have shuffle or match Spark
semantics in some cases, for example), it does give some idea about the potential future performance of
Comet. Comet aims to provide a 2x-4x speedup for a wide range of queries once more operators and expressions
can run natively.&lt;/p&gt;
&lt;p&gt;The following chart shows how much Comet currently accelerates each query from the benchmark.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Chart showing TPC-H benchmark results for Comet 0.1.0" class="img-responsive" src="../images/comet-0.1.0/tpch_queries_speedup.png" width="100%"/&gt;&lt;/p&gt;
&lt;p&gt;These benchmarks can be reproduced in any environment using the documentation in the &lt;a href="https://datafusion.apache.org/comet/contributor-guide/benchmarking.html"&gt;Comet Benchmarking Guide&lt;/a&gt;. We
encourage you to run these benchmarks in your environment or, even better, try Comet out with your existing Spark jobs.&lt;/p&gt;
&lt;h2&gt;Roadmap&lt;/h2&gt;
&lt;p&gt;Comet is an open-source project, and contributors are welcome to work on any features they are interested in, but
here are some current focus areas.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improve Performance &amp;amp; Reliability:&lt;/li&gt;
&lt;li&gt;Implement the remaining features needed so that all TPC-H queries can run entirely natively&lt;/li&gt;
&lt;li&gt;Implement spill support in SortMergeJoin&lt;/li&gt;
&lt;li&gt;Enable columnar shuffle by default&lt;/li&gt;
&lt;li&gt;Fully support Spark version 4.0.0&lt;/li&gt;
&lt;li&gt;Support more Spark operators and expressions&lt;/li&gt;
&lt;li&gt;We would like to support many more expressions natively in Comet, and this is a great place to start
    contributing. The contributors' guide has a section covering &lt;a href="https://datafusion.apache.org/comet/contributor-guide/adding_a_new_expression.html"&gt;adding support for new expressions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Move more Spark expressions into the &lt;a href="https://crates.io/crates/datafusion-comet-spark-expr"&gt;datafusion-comet-spark-expr&lt;/a&gt; crate. Although the main focus of the Comet
  project is to provide an accelerator for Apache Spark, we also publish a standalone crate containing
  Spark-compatible expressions that can be used by any project using DataFusion, without adding any dependencies
  on JVM or Apache Spark.&lt;/li&gt;
&lt;li&gt;Release Process &amp;amp; Documentation&lt;/li&gt;
&lt;li&gt;Implement a binary release process so that we can publish JAR files to Maven for all supported platforms&lt;/li&gt;
&lt;li&gt;Add documentation for running Spark and Comet in Kubernetes, and add example Dockerfiles.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Getting Involved&lt;/h2&gt;
&lt;p&gt;The Comet project welcomes new contributors. We use the same &lt;a href="https://datafusion.apache.org/contributor-guide/communication.html#slack-and-discord"&gt;Slack and Discord&lt;/a&gt; channels as the main DataFusion
project, and there is a Comet community video call held every four weeks on Wednesdays at 11:30 a.m. Eastern Time,
which is 16:30 UTC during Eastern Standard Time and 15:30 UTC during Eastern Daylight Time. See the
&lt;a href="https://docs.google.com/document/d/1NBpkIAuU7O9h8Br5CbFksDhX-L9TyO9wmGLPMe0Plc8/edit?usp=sharing"&gt;Comet Community Meeting&lt;/a&gt; Google Document for the next scheduled meeting date, the video call link, and
recordings of previous calls.&lt;/p&gt;
&lt;p&gt;The easiest way to get involved is to test Comet with your current Spark jobs and file issues for any bugs or
performance regressions that you find. See the &lt;a href="https://datafusion.apache.org/comet/user-guide/installation.html"&gt;Getting Started&lt;/a&gt; guide for instructions on downloading and installing
Comet.&lt;/p&gt;
&lt;p&gt;There are also many &lt;a href="https://github.com/apache/datafusion-comet/contribute"&gt;good first issues&lt;/a&gt; waiting for contributions.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Announcing Apache Arrow DataFusion is now Apache DataFusion</title><link href="https://datafusion.apache.org/blog/blog/2024/05/07/datafusion-tlp" rel="alternate"></link><published>2024-05-07T00:00:00+00:00</published><updated>2024-05-07T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2024-05-07:/blog/blog/2024/05/07/datafusion-tlp</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;TLDR; &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; DataFusion --&amp;gt; &lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Arrow PMC and newly created DataFusion PMC are happy to announce that as of
April 16, 2024 the Apache Arrow DataFusion subproject is now a top level
&lt;a href="https://www.apache.org/"&gt;Apache Software Foundation&lt;/a&gt; project.&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Apache DataFusion is a fast, extensible query engine for building …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;TLDR; &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; DataFusion --&amp;gt; &lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Arrow PMC and newly created DataFusion PMC are happy to announce that as of
April 16, 2024 the Apache Arrow DataFusion subproject is now a top level
&lt;a href="https://www.apache.org/"&gt;Apache Software Foundation&lt;/a&gt; project.&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Apache DataFusion is a fast, extensible query engine for building high-quality
data-centric systems in Rust, using the Apache Arrow in-memory format.&lt;/p&gt;
&lt;p&gt;When DataFusion was &lt;a href="https://arrow.apache.org/blog/2019/02/04/datafusion-donation/"&gt;donated to the Apache Software Foundation&lt;/a&gt; in 2019, the
DataFusion community was not large enough to stand on its own and the Arrow
project agreed to help support it. The community has grown significantly since
2019, benefiting immensely from being part of Arrow and following &lt;a href="https://www.apache.org/theapacheway/"&gt;The Apache
Way&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Why now?&lt;/h2&gt;
&lt;p&gt;The community &lt;a href="https://github.com/apache/datafusion/discussions/6475"&gt;discussed graduating to a top level project publicly&lt;/a&gt; for almost
a year, as the project seemed ready to stand on its own and would benefit from
more focused governance. For example, earlier in DataFusion's life many
contributed to both &lt;a href="https://github.com/apache/arrow-rs"&gt;arrow-rs&lt;/a&gt; and DataFusion, but as DataFusion has matured many
contributors, committers and PMC members focused more and more exclusively on
DataFusion.&lt;/p&gt;
&lt;h2&gt;Looking forward&lt;/h2&gt;
&lt;p&gt;The future looks bright. There are now &lt;a href="https://datafusion.apache.org/user-guide/introduction.html#known-users"&gt;10s of known projects built with
DataFusion&lt;/a&gt;, and that number continues to grow. We recently held our &lt;a href="https://github.com/apache/datafusion/discussions/8522"&gt;first in
person meetup&lt;/a&gt; passed &lt;a href="https://github.com/apache/datafusion/stargazers"&gt;5000 stars&lt;/a&gt; on GitHub, &lt;a href="https://github.com/apache/datafusion/issues/8373#issuecomment-2025133714"&gt;wrote a paper that was accepted
at SIGMOD 2024&lt;/a&gt;, and began work on &lt;a href="https://github.com/apache/datafusion-comet"&gt;Comet&lt;/a&gt;, an &lt;a href="https://spark.apache.org/"&gt;Apache Spark&lt;/a&gt; accelerator
&lt;a href="https://arrow.apache.org/blog/2024/03/06/comet-donation/"&gt;initially donated by Apple&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thank you to everyone in the Arrow community who helped DataFusion grow and
mature over the years, and we look forward to continuing our collaboration as
projects. All future blogs and announcements will be posted on the &lt;a href="https://datafusion.apache.org/"&gt;Apache
DataFusion&lt;/a&gt; website.&lt;/p&gt;
&lt;h2&gt;Get Involved&lt;/h2&gt;
&lt;p&gt;If you are interested in joining the community, we would love to have you join
us. Get in touch using &lt;a href="https://datafusion.apache.org/contributor-guide/communication.html"&gt;Communication Doc&lt;/a&gt; and learn how to get involved in the
&lt;a href="https://datafusion.apache.org/contributor-guide/index.html"&gt;Contributor Guide&lt;/a&gt;. We welcome everyone to try DataFusion on their
own data and projects and let us know how it goes, contribute suggestions,
documentation, bug reports, or a PR with documentation, tests or code.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Announcing Apache Arrow DataFusion Comet</title><link href="https://datafusion.apache.org/blog/blog/2024/03/06/comet-donation" rel="alternate"></link><published>2024-03-06T00:00:00+00:00</published><updated>2024-03-06T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2024-03-06:/blog/blog/2024/03/06/comet-donation</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The Apache Arrow PMC is pleased to announce the donation of the &lt;a href="https://github.com/apache/arrow-datafusion-comet"&gt;Comet project&lt;/a&gt;,
a native Spark SQL Accelerator built on &lt;a href="https://arrow.apache.org/datafusion"&gt;Apache Arrow DataFusion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Comet is an Apache Spark plugin that uses Apache Arrow DataFusion to
accelerate Spark workloads. It is designed as a drop-in
replacement for Spark's JVM …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The Apache Arrow PMC is pleased to announce the donation of the &lt;a href="https://github.com/apache/arrow-datafusion-comet"&gt;Comet project&lt;/a&gt;,
a native Spark SQL Accelerator built on &lt;a href="https://arrow.apache.org/datafusion"&gt;Apache Arrow DataFusion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Comet is an Apache Spark plugin that uses Apache Arrow DataFusion to
accelerate Spark workloads. It is designed as a drop-in
replacement for Spark's JVM based SQL execution engine and offers significant
performance improvements for some workloads as shown below.&lt;/p&gt;
&lt;figure style="text-align: center;"&gt;
&lt;img alt="Fig 1: Adaptive Arrow schema architecture overview." class="img-responsive" src="../images/datafusion-comet/comet-architecture.png" width="100%"/&gt;
&lt;figcaption&gt;
&lt;b&gt;Figure 1&lt;/b&gt;: With Comet, users interact with the same Spark ecosystem, tools
    and APIs such as Spark SQL. Queries still run through Spark's query optimizer and planner. 
    However, the execution is delegated to Comet,
    which is significantly faster and more resource efficient than a JVM based
    implementation.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Comet is one of a growing class of projects that aim to accelerate Spark using
native columnar engines such as the proprietary &lt;a href="https://www.databricks.com/product/photon"&gt;Databricks Photon Engine&lt;/a&gt; and
open source projects &lt;a href="https://incubator.apache.org/projects/gluten.html"&gt;Gluten&lt;/a&gt;, &lt;a href="https://github.com/NVIDIA/spark-rapids"&gt;Spark RAPIDS&lt;/a&gt;, and &lt;a href="https://github.com/kwai/blaze"&gt;Blaze&lt;/a&gt; (also built using
DataFusion).&lt;/p&gt;
&lt;p&gt;Comet was originally implemented at Apple and the engineers who worked on the
project are also significant contributors to Arrow and DataFusion. Bringing 
Comet into the Apache Software Foundation will accelerate its development and 
grow its community of contributors and users.&lt;/p&gt;
&lt;h1&gt;Get Involved&lt;/h1&gt;
&lt;p&gt;Comet is still in the early stages of development and we would love to have you
join us and help shape the project. We are working on an initial release, and 
expect to post another update with more details at that time.&lt;/p&gt;
&lt;p&gt;Before then, here are some ways to get involved:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Learn more by visiting the &lt;a href="https://github.com/apache/arrow-datafusion-comet"&gt;Comet project&lt;/a&gt; page and reading the &lt;a href="https://lists.apache.org/thread/0q1rb11jtpopc7vt1ffdzro0omblsh0s"&gt;mailing list
  discussion&lt;/a&gt; about the initial donation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Help us plan out the &lt;a href="https://github.com/apache/arrow-datafusion-comet/issues/19"&gt;roadmap&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Try out the project and provide feedback, file issues, and contribute code.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow DataFusion 34.0.0 Released, Looking Forward to 2024</title><link href="https://datafusion.apache.org/blog/blog/2024/01/19/datafusion-34.0.0" rel="alternate"></link><published>2024-01-19T00:00:00+00:00</published><updated>2024-01-19T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2024-01-19:/blog/blog/2024/01/19/datafusion-34.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;We recently &lt;a href="https://crates.io/crates/datafusion/34.0.0"&gt;released DataFusion 34.0.0&lt;/a&gt;. This blog highlights some of the major
improvements since we &lt;a href="https://arrow.apache.org/blog/2023/06/24/datafusion-25.0.0/."&gt;released DataFusion 26.0.0&lt;/a&gt; (spoiler alert there are many)
and a preview of where the community plans to focus in the next 6 months.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt; is an extensible query …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;We recently &lt;a href="https://crates.io/crates/datafusion/34.0.0"&gt;released DataFusion 34.0.0&lt;/a&gt;. This blog highlights some of the major
improvements since we &lt;a href="https://arrow.apache.org/blog/2023/06/24/datafusion-25.0.0/."&gt;released DataFusion 26.0.0&lt;/a&gt; (spoiler alert there are many)
and a preview of where the community plans to focus in the next 6 months.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt; is an extensible query engine, written in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, that
uses &lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt; as its in-memory format. DataFusion is used by developers to
create new, fast data centric systems such as databases, dataframe libraries,
machine learning and streaming applications. While &lt;a href="https://arrow.apache.org/datafusion/user-guide/introduction.html#project-goals"&gt;DataFusion&amp;rsquo;s primary design
goal&lt;/a&gt; is to accelerate creating other data centric systems, it has a
reasonable experience directly out of the box as a &lt;a href="https://arrow.apache.org/datafusion-python/"&gt;dataframe library&lt;/a&gt; and
&lt;a href="https://arrow.apache.org/datafusion/user-guide/cli.html"&gt;command line SQL tool&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This may also be our last update on the Apache Arrow Site. Future
updates will likely be on the DataFusion website as we are working to &lt;a href="https://github.com/apache/arrow-datafusion/discussions/6475"&gt;graduate
to a top level project&lt;/a&gt; (Apache Arrow DataFusion &amp;rarr; Apache DataFusion!) which
will help focus governance and project growth. Also exciting, our &lt;a href="https://github.com/apache/arrow-datafusion/discussions/8522"&gt;first
DataFusion in person meetup&lt;/a&gt; is planned for March 2024.&lt;/p&gt;
&lt;p&gt;DataFusion is very much a community endeavor. Our core thesis is that as a
community we can build much more advanced technology than any of us as
individuals or companies could alone. In the last 6 months between &lt;code&gt;26.0.0&lt;/code&gt; and
&lt;code&gt;34.0.0&lt;/code&gt;, community growth has been strong. We accepted and reviewed over a
thousand PRs from 124 different committers, created over 650 issues and closed 517
of them.
You can find a list of all changes in the detailed &lt;a href="https://github.com/apache/arrow-datafusion/blob/main/datafusion/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt;
&lt;!--
$ git log --pretty=oneline 26.0.0..34.0.0 . | wc -l
     1009

$ git shortlog -sn 26.0.0..34.0.0 . | wc -l
      124

https://crates.io/crates/datafusion/26.0.0
DataFusion 26 released June 7, 2023

https://crates.io/crates/datafusion/34.0.0
DataFusion 34 released Dec 17, 2023

Issues created in this time: 214 open, 437 closed
https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+created%3A2023-06-23..2023-12-17

Issues closes: 517
https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+closed%3A2023-06-23..2023-12-17+

PRs merged in this time 908
https://github.com/apache/arrow-datafusion/pulls?q=is%3Apr+merged%3A2023-06-23..2023-12-17
--&gt;
&lt;h1&gt;Improved Performance 🚀&lt;/h1&gt;
&lt;p&gt;Performance is a key feature of DataFusion, DataFusion is 
more than 2x faster on &lt;a href="https://benchmark.clickhouse.com/"&gt;ClickBench&lt;/a&gt; compared to version &lt;code&gt;25.0.0&lt;/code&gt;, as shown below:&lt;/p&gt;
&lt;!--
  Scripts: https://github.com/alamb/datafusion-duckdb-benchmark/tree/datafusion-25-34
  Spreadsheet: https://docs.google.com/spreadsheets/d/1FtI3652WIJMC5LmJbLfT3G06w0JQIxEPG4yfMafexh8/edit#gid=1879366976
  Average runtime on 25.0.0: 7.2s (for the queries that actually ran)
  Average runtime on 34.0.0: 3.6s (for the same queries that ran in 25.0.0)
--&gt;
&lt;figure style="text-align: center;"&gt;
&lt;img alt="Fig 1: Adaptive Arrow schema architecture overview." class="img-responsive" src="../images/datafusion-34.0.0/compare-new.png" width="100%"/&gt;
&lt;figcaption&gt;
&lt;b&gt;Figure 1&lt;/b&gt;: Performance improvement between &lt;code&gt;25.0.0&lt;/code&gt; and &lt;code&gt;34.0.0&lt;/code&gt; on ClickBench. 
    Note that DataFusion &lt;code&gt;25.0.0&lt;/code&gt;, could not run several queries due to 
    unsupported SQL (Q9, Q11, Q12, Q14) or memory requirements (Q33).
  &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure style="text-align: center;"&gt;
&lt;img alt="Fig 1: Adaptive Arrow schema architecture overview." class="img-responsive" src="../images/datafusion-34.0.0/compare.png" width="100%"/&gt;
&lt;figcaption&gt;
&lt;b&gt;Figure 2&lt;/b&gt;: Total query runtime for DataFusion &lt;code&gt;34.0.0&lt;/code&gt; and DataFusion &lt;code&gt;25.0.0&lt;/code&gt;.
  &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Here are some specific enhancements we have made to improve performance:
* &lt;a href="https://arrow.apache.org/blog/2023/08/05/datafusion_fast_grouping/"&gt;2-3x better aggregation performance with many distinct groups&lt;/a&gt;
* Partially ordered grouping / streaming grouping
* [Specialized operator for "TopK" &lt;code&gt;ORDER BY LIMIT XXX&lt;/code&gt;] 
* [Specialized operator for &lt;code&gt;min(col) GROUP BY .. ORDER by min(col) LIMIT XXX&lt;/code&gt;]
* &lt;a href="https://github.com/apache/arrow-datafusion/pull/8126"&gt;Improved join performance&lt;/a&gt;
* Eliminate redundant sorting with sort order aware optimizers&lt;/p&gt;
&lt;h1&gt;New Features ✨&lt;/h1&gt;
&lt;h2&gt;DML / Insert / Creating Files&lt;/h2&gt;
&lt;p&gt;DataFusion now supports writing data in parallel, to individual or multiple
files, using &lt;code&gt;Parquet&lt;/code&gt;, &lt;code&gt;CSV&lt;/code&gt;, &lt;code&gt;JSON&lt;/code&gt;, &lt;code&gt;ARROW&lt;/code&gt; and user defined formats.
&lt;a href="https://github.com/apache/arrow-datafusion/pull/7655"&gt;Benchmark results&lt;/a&gt; show improvements up to 5x in some cases.&lt;/p&gt;
&lt;p&gt;Similarly to reading, data can now be written to any [&lt;code&gt;ObjectStore&lt;/code&gt;]
implementation, including AWS S3, Azure Blob Storage, GCP Cloud Storage, local
files, and user defined implementations. While reading from &lt;a href="https://docs.rs/datafusion/latest/datafusion/datasource/listing/struct.ListingTable.html#features"&gt;hive style
partitioned tables&lt;/a&gt; has long been supported, it is now possible to write to such
tables as well.&lt;/p&gt;
&lt;p&gt;For example, to write to a local file:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;❯&lt;/span&gt; &lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;EXTERNAL&lt;/span&gt; &lt;span class="k"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;awesome_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;STORED&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;PARQUET&lt;/span&gt; &lt;span class="k"&gt;LOCATION&lt;/span&gt; &lt;span class="s1"&gt;'/tmp/my_awesome_table'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;rows&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="k"&gt;set&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Query&lt;/span&gt; &lt;span class="n"&gt;took&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;003&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;

&lt;span class="err"&gt;❯&lt;/span&gt; &lt;span class="k"&gt;INSERT&lt;/span&gt; &lt;span class="k"&gt;INTO&lt;/span&gt; &lt;span class="n"&gt;awesome_table&lt;/span&gt; &lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;my_source_table&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-------+&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;row&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="k"&gt;set&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Query&lt;/span&gt; &lt;span class="n"&gt;took&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;024&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can also write to files with the [&lt;code&gt;COPY&lt;/code&gt;], similarly to [DuckDB&amp;rsquo;s &lt;code&gt;COPY&lt;/code&gt;]:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;❯&lt;/span&gt; &lt;span class="k"&gt;COPY&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;my_source_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;TO&lt;/span&gt; &lt;span class="s1"&gt;'/tmp/output.json'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;     &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-------+&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;row&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="k"&gt;set&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Query&lt;/span&gt; &lt;span class="n"&gt;took&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;014&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ cat /tmp/output.json
&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"x"&lt;/span&gt;:1&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"x"&lt;/span&gt;:2&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"x"&lt;/span&gt;:3&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Improved &lt;code&gt;STRUCT&lt;/code&gt; and &lt;code&gt;ARRAY&lt;/code&gt; support&lt;/h2&gt;
&lt;p&gt;DataFusion &lt;code&gt;34.0.0&lt;/code&gt; has much improved &lt;code&gt;STRUCT&lt;/code&gt; and &lt;code&gt;ARRAY&lt;/code&gt;
support, including a full range of &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/scalar_functions.html#struct-functions"&gt;struct functions&lt;/a&gt; and &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/scalar_functions.html#array-functions"&gt;array functions&lt;/a&gt;.&lt;/p&gt;
&lt;!--
❯ create table my_table as values ([1,2,3]), ([2]), ([4,5]);
--&gt;
&lt;p&gt;For example, you can now use &lt;code&gt;[]&lt;/code&gt; syntax and &lt;code&gt;array_length&lt;/code&gt; to access and inspect arrays:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;❯&lt;/span&gt; &lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;column1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
         &lt;span class="n"&gt;column1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;first_element&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
         &lt;span class="n"&gt;array_length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;column1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;len&lt;/span&gt; 
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;my_table&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-----------+---------------+-----+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;column1&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;first_element&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;len&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-----------+---------------+-----+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;             &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;       &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;             &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;    &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;             &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;-----------+---------------+-----+&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;❯&lt;/span&gt; &lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;column1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;column1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'c0'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt;  &lt;span class="n"&gt;my_table&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;------------------+----------------------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;column1&lt;/span&gt;          &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;my_table&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;------------------+----------------------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;c0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;                  &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;c0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;                  &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;------------------+----------------------+&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;rows&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="k"&gt;set&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Query&lt;/span&gt; &lt;span class="n"&gt;took&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;002&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Other Features&lt;/h2&gt;
&lt;p&gt;Other notable features include:
* Support aggregating datasets that exceed memory size, with &lt;a href="https://github.com/apache/arrow-datafusion/pull/7400"&gt;group by spill to disk&lt;/a&gt;
* All operators now track and limit their memory consumption, including Joins&lt;/p&gt;
&lt;h1&gt;Building Systems is Easier with DataFusion 🛠️&lt;/h1&gt;
&lt;h2&gt;Documentation&lt;/h2&gt;
&lt;p&gt;It is easier than ever to get started using DataFusion with the
new &lt;a href="https://arrow.apache.org/datafusion/library-user-guide/index.html"&gt;Library Users Guide&lt;/a&gt; as well as significantly improved the &lt;a href="https://docs.rs/datafusion/latest/datafusion/index.html"&gt;API documentation&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;User Defined Window and Table Functions&lt;/h2&gt;
&lt;p&gt;In addition to DataFusion's &lt;a href="https://arrow.apache.org/datafusion/library-user-guide/adding-udfs.html#adding-a-scalar-udf"&gt;User Defined Scalar Functions&lt;/a&gt;, and &lt;a href="https://arrow.apache.org/datafusion/library-user-guide/adding-udfs.html#adding-an-aggregate-udf"&gt;User Defined Aggregate Functions&lt;/a&gt;, DataFusion now supports &lt;a href="https://arrow.apache.org/datafusion/library-user-guide/adding-udfs.html#adding-a-window-udf"&gt;User Defined Window Functions&lt;/a&gt; 
 and &lt;a href="https://arrow.apache.org/datafusion/library-user-guide/adding-udfs.html#adding-a-user-defined-table-function"&gt;User Defined Table Functions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For example, [the &lt;code&gt;datafusion-cli&lt;/code&gt;] implements a DuckDB style [&lt;code&gt;parquet_metadata&lt;/code&gt;]
function as a user defined table function (&lt;a href="https://github.com/apache/arrow-datafusion/blob/3f219bc929cfd418b0e3d3501f8eba1d5a2c87ae/datafusion-cli/src/functions.rs#L222-L248"&gt;source code here&lt;/a&gt;): &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;❯&lt;/span&gt; &lt;span class="k"&gt;SELECT&lt;/span&gt; 
      &lt;span class="n"&gt;path_in_schema&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row_group_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row_group_num_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stats_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stats_max&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_compressed_size&lt;/span&gt; 
&lt;span class="k"&gt;FROM&lt;/span&gt; 
      &lt;span class="n"&gt;parquet_metadata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'hits.parquet'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;path_in_schema&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'"WatchID"'&lt;/span&gt; 
&lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------+--------------+--------------------+---------------------+---------------------+-----------------------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;path_in_schema&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;row_group_id&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;row_group_num_rows&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;stats_min&lt;/span&gt;           &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;stats_max&lt;/span&gt;           &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;total_compressed_size&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------+--------------+--------------------+---------------------+---------------------+-----------------------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="ss"&gt;"WatchID"&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;            &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;450560&lt;/span&gt;             &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;4611687214012840539&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;9223369186199968220&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;3883759&lt;/span&gt;               &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="ss"&gt;"WatchID"&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;            &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;612174&lt;/span&gt;             &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;4611689135232456464&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;9223371478009085789&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;5176803&lt;/span&gt;               &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="ss"&gt;"WatchID"&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;            &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;344064&lt;/span&gt;             &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;4611692774829951781&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;9223363791697310021&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;3031680&lt;/span&gt;               &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;----------------+--------------+--------------------+---------------------+---------------------+-----------------------+&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="k"&gt;rows&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="k"&gt;set&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Query&lt;/span&gt; &lt;span class="n"&gt;took&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;053&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Growth of DataFusion 📈&lt;/h3&gt;
&lt;p&gt;DataFusion has been appearing more publically in the wild. For example
* New projects built using DataFusion such as &lt;a href="https://lancedb.com/"&gt;lancedb&lt;/a&gt;, &lt;a href="https://glaredb.com/"&gt;GlareDB&lt;/a&gt;, &lt;a href="https://www.arroyo.dev/"&gt;Arroyo&lt;/a&gt;, and &lt;a href="https://github.com/cmu-db/optd"&gt;optd&lt;/a&gt;.
* Public talks such as &lt;a href="https://www.youtube.com/watch?v=AJU9rdRNk9I"&gt;Apache Arrow Datafusion: Vectorized
  Execution Framework For Maximum Performance&lt;/a&gt; in &lt;a href="https://www.bagevent.com/event/8432178"&gt;CommunityOverCode Asia 2023&lt;/a&gt; 
* Blogs posts such as &lt;a href="https://www.synnada.ai/blog/apache-arrow-arrow-datafusion-ai-native-data-infra-an-interview-with-our-ceo-ozan"&gt;Apache Arrow, Arrow/DataFusion, AI-native Data Infra&lt;/a&gt;,
  &lt;a href="https://www.influxdata.com/blog/flight-datafusion-arrow-parquet-fdap-architecture-influxdb/"&gt;Flight, DataFusion, Arrow, and Parquet: Using the FDAP Architecture to build InfluxDB 3.0&lt;/a&gt;, and 
  &lt;a href="https://www.linkedin.com/pulse/guide-user-defined-functions-apache-arrow-datafusion-dade-aderemi/"&gt;A Guide to User-Defined Functions in Apache Arrow DataFusion&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We have also &lt;a href="https://github.com/apache/arrow-datafusion/issues/6782"&gt;submitted a paper&lt;/a&gt; to &lt;a href="https://2024.sigmod.org/"&gt;SIGMOD 2024&lt;/a&gt;, one of the
premiere database conferences, describing DataFusion in a technically formal
style and making the case that it is possible to create a modular and extensive query engine 
without sacrificing performance. We hope this paper helps people 
evaluating DataFusion for their needs understand it better.&lt;/p&gt;
&lt;h1&gt;DataFusion in 2024 🥳&lt;/h1&gt;
&lt;p&gt;Some major initiatives from contributors we know of this year are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Modularity&lt;/em&gt;: Make DataFusion even more modular, such as &lt;a href="https://github.com/apache/arrow-datafusion/issues/8045"&gt;unifying
   built in and user functions&lt;/a&gt;, making it easier to customize 
   DataFusion's behavior.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Community Growth&lt;/em&gt;: Graduate to our own top level Apache project, and
   subsequently add more committers and PMC members to keep pace with project
   growth.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Use case white papers&lt;/em&gt;: Write blog posts and videos explaining
   how to use DataFusion for real-world use cases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Testing&lt;/em&gt;: Improve CI infrastructure and test coverage, more fuzz
   testing, and better functional and performance regression testing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Planning Time&lt;/em&gt;: Reduce the time taken to plan queries, both &lt;a href="https://github.com/apache/arrow-datafusion/issues/7698"&gt;wide
   tables of 1000s of columns&lt;/a&gt;, and in &lt;a href="https://github.com/apache/arrow-datafusion/issues/5637"&gt;general&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Aggregate Performance&lt;/em&gt;: Improve the speed of &lt;a href="https://github.com/apache/arrow-datafusion/issues/7000"&gt;aggregating "high cardinality"&lt;/a&gt; data
   when there are many (e.g. millions) of distinct groups.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Statistics&lt;/em&gt;: &lt;a href="https://github.com/apache/arrow-datafusion/issues/8227"&gt;Improved statistics handling&lt;/a&gt; with an eye towards more
   sophisticated expression analysis and cost models.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to DataFusion we would love to have you
join us. You can try out DataFusion on some of your own data and projects and
let us know how it goes, contribute suggestions, documentation, bug reports, or
a PR with documentation, tests or code. A list of open issues
suitable for beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As the community grows, we are also looking to restart biweekly calls /
meetings. Timezones are always a challenge for such meetings, but we hope to
have two calls that can work for most attendees. If you are interested
in helping, or just want to say hi, please drop us a note via one of 
the methods listed in our &lt;a href="https://arrow.apache.org/datafusion/contributor-guide/communication.html"&gt;Communication Doc&lt;/a&gt;.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Aggregating Millions of Groups Fast in Apache Arrow DataFusion 28.0.0</title><link href="https://datafusion.apache.org/blog/blog/2023/08/05/datafusion_fast_grouping" rel="alternate"></link><published>2023-08-05T00:00:00+00:00</published><updated>2023-08-05T00:00:00+00:00</updated><author><name>alamb, Dandandan, tustvold</name></author><id>tag:datafusion.apache.org,2023-08-05:/blog/blog/2023/08/05/datafusion_fast_grouping</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;!-- Converted from Google Docs using https://www.buymeacoffee.com/docstomarkdown --&gt;
&lt;h2&gt;Aggregating Millions of Groups Fast in Apache Arrow DataFusion&lt;/h2&gt;
&lt;p&gt;Andrew Lamb, Dani&amp;euml;l Heres, Raphael Taylor-Davies,&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: this article was originally published on the &lt;a href="https://www.influxdata.com/blog/aggregating-millions-groups-fast-apache-arrow-datafusion"&gt;InfluxData Blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;TLDR&lt;/h2&gt;
&lt;p&gt;Grouped aggregations are a core part of any analytic tool, creating understandable summaries of huge data volumes. &lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt;&amp;rsquo;s parallel aggregation capability …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;!-- Converted from Google Docs using https://www.buymeacoffee.com/docstomarkdown --&gt;
&lt;h2&gt;Aggregating Millions of Groups Fast in Apache Arrow DataFusion&lt;/h2&gt;
&lt;p&gt;Andrew Lamb, Dani&amp;euml;l Heres, Raphael Taylor-Davies,&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: this article was originally published on the &lt;a href="https://www.influxdata.com/blog/aggregating-millions-groups-fast-apache-arrow-datafusion"&gt;InfluxData Blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;TLDR&lt;/h2&gt;
&lt;p&gt;Grouped aggregations are a core part of any analytic tool, creating understandable summaries of huge data volumes. &lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt;&amp;rsquo;s parallel aggregation capability is 2-3x faster in the &lt;a href="https://crates.io/crates/datafusion/28.0.0"&gt;newly released version &lt;code&gt;28.0.0&lt;/code&gt;&lt;/a&gt; for queries with a large number (10,000 or more) of groups.&lt;/p&gt;
&lt;p&gt;Improving aggregation performance matters to all users of DataFusion. For example, both InfluxDB, a &lt;a href="https://github.com/influxdata/influxdb"&gt;time series data platform&lt;/a&gt; and Coralogix, a &lt;a href="https://coralogix.com/?utm_source=InfluxDB&amp;amp;utm_medium=Blog&amp;amp;utm_campaign=organic"&gt;full-stack observability&lt;/a&gt; platform, aggregate vast amounts of raw data to monitor and create insights for our customers. Improving DataFusion&amp;rsquo;s performance lets us provide better user experiences by generating insights faster with fewer resources. Because DataFusion is open source and released under the permissive &lt;a href="https://github.com/apache/arrow-datafusion/blob/main/LICENSE.txt"&gt;Apache 2.0&lt;/a&gt; license, the whole DataFusion community benefits as well.&lt;/p&gt;
&lt;p&gt;With the new optimizations, DataFusion&amp;rsquo;s grouping speed is now close to DuckDB, a system that regularly reports &lt;a href="https://duckdblabs.github.io/db-benchmark/"&gt;great&lt;/a&gt; &lt;a href="https://duckdb.org/2022/03/07/aggregate-hashtable.html#experiments"&gt;grouping&lt;/a&gt; benchmark performance numbers. Figure 1 contains a representative sample of &lt;a href="https://github.com/ClickHouse/ClickBench/tree/main"&gt;ClickBench&lt;/a&gt; on a single Parquet file, and the full results are at the end of this article.&lt;/p&gt;
&lt;p&gt;&lt;img src="../images/datafusion_fast_grouping/summary.png" width="700"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;: Query performance for ClickBench queries on queries 16, 17, 18 and 19 on a single Parquet file for DataFusion &lt;code&gt;27.0.0&lt;/code&gt;, DataFusion &lt;code&gt;28.0.0&lt;/code&gt; and DuckDB &lt;code&gt;0.8.1&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Introduction to high cardinality grouping&lt;/h2&gt;
&lt;p&gt;Aggregation is a fancy word for computing summary statistics across many rows that have the same value in one or more columns. We call the rows with the same values &lt;em&gt;groups&lt;/em&gt; and &amp;ldquo;high cardinality&amp;rdquo; means there are a large number of distinct groups in the dataset. At the time of writing, a &amp;ldquo;large&amp;rdquo; number of groups in analytic engines is around 10,000.&lt;/p&gt;
&lt;p&gt;For example the &lt;a href="https://github.com/ClickHouse/ClickBench"&gt;ClickBench&lt;/a&gt; &lt;em&gt;hits&lt;/em&gt; dataset contains 100 million anonymized user clicks across a set of websites. ClickBench Query 17 is:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="ss"&gt;"UserID"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;"SearchPhrase"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;hits&lt;/span&gt;
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="ss"&gt;"UserID"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;"SearchPhrase"&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;DESC&lt;/span&gt; &lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In English, this query finds &amp;ldquo;the top ten (user, search phrase) combinations, across all clicks&amp;rdquo; and produces the following results (there are no search phrases for the top ten users):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;+---------------------+--------------+-----------------+
| UserID              | SearchPhrase | COUNT(UInt8(1)) |
+---------------------+--------------+-----------------+
| 1313338681122956954 |              | 29097           |
| 1907779576417363396 |              | 25333           |
| 2305303682471783379 |              | 10597           |
| 7982623143712728547 |              | 6669            |
| 7280399273658728997 |              | 6408            |
| 1090981537032625727 |              | 6196            |
| 5730251990344211405 |              | 6019            |
| 6018350421959114808 |              | 5990            |
| 835157184735512989  |              | 5209            |
| 770542365400669095  |              | 4906            |
+---------------------+--------------+-----------------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The ClickBench dataset contains&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;99,997,497 total rows[^1]&lt;/li&gt;
&lt;li&gt;17,630,976 different users (distinct UserIDs)[^2]&lt;/li&gt;
&lt;li&gt;6,019,103 different search phrases[^3]&lt;/li&gt;
&lt;li&gt;24,070,560 distinct combinations[^4] of (UserID, SearchPhrase)
Thus, to answer the query, DataFusion must map each of the 100M different input rows into one of the &lt;strong&gt;24 million different groups&lt;/strong&gt;, and keep count of how many such rows there are in each group.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;The solution&lt;/h2&gt;
&lt;p&gt;Like most concepts in databases and other analytic systems, the basic ideas of this algorithm are straightforward and taught in introductory computer science courses. You could compute the query with a program such as this[^5]:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;itemgetter&lt;/span&gt;

&lt;span class="c1"&gt;# read file&lt;/span&gt;
&lt;span class="n"&gt;hits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_parquet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'hits.parquet'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'pyarrow'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# build groups&lt;/span&gt;
&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;hits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterrows&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;group&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'UserID'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'SearchPhrase'&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
    &lt;span class="c1"&gt;# update the dict entry for the corresponding key&lt;/span&gt;
    &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# Print the top 10 values&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;itemgetter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This approach, while simple, is both slow and very memory inefficient. It requires over 40 seconds to compute the results for less than 1% of the dataset[^6]. Both DataFusion &lt;code&gt;28.0.0&lt;/code&gt; and DuckDB &lt;code&gt;0.8.1&lt;/code&gt; compute results in under 10 seconds for the &lt;em&gt;entire&lt;/em&gt; dataset.&lt;/p&gt;
&lt;p&gt;To answer this query quickly and efficiently, you have to write your code such that it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Keeps all cores busy aggregating via parallelized computation&lt;/li&gt;
&lt;li&gt;Updates aggregate values quickly, using vectorizable loops that are easy for compilers to translate into the high performance &lt;a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data"&gt;SIMD&lt;/a&gt; instructions available in modern CPUs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The rest of this article explains how grouping works in DataFusion and the improvements we made in &lt;code&gt;28.0.0&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Two phase parallel partitioned grouping&lt;/h3&gt;
&lt;p&gt;Both DataFusion &lt;code&gt;27.0.&lt;/code&gt; and &lt;code&gt;28.0.0&lt;/code&gt; use state-of-the-art, two phase parallel hash partitioned grouping, similar to other high-performance vectorized engines like &lt;a href="https://duckdb.org/2022/03/07/aggregate-hashtable.html"&gt;DuckDB&amp;rsquo;s Parallel Grouped Aggregates&lt;/a&gt;. In pictures this looks like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;            ▲                        ▲
            &amp;boxv;                        &amp;boxv;
            &amp;boxv;                        &amp;boxv;
            &amp;boxv;                        &amp;boxv;
&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;  &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;        GroupBy        &amp;boxv;  &amp;boxv;      GroupBy      &amp;boxv;      Step 4
&amp;boxv;        (Final)        &amp;boxv;  &amp;boxv;      (Final)      &amp;boxv;
&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;  &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
            ▲                        ▲
            &amp;boxv;                        &amp;boxv;
            &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhd;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
                         &amp;boxv;
                         &amp;boxv;
            &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
            &amp;boxv;       Repartition       &amp;boxv;               Step 3
            &amp;boxv;         HASH(x)         &amp;boxv;
            &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
                         ▲
                         &amp;boxv;
            &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
            &amp;boxv;                       &amp;boxv;
            &amp;boxv;                       &amp;boxv;
 &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;  &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
 &amp;boxv;      GroupyBy      &amp;boxv;  &amp;boxv;       GroupBy       &amp;boxv;      Step 2
 &amp;boxv;     (Partial)      &amp;boxv;  &amp;boxv;      (Partial)      &amp;boxv;
 &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;  &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
            ▲                       ▲
         &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxul;                       &amp;boxur;&amp;boxh;&amp;boxdl;
         &amp;boxv;                            &amp;boxv;
    .&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;.                  .&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;.
 ,&amp;boxh;'           '&amp;boxh;.            ,&amp;boxh;'           '&amp;boxh;.
;      Input      :          ;      Input      :      Step 1
:    Stream 1     ;          :    Stream 2     ;
 ╲               ╱            ╲               ╱
  '&amp;boxh;.         ,&amp;boxh;'              '&amp;boxh;.         ,&amp;boxh;'
     `&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;'                    `&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt;: Two phase repartitioned grouping: data flows from bottom (source) to top (results) in two phases. First (Steps 1 and 2), each core reads the data into a core-specific hash table, computing intermediate aggregates without any cross-core coordination. Then (Steps 3 and 4) DataFusion divides the data (&amp;ldquo;repartitions&amp;rdquo;) into distinct subsets by group value, and each subset is sent to a specific core which computes the final aggregate.&lt;/p&gt;
&lt;p&gt;The two phases are critical for keeping cores busy in a multi-core system. Both phases use the same hash table approach (explained in the next section), but differ in how the groups are distributed and the partial results emitted from the accumulators. The first phase aggregates data as soon as possible after it is produced. However, as shown in Figure 2, the groups can be anywhere in any input, so the same group is often found on many different cores. The second phase uses a hash function to redistribute data evenly across the cores, so each group value is processed by exactly one core which emits the final results for that group.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;   &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="k"&gt;After&lt;/span&gt; &lt;span class="n"&gt;Repartitioning&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;each&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;   &lt;span class="k"&gt;group&lt;/span&gt; &lt;span class="k"&gt;key&lt;/span&gt;  &lt;span class="n"&gt;appears&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;exactly&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;   &lt;span class="n"&gt;one&lt;/span&gt; &lt;span class="n"&gt;partition&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;

&lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt;

    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="k"&gt;Input&lt;/span&gt; &lt;span class="n"&gt;Stream&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;groups&lt;/span&gt;
      &lt;span class="p"&gt;...&lt;/span&gt;        &lt;span class="p"&gt;...&lt;/span&gt;      &lt;span class="k"&gt;values&lt;/span&gt; &lt;span class="k"&gt;are&lt;/span&gt; &lt;span class="n"&gt;spread&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;    &lt;span class="n"&gt;arbitrarily&lt;/span&gt; &lt;span class="n"&gt;over&lt;/span&gt; &lt;span class="k"&gt;each&lt;/span&gt; &lt;span class="k"&gt;input&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;

    &lt;span class="n"&gt;Core&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;      &lt;span class="n"&gt;Core&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 3&lt;/strong&gt;: Group value distribution across 2 cores during aggregation phases. In the first phase, every group value &lt;code&gt;1&lt;/code&gt;, &lt;code&gt;2&lt;/code&gt;, &lt;code&gt;3&lt;/code&gt;, &lt;code&gt;4&lt;/code&gt;, is present in the input stream processed by each core. In the second phase, after repartitioning, the group values &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;2&lt;/code&gt; are processed by core A, and values &lt;code&gt;3&lt;/code&gt; and &lt;code&gt;4&lt;/code&gt; are processed only by core B.&lt;/p&gt;
&lt;p&gt;There are some additional subtleties in the &lt;a href="https://github.com/apache/arrow-datafusion/blob/main/datafusion/core/src/physical_plan/aggregates/row_hash.rs"&gt;DataFusion implementation&lt;/a&gt; not mentioned above due to space constraints, such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The policy of when to emit data from the first phase&amp;rsquo;s hash table (e.g. because the data is partially sorted)&lt;/li&gt;
&lt;li&gt;Handling specific filters per aggregate (due to the &lt;code&gt;FILTER&lt;/code&gt; SQL clause)&lt;/li&gt;
&lt;li&gt;Data types of intermediate values (which may not be the same as the final output for some aggregates such as &lt;code&gt;AVG&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Action taken when memory use exceeds its budget.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Hash grouping&lt;/h3&gt;
&lt;p&gt;DataFusion queries can compute many different aggregate functions for each group, both &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/aggregate_functions.html"&gt;built in&lt;/a&gt; and/or user defined &lt;a href="https://docs.rs/datafusion/latest/datafusion/logical_expr/struct.AggregateUDF.html"&gt;&lt;code&gt;AggregateUDFs&lt;/code&gt;&lt;/a&gt;. The state for each aggregate function, called an &lt;em&gt;accumulator&lt;/em&gt;, is tracked with a hash table (DataFusion uses the excellent &lt;a href="https://docs.rs/hashbrown/latest/hashbrown/index.html"&gt;HashBrown&lt;/a&gt; &lt;a href="https://docs.rs/hashbrown/latest/hashbrown/raw/struct.RawTable.html"&gt;RawTable API&lt;/a&gt;), which logically stores the &amp;ldquo;index&amp;rdquo;  identifying the specific group value.&lt;/p&gt;
&lt;h3&gt;Hash grouping in &lt;code&gt;27.0.0&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;As shown in Figure 3, DataFusion &lt;code&gt;27.0.0&lt;/code&gt; stores the data in a &lt;a href="https://github.com/apache/arrow-datafusion/blob/4d93b6a3802151865b68967bdc4c7d7ef425b49a/datafusion/core/src/physical_plan/aggregates/utils.rs#L38-L50"&gt;&lt;code&gt;GroupState&lt;/code&gt;&lt;/a&gt; structure which, unsurprisingly, tracks the state for each group. The state for each group consists of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The actual value of the group columns, in &lt;a href="https://docs.rs/arrow-row/latest/arrow_row/index.html"&gt;Arrow Row&lt;/a&gt; format.&lt;/li&gt;
&lt;li&gt;In-progress accumulations (e.g. the running counts for the &lt;code&gt;COUNT&lt;/code&gt; aggregate) for each group, in one of two possible formats (&lt;a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/expr/src/accumulator.rs#L24-L49"&gt;&lt;code&gt;Accumulator&lt;/code&gt;&lt;/a&gt;  or &lt;a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/physical-expr/src/aggregate/row_accumulator.rs#L26-L46"&gt;&lt;code&gt;RowAccumulator&lt;/code&gt;&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Scratch space for tracking which rows match each aggregate in each batch.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;                           &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;
                           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                                      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                  &lt;span class="p"&gt;...&lt;/span&gt;                 &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;                                  &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;            &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;            &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;&lt;span class="k"&gt;group&lt;/span&gt; &lt;span class="k"&gt;values&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;OwnedRow&lt;/span&gt;        &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;            &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;5&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;            &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxvl;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;            &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;&lt;span class="k"&gt;Row&lt;/span&gt; &lt;span class="n"&gt;accumulator&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;              &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxh;&amp;boxvh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;&lt;span class="n"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;u8&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxvl;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxvl;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;&lt;span class="n"&gt;Accumulator&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxvl;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;&lt;span class="n"&gt;Accumulator&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;    &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="n"&gt;Box&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dyn&lt;/span&gt; &lt;span class="n"&gt;Accumulator&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
    &lt;span class="n"&gt;Hash&lt;/span&gt; &lt;span class="k"&gt;Table&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;         &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;      &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;&lt;span class="n"&gt;scratch&lt;/span&gt; &lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;u32&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;      &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;      &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="n"&gt;GroupState&lt;/span&gt;                       &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                   &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;▶&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                                      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
  &lt;span class="n"&gt;Hash&lt;/span&gt; &lt;span class="k"&gt;table&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                 &lt;span class="p"&gt;...&lt;/span&gt;                  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
  &lt;span class="k"&gt;index&lt;/span&gt; &lt;span class="k"&gt;into&lt;/span&gt; &lt;span class="n"&gt;group_states&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                                      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
                           &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;
                           &lt;span class="n"&gt;group_states&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;GroupState&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;

                           &lt;span class="n"&gt;There&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;one&lt;/span&gt; &lt;span class="n"&gt;GroupState&lt;/span&gt; &lt;span class="n"&gt;PER&lt;/span&gt; &lt;span class="k"&gt;GROUP&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt;: Hash group operator structure in DataFusion &lt;code&gt;27.0.0&lt;/code&gt;. A hash table maps each group to a GroupState which contains all the per-group states.&lt;/p&gt;
&lt;p&gt;To compute the aggregate, DataFusion performs the following steps for each input batch:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Calculate hash using &lt;a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/physical-expr/src/hash_utils.rs#L264-L307"&gt;efficient vectorized code&lt;/a&gt;, specialized for each data type.&lt;/li&gt;
&lt;li&gt;Determine group indexes for each input row using the hash table (creating new entries for newly seen groups).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion/blob/4ab8be57dee3bfa72dd105fbd7b8901b873a4878/datafusion/core/src/physical_plan/aggregates/row_hash.rs#L562-L602"&gt;Update Accumulators for each group that had input rows,&lt;/a&gt; assembling the rows into a contiguous range for vectorized accumulator if there are a sufficient number of them.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;DataFusion also stores the hash values in the table to avoid potentially costly hash recomputation when resizing the hash table.&lt;/p&gt;
&lt;p&gt;This scheme works very well for a relatively small number of distinct groups: all accumulators are efficiently updated with large contiguous batches of rows.&lt;/p&gt;
&lt;p&gt;However, this scheme is not ideal for high cardinality grouping due to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Multiple allocations per group&lt;/strong&gt; for the group value row format, as well as for the &lt;code&gt;RowAccumulator&lt;/code&gt;s and each  &lt;code&gt;Accumulator&lt;/code&gt;. The &lt;code&gt;Accumulator&lt;/code&gt; may have additional allocations within it as well.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-vectorized updates:&lt;/strong&gt; Accumulator updates often fall back to a slower non-vectorized form because the number of distinct groups is large (and thus number of values per group is small) in each input batch.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Hash grouping in &lt;code&gt;28.0.0&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;For &lt;code&gt;28.0.0&lt;/code&gt;, we rewrote the core group by implementation following traditional system optimization principles: fewer allocations, type specialization, and aggressive vectorization.&lt;/p&gt;
&lt;p&gt;DataFusion &lt;code&gt;28.0.0&lt;/code&gt; uses the same RawTable and still stores group indexes. The major differences, as shown in Figure 4, are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Group values are stored either&lt;ol&gt;
&lt;li&gt;Inline in the &lt;code&gt;RawTable&lt;/code&gt; (for single columns of primitive types), where the conversion to Row format costs more than its benefit&lt;/li&gt;
&lt;li&gt;In a separate &lt;a href="https://docs.rs/arrow-row/latest/arrow_row/struct.Row.html"&gt;Rows&lt;/a&gt; structure with a single contiguous allocation for all groups values, rather than an allocation per group. Accumulators manage the state for all the groups internally, so the code to update intermediate values is a tight type specialized loop. The new &lt;a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/physical-expr/src/aggregate/groups_accumulator/mod.rs#L66-L75"&gt;&lt;code&gt;GroupsAccumulator&lt;/code&gt;&lt;/a&gt; interface results in highly efficient type accumulator update loops.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdr;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdl;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┏━━━━━━━━━━━━━━━━━━━┓&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                 &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdr;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxdl;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="n"&gt;X&lt;/span&gt;   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;5&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;  &lt;span class="n"&gt;value1&lt;/span&gt;   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvr;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvl;&amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxvl;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="n"&gt;Q&lt;/span&gt;   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxh;&amp;boxh;&amp;boxvh;&amp;boxvh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;     &lt;span class="p"&gt;...&lt;/span&gt;      &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvr;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvl;&amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxvl;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxvh;&amp;boxh;╋&amp;boxh;▶&amp;boxv;&lt;/span&gt;              &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;   &lt;span class="p"&gt;...&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvr;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvl;&amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxvl;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;  &lt;span class="n"&gt;valueN&lt;/span&gt;   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;    &lt;span class="n"&gt;H&lt;/span&gt;   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvr;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxvl;&amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxvl;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;&lt;span class="k"&gt;values&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;     &lt;span class="k"&gt;Rows&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;   &lt;span class="p"&gt;...&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;           &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxur;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxul;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt;                   &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;  &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt; &lt;span class="err"&gt;&amp;boxh;&lt;/span&gt;   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                 &lt;span class="err"&gt;&amp;boxv;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="n"&gt;GroupsAccumulator&lt;/span&gt; &lt;span class="err"&gt;┃&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt; &lt;span class="err"&gt;┗━━━━━━━━━━━━━━━━━━━┛&lt;/span&gt; &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                  &lt;span class="n"&gt;Hash&lt;/span&gt; &lt;span class="k"&gt;Table&lt;/span&gt;       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                       &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;                                   &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;          &lt;span class="p"&gt;...&lt;/span&gt;          &lt;span class="err"&gt;&amp;boxv;&lt;/span&gt;
&lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;     &lt;span class="err"&gt;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&lt;/span&gt;
  &lt;span class="n"&gt;GroupState&lt;/span&gt;                               &lt;span class="n"&gt;Accumulators&lt;/span&gt;


&lt;span class="n"&gt;Hash&lt;/span&gt; &lt;span class="k"&gt;table&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;stores&lt;/span&gt; &lt;span class="n"&gt;group_indexes&lt;/span&gt;     &lt;span class="n"&gt;One&lt;/span&gt;  &lt;span class="n"&gt;GroupsAccumulator&lt;/span&gt;
&lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="k"&gt;group&lt;/span&gt; &lt;span class="k"&gt;values&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;                         &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="k"&gt;aggregate&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="k"&gt;Each&lt;/span&gt;
                                          &lt;span class="n"&gt;stores&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="k"&gt;state&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt;
&lt;span class="k"&gt;Group&lt;/span&gt; &lt;span class="k"&gt;values&lt;/span&gt; &lt;span class="k"&gt;are&lt;/span&gt; &lt;span class="n"&gt;stored&lt;/span&gt; &lt;span class="n"&gt;either&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;     &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="k"&gt;ALL&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;groups&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;typically&lt;/span&gt;
&lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;hash&lt;/span&gt; &lt;span class="k"&gt;table&lt;/span&gt; &lt;span class="k"&gt;or&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;single&lt;/span&gt;          &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;native&lt;/span&gt; &lt;span class="n"&gt;Vec&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="n"&gt;allocation&lt;/span&gt; &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;arrow&lt;/span&gt; &lt;span class="k"&gt;Row&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 5&lt;/strong&gt;: Hash group operator structure in DataFusion &lt;code&gt;28.0.0&lt;/code&gt;. Group values are stored either directly in the hash table, or in a single allocation using the arrow Row format. The hash table contains group indexes. A single &lt;code&gt;GroupsAccumulator&lt;/code&gt; stores the per-aggregate state for &lt;em&gt;all&lt;/em&gt; groups.&lt;/p&gt;
&lt;p&gt;This new structure improves performance significantly for high cardinality groups due to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Reduced allocations&lt;/strong&gt;: There are no longer any individual allocations per group.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Contiguous native accumulator states&lt;/strong&gt;: Type-specialized accumulators store the values for all groups in a single contiguous allocation using a &lt;a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"&gt;Rust Vec&amp;lt;T&amp;gt;&lt;/a&gt; of some native type.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vectorized state update&lt;/strong&gt;: The inner aggregate update loops, which are type-specialized and in terms of native &lt;code&gt;Vec&lt;/code&gt;s, are well-vectorized by the Rust compiler (thanks &lt;a href="https://llvm.org/"&gt;LLVM&lt;/a&gt;!).&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;p&gt;Some vectorized grouping implementations store the accumulator state row-wise directly in the hash table, which often uses modern CPU caches efficiently. Managing accumulator state in columnar fashion may sacrifice some cache locality, however it ensures the size of the hash table remains small, even when there are large numbers of groups and aggregates, making it easier for the compiler to vectorize the accumulator update.&lt;/p&gt;
&lt;p&gt;Depending on the cost of recomputing hash values, DataFusion &lt;code&gt;28.0.0&lt;/code&gt; may or may not store the hash values in the table. This optimizes the tradeoff between the cost of computing the hash value (which is expensive for strings, for example) vs. the cost of storing it in the hash table.&lt;/p&gt;
&lt;p&gt;One subtlety that arises from pushing state updates into GroupsAccumulators is that each accumulator must handle similar variations with/without filtering and with/without nulls in the input. DataFusion &lt;code&gt;28.0.0&lt;/code&gt; uses a templated &lt;a href="https://github.com/apache/arrow-datafusion/blob/a6dcd943051a083693c352c6b4279156548490a0/datafusion/physical-expr/src/aggregate/groups_accumulator/accumulate.rs#L28-L54"&gt;&lt;code&gt;NullState&lt;/code&gt;&lt;/a&gt; which encapsulates these common patterns across accumulators.&lt;/p&gt;
&lt;p&gt;The code structure is heavily influenced by the fact DataFusion is implemented using &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, a new(ish) systems programming language focused on speed and safety. Rust heavily discourages many of the traditional pointer casting &amp;ldquo;tricks&amp;rdquo; used in C/C++ hash grouping implementations. The DataFusion aggregation code is almost entirely &lt;a href="https://doc.rust-lang.org/nomicon/meet-safe-and-unsafe.html#:~:text=Safe%20Rust%20is%20the%20true,Undefined%20Behavior%20(a.k.a.%20UB)."&gt;&lt;code&gt;safe&lt;/code&gt;&lt;/a&gt;, deviating into &lt;code&gt;unsafe&lt;/code&gt; only when necessary. (Rust is a great choice because it makes DataFusion fast, easy to embed, and prevents many crashes and security issues often associated with multi-threaded C/C++ code).&lt;/p&gt;
&lt;h2&gt;ClickBench results&lt;/h2&gt;
&lt;p&gt;The full results of running the &lt;a href="https://github.com/ClickHouse/ClickBench/tree/main"&gt;ClickBench&lt;/a&gt; queries against the single Parquet file with DataFusion &lt;code&gt;27.0.0&lt;/code&gt;, DataFusion &lt;code&gt;28.0.0&lt;/code&gt;, and DuckDB &lt;code&gt;0.8.1&lt;/code&gt; are below. These numbers were run on a GCP &lt;code&gt;e2-standard-8 machine&lt;/code&gt; with 8 cores and 32 GB of RAM, using the scripts &lt;a href="https://github.com/alamb/datafusion-duckdb-benchmark"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As the industry moves towards data systems assembled from components, it is increasingly important that they exchange data using open standards such as &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; and &lt;a href="https://parquet.apache.org/"&gt;Parquet&lt;/a&gt; rather than custom storage and in-memory formats. Thus, this benchmark uses a single input Parquet file representative of many DataFusion users and aligned with the current trend in analytics of avoiding a costly load/transformation into a custom storage format prior to query.&lt;/p&gt;
&lt;p&gt;DataFusion now reaches near-DuckDB-speeds querying Parquet data. While we don&amp;rsquo;t plan to engage in a benchmarking shootout with a team that literally wrote &lt;a href="https://dl.acm.org/doi/abs/10.1145/3209950.3209955"&gt;Fair Benchmarking Considered Difficult&lt;/a&gt;, hopefully everyone can agree that DataFusion &lt;code&gt;28.0.0&lt;/code&gt; is a significant improvement.&lt;/p&gt;
&lt;p&gt;&lt;img src="../images/datafusion_fast_grouping/full.png" width="700"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 6&lt;/strong&gt;: Performance of DataFusion &lt;code&gt;27.0.0&lt;/code&gt;, DataFusion &lt;code&gt;28.0.0&lt;/code&gt;, and DuckDB &lt;code&gt;0.8.1&lt;/code&gt; on all 43 ClickBench queries against a single &lt;code&gt;hits.parquet&lt;/code&gt; file. Lower is better.&lt;/p&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;p&gt;DataFusion &lt;code&gt;27.0.0&lt;/code&gt; was not able to run several queries due to either planner bugs (Q9, Q11, Q12, 14) or running out of memory (Q33). DataFusion &lt;code&gt;28.0.0&lt;/code&gt; solves those issues.&lt;/p&gt;
&lt;p&gt;DataFusion is faster than DuckDB for query 21 and 22, likely due to optimized implementations of string pattern matching.&lt;/p&gt;
&lt;h2&gt;Conclusion: performance matters&lt;/h2&gt;
&lt;p&gt;Improving aggregation performance by more than a factor of two allows developers building products and projects with DataFusion to spend more time on value-added domain specific features. We believe building systems with DataFusion is much faster than trying to build something similar from scratch. DataFusion increases productivity because it eliminates the need to rebuild well-understood, but costly to implement, analytic database technology. While we&amp;rsquo;re pleased with the improvements in DataFusion &lt;code&gt;28.0.0&lt;/code&gt;, we are by no means done and are pursuing &lt;a href="https://github.com/apache/arrow-datafusion/issues/7000"&gt;(Even More) Aggregation Performance&lt;/a&gt;. The future for performance is bright.&lt;/p&gt;
&lt;h2&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;DataFusion is a &lt;a href="https://arrow.apache.org/datafusion/contributor-guide/communication.html"&gt;community effort&lt;/a&gt; and this work was not possible without contributions from many in the community. A special shout out to &lt;a href="https://github.com/sunchao"&gt;sunchao&lt;/a&gt;, &lt;a href="https://github.com/jyshen"&gt;yjshen&lt;/a&gt;, &lt;a href="https://github.com/yahoNanJing"&gt;yahoNanJing&lt;/a&gt;, &lt;a href="https://github.com/mingmwang"&gt;mingmwang&lt;/a&gt;, &lt;a href="https://github.com/ozankabak"&gt;ozankabak&lt;/a&gt;, &lt;a href="https://github.com/mustafasrepo"&gt;mustafasrepo&lt;/a&gt;, and everyone else who contributed ideas, reviews, and encouragement &lt;a href="https://github.com/apache/arrow-datafusion/pull/6800"&gt;during&lt;/a&gt; this &lt;a href="https://github.com/apache/arrow-datafusion/pull/6904"&gt;work&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;About DataFusion&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt; is an extensible query engine and database toolkit, written in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, that uses &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; as its in-memory format. DataFusion, along with &lt;a href="https://calcite.apache.org/"&gt;Apache Calcite&lt;/a&gt;, Facebook&amp;rsquo;s &lt;a href="https://github.com/facebookincubator/velox"&gt;Velox&lt;/a&gt;, and similar technology are part of the next generation &amp;ldquo;&lt;a href="https://www.usenix.org/publications/login/winter2018/khurana"&gt;Deconstructed Database&lt;/a&gt;&amp;rdquo; architectures, where new systems are built on a foundation of fast, modular components, rather than as a single tightly integrated system.&lt;/p&gt;
&lt;!-- Footnotes themselves at the bottom. --&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;p&gt;[^1]: &lt;code&gt;SELECT COUNT(*) FROM 'hits.parquet';&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[^2]: &lt;code&gt;SELECT COUNT(DISTINCT "UserID") as num_users FROM 'hits.parquet';&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[^3]: &lt;code&gt;SELECT COUNT(DISTINCT "SearchPhrase") as num_phrases FROM 'hits.parquet';&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[^4]: &lt;code&gt;SELECT COUNT(*) FROM (SELECT DISTINCT "UserID", "SearchPhrase" FROM 'hits.parquet')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;[^5]: Full script at &lt;a href="https://github.com/alamb/datafusion-duckdb-benchmark/blob/main/hash.py"&gt;hash.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[^6]: &lt;a href="https://datasets.clickhouse.com/hits_compatible/athena_partitioned/hits_%7B%7D.parquet"&gt;hits_0.parquet&lt;/a&gt;, one of the files from the partitioned ClickBench dataset, which has &lt;code&gt;100,000&lt;/code&gt; rows and is 117 MB in size. The entire dataset has &lt;code&gt;100,000,000&lt;/code&gt; rows in a single 14 GB Parquet file. The script did not complete on the entire dataset after 40 minutes, and used 212 GB RAM at peak.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow DataFusion 26.0.0</title><link href="https://datafusion.apache.org/blog/blog/2023/06/24/datafusion-25.0.0" rel="alternate"></link><published>2023-06-24T00:00:00+00:00</published><updated>2023-06-24T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2023-06-24:/blog/blog/2023/06/24/datafusion-25.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;It has been a whirlwind 6 months of DataFusion development since &lt;a href="https://arrow.apache.org/blog/2023/01/19/datafusion-16.0.0"&gt;our
last update&lt;/a&gt;: the community has grown, many features have been added,
performance improved and we are &lt;a href="https://github.com/apache/arrow-datafusion/discussions/6475"&gt;discussing&lt;/a&gt; branching out to our own
top level Apache Project.&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt; is an extensible query engine and database
toolkit …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;It has been a whirlwind 6 months of DataFusion development since &lt;a href="https://arrow.apache.org/blog/2023/01/19/datafusion-16.0.0"&gt;our
last update&lt;/a&gt;: the community has grown, many features have been added,
performance improved and we are &lt;a href="https://github.com/apache/arrow-datafusion/discussions/6475"&gt;discussing&lt;/a&gt; branching out to our own
top level Apache Project.&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt; is an extensible query engine and database
toolkit, written in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, that uses &lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt; as its in-memory
format.&lt;/p&gt;
&lt;p&gt;DataFusion, along with &lt;a href="https://calcite.apache.org"&gt;Apache Calcite&lt;/a&gt;, Facebook's &lt;a href="https://github.com/facebookincubator/velox"&gt;Velox&lt;/a&gt; and
similar technology are part of the next generation "&lt;a href="https://www.usenix.org/publications/login/winter2018/khurana"&gt;Deconstructed
Database&lt;/a&gt;" architectures, where new systems are built on a foundation
of fast, modular components, rather as a single tightly integrated
system.&lt;/p&gt;
&lt;p&gt;While single tightly integrated systems such as &lt;a href="https://spark.apache.org/"&gt;Spark&lt;/a&gt;, &lt;a href="https://duckdb.org"&gt;DuckDB&lt;/a&gt; and
&lt;a href="https://www.pola.rs/"&gt;Pola.rs&lt;/a&gt; are great pieces of technology, our community believes that
anyone developing new data heavy application, such as those common in
machine learning in the next 5 years, will &lt;strong&gt;require&lt;/strong&gt; a high
performance, vectorized, query engine to remain relevant. The only
practical way to gain access to such technology without investing many
millions of dollars to build a new tightly integrated engine, is
though open source projects like DataFusion and similar enabling
technologies such as &lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt; and &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;DataFusion is targeted primarily at developers creating other data
intensive analytics, and offers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;High performance, native, parallel streaming execution engine&lt;/li&gt;
&lt;li&gt;Mature &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/index.html"&gt;SQL support&lt;/a&gt;, featuring  subqueries, window functions, grouping sets, and more&lt;/li&gt;
&lt;li&gt;Built in support for Parquet, Avro, CSV, JSON and Arrow formats and easy extension for others&lt;/li&gt;
&lt;li&gt;Native DataFrame API and &lt;a href="https://arrow.apache.org/datafusion-python/"&gt;python bindings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.rs/datafusion/latest/datafusion/index.html"&gt;Well documented&lt;/a&gt; source code and architecture, designed to be customized to suit downstream project needs&lt;/li&gt;
&lt;li&gt;High quality, easy to use code &lt;a href="https://crates.io/crates/datafusion/versions"&gt;released every 2 weeks to crates.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Welcoming, open community, governed by the highly regarded and well understood &lt;a href="https://www.apache.org/"&gt;Apache Software Foundation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The rest of this post highlights some of the improvements we have made
to DataFusion over the last 6 months and a preview of where we are
heading. You can see a list of all changes in the detailed
&lt;a href="https://github.com/apache/arrow-datafusion/blob/main/datafusion/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;(Even) Better Performance&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://voltrondata.com/resources/speeds-and-feeds-hardware-and-software-matter"&gt;Various&lt;/a&gt; benchmarks show DataFusion to be quite close or &lt;a href="https://github.com/tustvold/access-log-bench"&gt;even
faster&lt;/a&gt; to the state of the art in analytic performance (at the moment
this seems to be DuckDB). We continually work on improving performance
(see &lt;a href="https://github.com/apache/arrow-datafusion/issues/5546"&gt;#5546&lt;/a&gt; for a list) and would love additional help in this area.&lt;/p&gt;
&lt;p&gt;DataFusion now reads single large Parquet files significantly faster by
&lt;a href="https://github.com/apache/arrow-datafusion/pull/5057"&gt;parallelizing across multiple cores&lt;/a&gt;. Native speeds for reading JSON
and CSV files are also up to 2.5x faster thanks to improvements
upstream in arrow-rs &lt;a href="https://github.com/apache/arrow-rs/pull/3479#issuecomment-1384353159"&gt;JSON reader&lt;/a&gt; and &lt;a href="https://github.com/apache/arrow-rs/pull/3365"&gt;CSV reader&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, we have integrated the &lt;a href="https://arrow.apache.org/blog/2022/11/07/multi-column-sorts-in-arrow-rust-part-1/"&gt;arrow-rs Row Format&lt;/a&gt; into DataFusion resulting in up to &lt;a href="https://github.com/apache/arrow-datafusion/pull/6163"&gt;2-3x faster sorting and merging&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Improved Documentation and Website&lt;/h2&gt;
&lt;p&gt;Part of growing the DataFusion community is ensuring that DataFusion's
features are understood and that it is easy to contribute and
participate. To that end the &lt;a href="https://arrow.apache.org/datafusion/"&gt;website&lt;/a&gt; has been cleaned up, &lt;a href="https://docs.rs/datafusion/latest/datafusion/index.html#architecture"&gt;the
architecture guide&lt;/a&gt; expanded, the &lt;a href="https://arrow.apache.org/datafusion/contributor-guide/roadmap.html"&gt;roadmap&lt;/a&gt; updated, and several
overview talks created:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apr 2023 &lt;em&gt;Query Engine&lt;/em&gt;: &lt;a href="https://youtu.be/NVKujPxwSBA"&gt;recording&lt;/a&gt; and &lt;a href="https://docs.google.com/presentation/d/1D3GDVas-8y0sA4c8EOgdCvEjVND4s2E7I6zfs67Y4j8/edit#slide=id.p"&gt;slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;April 2023 &lt;em&gt;Logical Plan and Expressions&lt;/em&gt;: &lt;a href="https://youtu.be/EzZTLiSJnhY"&gt;recording&lt;/a&gt; and &lt;a href="https://docs.google.com/presentation/d/1ypylM3-w60kVDW7Q6S99AHzvlBgciTdjsAfqNP85K30"&gt;slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;April 2023 &lt;em&gt;Physical Plan and Execution&lt;/em&gt;: &lt;a href="https://youtu.be/2jkWU3_w6z0"&gt;recording&lt;/a&gt; and &lt;a href="https://docs.google.com/presentation/d/1cA2WQJ2qg6tx6y4Wf8FH2WVSm9JQ5UgmBWATHdik0hg"&gt;slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;New Features&lt;/h2&gt;
&lt;h3&gt;More Streaming, Less Memory&lt;/h3&gt;
&lt;p&gt;We have made significant progress on the &lt;a href="https://github.com/apache/arrow-datafusion/issues/4285"&gt;streaming execution roadmap&lt;/a&gt;
such as &lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/trait.ExecutionPlan.html#method.unbounded_output"&gt;unbounded datasources&lt;/a&gt;, &lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/aggregates/enum.GroupByOrderMode.html"&gt;streaming group by&lt;/a&gt;, sophisticated
&lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_optimizer/global_sort_selection/index.html"&gt;sort&lt;/a&gt; and &lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_optimizer/repartition/index.html"&gt;repartitioning&lt;/a&gt; improvements in the optimizer, and support
for &lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/joins/struct.SymmetricHashJoinExec.html"&gt;symmetric hash join&lt;/a&gt; (read more about that in the great &lt;a href="https://www.synnada.ai/blog/general-purpose-stream-joins-via-pruning-symmetric-hash-joins"&gt;Synnada
Blog Post&lt;/a&gt; on the topic). Together, these features both 1) make it
easier to build streaming systems using DataFusion that can
incrementally generate output before (or ever) seeing the end of the
input and 2) allow general queries to use less memory and generate their
results faster.&lt;/p&gt;
&lt;p&gt;We have also improved the runtime &lt;a href="https://docs.rs/datafusion/latest/datafusion/execution/memory_pool/index.html"&gt;memory management&lt;/a&gt; system so that
DataFusion now stays within its declared memory budget &lt;a href="https://github.com/apache/arrow-datafusion/issues/3941"&gt;generate
runtime errors&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;DML Support (&lt;code&gt;INSERT&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;, &lt;code&gt;UPDATE&lt;/code&gt;, etc)&lt;/h3&gt;
&lt;p&gt;Part of building high performance data systems includes writing data,
and DataFusion supports several features for creating new files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;INSERT INTO&lt;/code&gt; and &lt;code&gt;SELECT ... INTO&lt;/code&gt; support for memory backed and CSV tables&lt;/li&gt;
&lt;li&gt;New &lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/insert/trait.DataSink.html"&gt;API for writing data into TableProviders&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are working on easier to use &lt;a href="https://github.com/apache/arrow-datafusion/issues/5654"&gt;COPY INTO&lt;/a&gt; syntax, better support
for writing parquet, JSON, and AVRO, and more -- see our &lt;a href="https://github.com/apache/arrow-datafusion/issues/6569"&gt;tracking epic&lt;/a&gt;
for more details.&lt;/p&gt;
&lt;h3&gt;Timestamp and Intervals&lt;/h3&gt;
&lt;p&gt;One mark of the maturity of a SQL engine is how it handles the tricky
world of timestamp, date, times and interval arithmetic. DataFusion is
feature complete in this area and behaves as you would expect,
supporting queries such as&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'1 month'&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;my_table&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We still have a long tail of &lt;a href="https://github.com/apache/arrow-datafusion/issues/3148"&gt;date and time improvements&lt;/a&gt;, which we are working on as well.&lt;/p&gt;
&lt;h3&gt;Querying Structured Types (&lt;code&gt;List&lt;/code&gt; and &lt;code&gt;Struct&lt;/code&gt;s)&lt;/h3&gt;
&lt;p&gt;Arrow and Parquet &lt;a href="https://arrow.apache.org/blog/2022/10/08/arrow-parquet-encoding-part-2/"&gt;support nested data&lt;/a&gt; well and DataFusion lets you
easily query such &lt;code&gt;Struct&lt;/code&gt; and &lt;code&gt;List&lt;/code&gt;. For example, you can use
DataFusion to read and query the &lt;a href="https://data.mendeley.com/datasets/ct8f9skv97"&gt;JSON Datasets for Exploratory OLAP -
Mendeley Data&lt;/a&gt; like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;----------&lt;/span&gt;
&lt;span class="c1"&gt;-- Explore structured data using SQL&lt;/span&gt;
&lt;span class="c1"&gt;----------&lt;/span&gt;
&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;delete&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="s1"&gt;'twitter-sample-head-100000.parquet'&lt;/span&gt; &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="k"&gt;delete&lt;/span&gt; &lt;span class="k"&gt;IS&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt; &lt;span class="k"&gt;limit&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;---------------------------------------------------------------------------------------------------------------------------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="k"&gt;delete&lt;/span&gt;                                                                                                                    &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;---------------------------------------------------------------------------------------------------------------------------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;135037425050320896&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;135037425050320896&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;334902461&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;334902461&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134703982051463168&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134703982051463168&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;405383453&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;405383453&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134773741740765184&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134773741740765184&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;64823441&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;64823441&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;132543659655704576&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;132543659655704576&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;45917834&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;45917834&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;133786431926697984&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;133786431926697984&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;67229952&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;67229952&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt;   &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134619093570560002&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134619093570560002&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;182430773&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;182430773&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134019857527214080&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134019857527214080&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;257396311&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;257396311&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;133931546469076993&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;133931546469076993&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;124539548&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;124539548&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134397743350296576&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;134397743350296576&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;139836391&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;139836391&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{$&lt;/span&gt;&lt;span class="n"&gt;numberLong&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;127833661767823360&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;127833661767823360&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;244442687&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id_str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;244442687&lt;/span&gt;&lt;span class="err"&gt;}}&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;---------------------------------------------------------------------------------------------------------------------------+&lt;/span&gt;

&lt;span class="c1"&gt;----------&lt;/span&gt;
&lt;span class="c1"&gt;-- Select some deeply nested fields&lt;/span&gt;
&lt;span class="c1"&gt;----------&lt;/span&gt;
&lt;span class="k"&gt;SELECT&lt;/span&gt;
  &lt;span class="k"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'status'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'id'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'$numberLong'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;delete_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="k"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'status'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'user_id'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;delete_user_id&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="s1"&gt;'twitter-sample-head-100000.parquet'&lt;/span&gt; &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="k"&gt;delete&lt;/span&gt; &lt;span class="k"&gt;IS&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt; &lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;--------------------+----------------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;delete_id&lt;/span&gt;          &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;delete_user_id&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;--------------------+----------------+&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;135037425050320896&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;334902461&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;134703982051463168&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;405383453&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;134773741740765184&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;64823441&lt;/span&gt;       &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;132543659655704576&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;45917834&lt;/span&gt;       &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;133786431926697984&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;67229952&lt;/span&gt;       &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;134619093570560002&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;182430773&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;134019857527214080&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;257396311&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;133931546469076993&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;124539548&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;134397743350296576&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;139836391&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;127833661767823360&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="mi"&gt;244442687&lt;/span&gt;      &lt;span class="o"&gt;|&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="c1"&gt;--------------------+----------------+&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Subqueries All the Way Down&lt;/h3&gt;
&lt;p&gt;DataFusion can run many different subqueries by rewriting them to
joins. It has been able to run the full suite of TPC-H queries for at
least the last year, but recently we have implemented significant
improvements to this logic, sufficient to run almost all queries in
the TPC-DS benchmark as well.&lt;/p&gt;
&lt;h2&gt;Community and Project Growth&lt;/h2&gt;
&lt;p&gt;The six months since &lt;a href="https://arrow.apache.org/blog/2023/01/19/datafusion-16.0.0"&gt;our last update&lt;/a&gt; saw significant growth in
the DataFusion community. Between versions &lt;code&gt;17.0.0&lt;/code&gt; and &lt;code&gt;26.0.0&lt;/code&gt;,
DataFusion merged 711 PRs from 107 distinct contributors, not
including all the work that goes into our core dependencies such as
&lt;a href="https://crates.io/crates/arrow"&gt;arrow&lt;/a&gt;,
&lt;a href="https://crates.io/crates/parquet"&gt;parquet&lt;/a&gt;, and
&lt;a href="https://crates.io/crates/object_store"&gt;object_store&lt;/a&gt;, that much of
the same community helps support.&lt;/p&gt;
&lt;p&gt;In addition, we have added 7 new committers and 1 new PMC member to
the Apache Arrow project, largely focused on DataFusion, and we
learned about some of the cool &lt;a href="https://arrow.apache.org/datafusion/user-guide/introduction.html#known-users"&gt;new systems&lt;/a&gt; which are using
DataFusion. Given the growth of the community and interest in the
project, we also clarified the &lt;a href="https://github.com/apache/arrow-datafusion/discussions/6441"&gt;mission statement&lt;/a&gt; and are
&lt;a href="https://github.com/apache/arrow-datafusion/discussions/6475"&gt;discussing&lt;/a&gt; "graduate"ing DataFusion to a new top level
Apache Software Foundation project.&lt;/p&gt;
&lt;!--
$ git log --pretty=oneline 17.0.0..26.0.0 . | wc -l
     711

$ git shortlog -sn 17.0.0..26.0.0 . | wc -l
      107
--&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;Kudos to everyone in the community who has contributed ideas,
discussions, bug reports, documentation and code. It is exciting to be
innovating on the next generation of database architectures together!&lt;/p&gt;
&lt;p&gt;If you are interested in contributing to DataFusion, we would love to
have you join us. You can try out DataFusion on some of your own
data and projects and let us know how it goes or contribute a PR with
documentation, tests or code. A list of open issues suitable for
beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Check out our &lt;a href="https://arrow.apache.org/datafusion/contributor-guide/communication.html"&gt;Communication Doc&lt;/a&gt; for more ways to engage with the
community.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow DataFusion 16.0.0 Project Update</title><link href="https://datafusion.apache.org/blog/blog/2023/01/19/datafusion-16.0.0" rel="alternate"></link><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2023-01-19:/blog/blog/2023/01/19/datafusion-16.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an extensible
query execution framework, written in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;,
that uses &lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt; as its
in-memory format. It is targeted primarily at developers creating data
intensive analytics, and offers mature
&lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/index.html"&gt;SQL support&lt;/a&gt;,
a DataFrame API, and many extension points.&lt;/p&gt;
&lt;p&gt;Systems based on DataFusion perform very well in benchmarks …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an extensible
query execution framework, written in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;,
that uses &lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt; as its
in-memory format. It is targeted primarily at developers creating data
intensive analytics, and offers mature
&lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/index.html"&gt;SQL support&lt;/a&gt;,
a DataFrame API, and many extension points.&lt;/p&gt;
&lt;p&gt;Systems based on DataFusion perform very well in benchmarks,
especially considering they operate directly on parquet files rather
than first loading into a specialized format.  Some recent highlights
include &lt;a href="https://benchmark.clickhouse.com/"&gt;clickbench&lt;/a&gt; and the
&lt;a href="https://www.cloudfuse.io/dashboards/standalone-engines"&gt;Cloudfuse.io standalone query
engines&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;DataFusion is also part of a longer term trend, articulated clearly by
&lt;a href="http://www.cs.cmu.edu/~pavlo/"&gt;Andy Pavlo&lt;/a&gt; in his &lt;a href="https://ottertune.com/blog/2022-databases-retrospective/"&gt;2022 Databases
Retrospective&lt;/a&gt;.
Database frameworks are proliferating and it is likely that all OLAP
DBMSs and other data heavy applications, such as machine learning,
will &lt;strong&gt;require&lt;/strong&gt; a vectorized, highly performant query engine in the next
5 years to remain relevant.  The only practical way to make such
technology so widely available without many millions of dollars of
investment is though open source engine such as DataFusion or
&lt;a href="https://github.com/facebookincubator/velox"&gt;Velox&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The rest of this post describes the improvements made to DataFusion
over the last three months and some hints of where we are heading.&lt;/p&gt;
&lt;h2&gt;Community Growth&lt;/h2&gt;
&lt;p&gt;We again saw significant growth in the DataFusion community since &lt;a href="https://arrow.apache.org/blog/2022/10/25/datafusion-13.0.0/"&gt;our last update&lt;/a&gt;. There are some interesting metrics on &lt;a href="https://ossrank.com/p/1573-apache-arrow-datafusion"&gt;OSSRank&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The DataFusion 16.0.0 release consists of 543 PRs from 73 distinct contributors, not including all the work that goes into dependencies such as &lt;a href="https://crates.io/crates/arrow"&gt;arrow&lt;/a&gt;, &lt;a href="https://crates.io/crates/parquet"&gt;parquet&lt;/a&gt;, and &lt;a href="https://crates.io/crates/object_store"&gt;object_store&lt;/a&gt;, that much of the same community helps support. Thank you all for your help&lt;/p&gt;
&lt;!--
$ git log --pretty=oneline 13.0.0..16.0.0 . | wc -l
     543

$ git shortlog -sn 13.0.0..16.0.0 . | wc -l
      73
--&gt;
&lt;p&gt;Several &lt;a href="https://github.com/apache/arrow-datafusion#known-uses"&gt;new systems based on DataFusion&lt;/a&gt; were recently added:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/GreptimeTeam/greptimedb"&gt;Greptime DB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://synnada.ai/"&gt;Synnada&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PRQL/prql-query"&gt;PRQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/parseablehq/parseable"&gt;Parseable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/splitgraph/seafowl"&gt;SeaFowl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Performance 🚀&lt;/h2&gt;
&lt;p&gt;Performance and efficiency are core values for
DataFusion. While there is still a gap between DataFusion and the best of
breed, tightly integrated systems such as &lt;a href="https://duckdb.org"&gt;DuckDB&lt;/a&gt;
and &lt;a href="https://www.pola.rs/"&gt;Polars&lt;/a&gt;, DataFusion is
closing the gap quickly. Performance highlights from the last three
months:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Up to 30% Faster Sorting and Merging using the new &lt;a href="https://arrow.apache.org/blog/2022/11/07/multi-column-sorts-in-arrow-rust-part-1/"&gt;Row Format&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arrow.apache.org/blog/2022/12/26/querying-parquet-with-millisecond-latency/"&gt;Advanced predicate pushdown&lt;/a&gt;, directly on parquet, directly from object storage, enabling sub millisecond filtering. &lt;!-- Andrew nots: we should really get this turned on by default --&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;70%&lt;/code&gt; faster &lt;code&gt;IN&lt;/code&gt; expressions evaluation (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4057"&gt;#4057&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Sort and partition aware optimizations (&lt;a href="https://github.com/apache/arrow-datafusion/issues/3969"&gt;#3969&lt;/a&gt; and  &lt;a href="https://github.com/apache/arrow-datafusion/issues/4691"&gt;#4691&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Filter selectivity analysis (&lt;a href="https://github.com/apache/arrow-datafusion/issues/3868"&gt;#3868&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Runtime Resource Limits&lt;/h2&gt;
&lt;p&gt;Previously, DataFusion could potentially use unbounded amounts of memory for certain queries that included Sorts, Grouping or Joins.&lt;/p&gt;
&lt;p&gt;In version 16.0.0, it is possible to limit DataFusion's memory usage for Sorting and Grouping. We are looking for help adding similar limiting for Joins as well as expanding our algorithms to optionally spill to secondary storage. See &lt;a href="https://github.com/apache/arrow-datafusion/issues/3941"&gt;#3941&lt;/a&gt; for more detail.&lt;/p&gt;
&lt;h2&gt;SQL Window Functions&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Window_function_(SQL)"&gt;SQL Window Functions&lt;/a&gt; are useful for a variety of analysis and DataFusion's implementation support expanded significantly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Custom window frames such as &lt;code&gt;... OVER (ORDER BY ... RANGE BETWEEN 0.2 PRECEDING AND 0.2 FOLLOWING)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Unbounded window frames such as &lt;code&gt;... OVER (ORDER BY ... RANGE UNBOUNDED ROWS PRECEDING)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Support for the &lt;code&gt;NTILE&lt;/code&gt; window function (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4676"&gt;#4676&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Support for &lt;code&gt;GROUPS&lt;/code&gt; mode (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4155"&gt;#4155&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Improved Joins&lt;/h1&gt;
&lt;p&gt;Joins are often the most complicated operations to handle well in
analytics systems and DataFusion 16.0.0 offers significant improvements
such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cost based optimizer (CBO) automatically reorders join evaluations, selects algorithms (Merge / Hash), and pick build side based on available statistics and join type (&lt;code&gt;INNER&lt;/code&gt;, &lt;code&gt;LEFT&lt;/code&gt;, etc) (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4219"&gt;#4219&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Fast non &lt;code&gt;column=column&lt;/code&gt; equijoins such as &lt;code&gt;JOIN ON a.x + 5 = b.y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Better performance on non-equijoins (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4562"&gt;#4562&lt;/a&gt;) &lt;!-- TODO is this a good thing to mention as any time this is usd the query is going to go slow or the data size is small --&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Streaming Execution&lt;/h1&gt;
&lt;p&gt;One emerging use case for Datafusion is as a foundation for
streaming-first data platforms. An important prerequisite
is support for incremental execution for queries that can be computed
incrementally.&lt;/p&gt;
&lt;p&gt;With this release, DataFusion now supports the following streaming features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data ingestion from infinite files such as FIFOs (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4694"&gt;#4694&lt;/a&gt;),&lt;/li&gt;
&lt;li&gt;Detection of pipeline-breaking queries in streaming use cases (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4694"&gt;#4694&lt;/a&gt;),&lt;/li&gt;
&lt;li&gt;Automatic input swapping for joins so probe side is a data stream (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4694"&gt;#4694&lt;/a&gt;),&lt;/li&gt;
&lt;li&gt;Intelligent elision of pipeline-breaking sort operations whenever possible (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4691"&gt;#4691&lt;/a&gt;),&lt;/li&gt;
&lt;li&gt;Incremental execution for more types of queries; e.g. queries involving finite window frames (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4777"&gt;#4777&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are a major steps forward, and we plan even more improvements over the next few releases.&lt;/p&gt;
&lt;h1&gt;Better Support for Distributed Catalogs&lt;/h1&gt;
&lt;p&gt;16.0.0 has been enhanced support for asynchronous catalogs (&lt;a href="https://github.com/apache/arrow-datafusion/issues/4607"&gt;#4607&lt;/a&gt;)
to better support distributed metadata stores such as
&lt;a href="https://delta.io/"&gt;Delta.io&lt;/a&gt; and &lt;a href="https://iceberg.apache.org/"&gt;Apache
Iceberg&lt;/a&gt; which require asynchronous I/O
during planning to access remote catalogs. Previously, DataFusion
required synchronous access to all relevant catalog information.&lt;/p&gt;
&lt;h1&gt;Additional SQL Support&lt;/h1&gt;
&lt;p&gt;SQL support continues to improve, including some of these highlights:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add TPC-DS query planning regression tests &lt;a href="https://github.com/apache/arrow-datafusion/issues/4719"&gt;#4719&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support for &lt;code&gt;PREPARE&lt;/code&gt; statement &lt;a href="https://github.com/apache/arrow-datafusion/issues/4490"&gt;#4490&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Automatic coercions ast between Date and Timestamp &lt;a href="https://github.com/apache/arrow-datafusion/issues/4726"&gt;#4726&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support type coercion for timestamp and utf8 &lt;a href="https://github.com/apache/arrow-datafusion/issues/4312"&gt;#4312&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Full support for time32 and time64 literal values (&lt;code&gt;ScalarValue&lt;/code&gt;) &lt;a href="https://github.com/apache/arrow-datafusion/issues/4156"&gt;#4156&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;New functions, incuding &lt;code&gt;uuid()&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/4041"&gt;#4041&lt;/a&gt;, &lt;code&gt;current_time&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/4054"&gt;#4054&lt;/a&gt;, &lt;code&gt;current_date&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/4022"&gt;#4022&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Compressed CSV/JSON support &lt;a href="https://github.com/apache/arrow-datafusion/issues/3642"&gt;#3642&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The community has also invested in new &lt;a href="https://github.com/apache/arrow-datafusion/blob/master/datafusion/core/tests/sqllogictests/README.md"&gt;sqllogic based&lt;/a&gt; tests to keep improving DataFusion's quality with less effort.&lt;/p&gt;
&lt;h1&gt;Plan Serialization and Substrait&lt;/h1&gt;
&lt;p&gt;DataFusion now supports serialization of physical plans, with a custom protocol buffers format. In addition, we are adding initial support for &lt;a href="https://substrait.io/"&gt;Substrait&lt;/a&gt;, a Cross-Language Serialization for Relational Algebra&lt;/p&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;Kudos to everyone in the community who contributed ideas, discussions, bug reports, documentation and code. It is exciting to be building something so cool together!&lt;/p&gt;
&lt;p&gt;If you are interested in contributing to DataFusion, we would love to
have you join us. You can try out DataFusion on some of your own
data and projects and let us know how it goes or contribute a PR with
documentation, tests or code. A list of open issues suitable for
beginners is
&lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Check out our &lt;a href="https://arrow.apache.org/datafusion/community/communication.html"&gt;Communication Doc&lt;/a&gt; on more
ways to engage with the community.&lt;/p&gt;
&lt;h2&gt;Appendix: Contributor Shoutout&lt;/h2&gt;
&lt;p&gt;Here is a list of people who have contributed PRs to this project over the last three releases, derived from &lt;code&gt;git shortlog -sn 13.0.0..16.0.0 .&lt;/code&gt; Thank you all!&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="mi"&gt;113&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andrew&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Lamb&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;58&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;jakevin&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;46&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Raphael&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Taylor&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Davies&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Grove&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Batuhan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Taskaya&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Remzi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Yang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;ygf11&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Burak&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jeffrey&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Marco&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Neumann&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Kun&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Liu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Yang&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Jiang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;mingmwang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dani&amp;euml;l&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Heres&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Mustafa&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;akur&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;comphead&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;mvanschellebeeck&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;xudong&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dependabot&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bot&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;yahoNanJing&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Brent&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Gardner&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;AssHero&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jiayu&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Liu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Wei&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Ting&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Kuo&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;askoa&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andr&amp;eacute;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Calado&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Coroado&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Han&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mease&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Metehan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Y&amp;inodot;ld&amp;inodot;r&amp;inodot;m&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Nga&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Tran&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Ruihang&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Xia&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;baishen&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Berkay&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;&amp;Scedil;ahin&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Harris&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dongyan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Zhou&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Eduard&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Karacharov&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Kikkon&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Liang&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Chi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Hsieh&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Marko&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Milenkovi&amp;cacute;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Martin&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Grigorov&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Roman&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Nozdrin&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Tim&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Van&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Wassenhove&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="mf"&gt;.4&lt;/span&gt;&lt;span class="n"&gt;ntix&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;unconsolable&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;unvalley&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Ajaya&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Agrawal&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Alexander&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Spies&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;ArkashaJavelin&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Artjoms&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Iskovs&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;BoredPerson&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Christian&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Salvati&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Creampanda&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;Data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Psycho&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Francis&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Du&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Francis&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Le&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Roy&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;LFC&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Marko&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Grujic&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Matt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Willian&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Matthijs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Brobbel&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;Max&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Burke&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Mehmet&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Ozan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Kabak&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Rito&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Takeuchi&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Roman&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Zeyde&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Vrishabh&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Zhang&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Li&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;ZuoTiJia&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;byteink&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;cfraz89&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;nbr&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;xxchan&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;yujie&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zhang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;zembunia&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;哇呜哇呜呀咦耶&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow Ballista 0.9.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2022/10/28/ballista-0.9.0" rel="alternate"></link><published>2022-10-28T00:00:00+00:00</published><updated>2022-10-28T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2022-10-28:/blog/blog/2022/10/28/ballista-0.9.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/apache/arrow-ballista"&gt;Ballista&lt;/a&gt; is an Arrow-native distributed SQL query engine implemented in Rust.&lt;/p&gt;
&lt;p&gt;Ballista 0.9.0 is now available and is the most significant release since the project was &lt;a href="http://arrow.apache.org/blog/2021/04/12/ballista-donation/"&gt;donated&lt;/a&gt; to Apache
Arrow in 2021.&lt;/p&gt;
&lt;p&gt;This release represents 4 weeks of work, with 66 commits from 14 contributors:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andy …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/apache/arrow-ballista"&gt;Ballista&lt;/a&gt; is an Arrow-native distributed SQL query engine implemented in Rust.&lt;/p&gt;
&lt;p&gt;Ballista 0.9.0 is now available and is the most significant release since the project was &lt;a href="http://arrow.apache.org/blog/2021/04/12/ballista-donation/"&gt;donated&lt;/a&gt; to Apache
Arrow in 2021.&lt;/p&gt;
&lt;p&gt;This release represents 4 weeks of work, with 66 commits from 14 contributors:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Grove&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;yahoNanJing&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dani&amp;euml;l&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Heres&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Brent&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Gardner&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dependabot&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bot&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="mf"&gt;.4&lt;/span&gt;&lt;span class="n"&gt;ntix&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Stefan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Stanciulescu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;mingmwang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Ken&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Suenobu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Yang&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Jiang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Metehan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Y&amp;inodot;ld&amp;inodot;r&amp;inodot;m&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Trent&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Feda&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;askoa&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;yangzhong&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Release Highlights&lt;/h2&gt;
&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes
and improvements have been made: we refer you to the &lt;a href="https://github.com/apache/arrow-ballista/blob/0.9.0-rc2/ballista/CHANGELOG.md"&gt;complete changelog&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Support for Cloud Object Stores and Distributed File Systems&lt;/h3&gt;
&lt;p&gt;This is the first release of Ballista to have documented support for querying data from distributed file systems and
object stores. Currently, S3 and HDFS are supported. Support for Google Cloud Storage and Azure Blob Storage is planned
for the next release.&lt;/p&gt;
&lt;h3&gt;Flight SQL &amp;amp; JDBC support&lt;/h3&gt;
&lt;p&gt;The Ballista scheduler now implements the &lt;a href="https://arrow.apache.org/blog/2022/02/16/introducing-arrow-flight-sql/"&gt;Flight SQL protocol&lt;/a&gt;, enabling any compliant Flight SQL client
to connect to and run queries against a Ballista cluster.&lt;/p&gt;
&lt;p&gt;The Apache Arrow Flight SQL JDBC driver can be used to connect Business Intelligence tools to a Ballista cluster.&lt;/p&gt;
&lt;h3&gt;Python Bindings&lt;/h3&gt;
&lt;p&gt;It is now possible to connect to a Ballista cluster from Python and execute queries using both the DataFrame and SQL
interfaces.&lt;/p&gt;
&lt;h3&gt;Scheduler Web User Interface and REST API&lt;/h3&gt;
&lt;p&gt;The scheduler now has a web user interface for monitoring queries. It is also possible to view graphical query plans
that show how the query was executed, along with metrics.&lt;/p&gt;
&lt;p&gt;&lt;img src="../images/2022-10-28-ballista-web-ui.png" width="800"/&gt;&lt;/p&gt;
&lt;p&gt;The REST API that powers the user interface can also be accessed directly.&lt;/p&gt;
&lt;h3&gt;Simplified Kubernetes Deployment&lt;/h3&gt;
&lt;p&gt;Ballista now provides a &lt;a href="https://github.com/apache/arrow-ballista/tree/master/helm"&gt;Helm chart&lt;/a&gt; for simplified Kubernetes deployment.&lt;/p&gt;
&lt;h3&gt;User Guide&lt;/h3&gt;
&lt;p&gt;The user guide is published at &lt;a href="https://arrow.apache.org/ballista/"&gt;https://arrow.apache.org/ballista/&lt;/a&gt; and provides
deployment instructions for Docker, Docker Compose, and Kubernetes, as well as references for configuring and
tuning Ballista.&lt;/p&gt;
&lt;h2&gt;Roadmap&lt;/h2&gt;
&lt;p&gt;The Ballista community is currently focused on the following tasks for the next release:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support for Azure Blob Storage and Google Cloud Storage&lt;/li&gt;
&lt;li&gt;Improve benchmark performance by implementing more query optimizations&lt;/li&gt;
&lt;li&gt;Improve scheduler web user interface&lt;/li&gt;
&lt;li&gt;Publish Docker images to GitHub Container Registry&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The detailed list of issues planned for the 0.10.0 release can be found in the &lt;a href="https://github.com/apache/arrow-ballista/issues/361"&gt;tracking issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Getting Involved&lt;/h2&gt;
&lt;p&gt;Ballista has a friendly community and we welcome contributions. A good place to start is to following the instructions
in the &lt;a href="https://arrow.apache.org/ballista/"&gt;user guide&lt;/a&gt; and try using Ballista with your own SQL queries and ETL pipelines, and file issues
for any bugs or feature suggestions.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow DataFusion 13.0.0 Project Update</title><link href="https://datafusion.apache.org/blog/blog/2022/10/25/datafusion-13.0.0" rel="alternate"></link><published>2022-10-25T00:00:00+00:00</published><updated>2022-10-25T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2022-10-25:/blog/blog/2022/10/25/datafusion-13.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt; &lt;a href="https://crates.io/crates/datafusion"&gt;&lt;code&gt;13.0.0&lt;/code&gt;&lt;/a&gt; is released, and this blog contains an update on the project for the 5 months since our &lt;a href="https://arrow.apache.org/blog/2022/05/16/datafusion-8.0.0/"&gt;last update in May 2022&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;DataFusion is an extensible and embeddable query engine, written in Rust used to create modern, fast and efficient data pipelines, ETL …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;Apache Arrow DataFusion&lt;/a&gt; &lt;a href="https://crates.io/crates/datafusion"&gt;&lt;code&gt;13.0.0&lt;/code&gt;&lt;/a&gt; is released, and this blog contains an update on the project for the 5 months since our &lt;a href="https://arrow.apache.org/blog/2022/05/16/datafusion-8.0.0/"&gt;last update in May 2022&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;DataFusion is an extensible and embeddable query engine, written in Rust used to create modern, fast and efficient data pipelines, ETL processes, and database systems. You may want to check out DataFusion to extend your Rust project to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/sql_status.html"&gt;SQL support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support &lt;a href="https://docs.rs/datafusion/13.0.0/datafusion/dataframe/struct.DataFrame.html"&gt;DataFrame API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support a Domain Specific Query Language&lt;/li&gt;
&lt;li&gt;Easily and quickly read and process Parquet, JSON, Avro or CSV data.&lt;/li&gt;
&lt;li&gt;Read from remote object stores such as AWS S3, Azure Blob Storage, GCP.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Even though DataFusion is 4 years "young," it has seen significant community growth in the last few months and the momentum continues to accelerate.&lt;/p&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;DataFusion is used as the engine in &lt;a href="https://github.com/apache/arrow-datafusion#known-uses"&gt;many open source and commercial projects&lt;/a&gt; and was one of the early open source projects to provide this capability. 2022 has validated our belief in the need for such a &lt;a href="https://docs.google.com/presentation/d/1iNX_35sWUakee2q3zMFPyHE4IV2nC3lkCK_H6Y2qK84/edit#slide=id.p"&gt;"LLVM for database and AI systems"&lt;/a&gt;&lt;a href="https://www.slideshare.net/AndrewLamb32/20220623-apache-arrow-and-datafusion-changing-the-game-for-implementing-database-systemspdf"&gt;(alternate link)&lt;/a&gt; with announcements such as the &lt;a href="https://engineering.fb.com/2022/08/31/open-source/velox/"&gt;release of FaceBook's Velox&lt;/a&gt; engine, the major investments in &lt;a href="https://arrow.apache.org/docs/cpp/streaming_execution.html"&gt;Acero&lt;/a&gt; as well as the continued popularity of &lt;a href="https://calcite.apache.org/"&gt;Apache Calcite&lt;/a&gt; and other similar technologies.&lt;/p&gt;
&lt;p&gt;While Velox and Acero focus on execution engines, DataFusion provides the entire suite of components needed to build most analytic systems, including a SQL frontend, a dataframe API, and  extension points for just about everything. Some &lt;a href="https://github.com/apache/arrow-datafusion#known-uses"&gt;DataFusion users&lt;/a&gt; use a subset of the features such as the frontend (e.g. &lt;a href="https://dask-sql.readthedocs.io/en/latest/"&gt;dask-sql&lt;/a&gt;) or the execution engine, (e.g.  &lt;a href="https://github.com/blaze-init/blaze"&gt;Blaze&lt;/a&gt;), and some use many different components to build both SQL based and customized DSL based systems such as &lt;a href="https://github.com/influxdata/influxdb_iox/pulls"&gt;InfluxDB IOx&lt;/a&gt; and &lt;a href="https://github.com/vegafusion/vegafusion"&gt;VegaFusion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One of DataFusion&amp;rsquo;s advantages is its implementation in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; and thus its easy integration with the broader Rust ecosystem. Rust continues to be a major source of benefit, from the &lt;a href="https://www.influxdata.com/blog/using-rustlangs-async-tokio-runtime-for-cpu-bound-tasks/"&gt;ease of parallelization with the high quality and standardized &lt;code&gt;async&lt;/code&gt; ecosystem&lt;/a&gt; , as well as its modern dependency management system and wonderful performance. &lt;!-- I wonder if we should link to clickbench?? --&gt;
&lt;!--While we haven’t invested in the benchmarking ratings game datafusion continues to be quite speedy (todo quantity this, with some evidence) – maybe clickbench?--&gt;&lt;/p&gt;
&lt;!--
Maybe we can do this un a future post
# DataFusion in Action

While DataFusion really shines as an embeddable query engine, if you want to try it out and get a feel for its power, you can use the basic[`datafusion-cli`](https://docs.rs/datafusion-cli/13.0.0/datafusion_cli/) tool to get a sense for what is possible to add in your application

(TODO example here of using datafusion-cli to query from local parquet files on disk)

TODO: also mention you can use the same thing to query data from S3
--&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;We have increased the frequency of DataFusion releases to monthly instead of quarterly. This
makes it easier for the increasing number of projects that now depend on DataFusion.&lt;/p&gt;
&lt;p&gt;We have also completed the "graduation" of &lt;a href="https://github.com/apache/arrow-ballista"&gt;Ballista to its own top-level arrow-ballista repository&lt;/a&gt;
which decouples the two projects and allows each project to move even faster.&lt;/p&gt;
&lt;p&gt;Along with numerous other bug fixes and smaller improvements, here are some of the major advances:&lt;/p&gt;
&lt;h1&gt;Improved Support for Cloud Object Stores&lt;/h1&gt;
&lt;p&gt;DataFusion now supports many major cloud object stores (Amazon S3, Azure Blob Storage, and Google Cloud Storage) "out of the box" via the &lt;a href="https://crates.io/crates/object_store"&gt;object_store&lt;/a&gt; crate. Using this integration, DataFusion optimizes reading parquet files by reading only the parts of the files that are needed.&lt;/p&gt;
&lt;h2&gt;Advanced SQL&lt;/h2&gt;
&lt;p&gt;DataFusion now supports correlated subqueries, by rewriting them as joins. See the &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/subqueries.html"&gt;Subquery&lt;/a&gt; page in the User Guide for more information.&lt;/p&gt;
&lt;p&gt;In addition to numerous other small improvements, the following SQL features are now supported:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ROWS&lt;/code&gt;, &lt;code&gt;RANGE&lt;/code&gt;, &lt;code&gt;PRECEDING&lt;/code&gt; and &lt;code&gt;FOLLOWING&lt;/code&gt; in &lt;code&gt;OVER&lt;/code&gt; clauses &lt;a href="https://github.com/apache/arrow-datafusion/issues/3570"&gt;#3570&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ROLLUP&lt;/code&gt; and &lt;code&gt;CUBE&lt;/code&gt; grouping set expressions  &lt;a href="https://github.com/apache/arrow-datafusion/issues/2446"&gt;#2446&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SUM DISTINCT&lt;/code&gt; aggregate support  &lt;a href="https://github.com/apache/arrow-datafusion/issues/2405"&gt;#2405&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;IN&lt;/code&gt; and &lt;code&gt;NOT IN&lt;/code&gt; Subqueries by rewriting them to &lt;code&gt;SEMI&lt;/code&gt; / &lt;code&gt;ANTI&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/2885"&gt;#2421&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Non equality predicates in  &lt;code&gt;ON&lt;/code&gt; clause of  &lt;code&gt;LEFT&lt;/code&gt;, &lt;code&gt;RIGHT,&lt;/code&gt;and &lt;code&gt;FULL&lt;/code&gt; joins &lt;a href="https://github.com/apache/arrow-datafusion/issues/2591"&gt;#2591&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Exact &lt;code&gt;MEDIAN&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/3009"&gt;#3009&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GROUPING SETS&lt;/code&gt;/&lt;code&gt;CUBE&lt;/code&gt;/&lt;code&gt;ROLLUP&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/2716"&gt;#2716&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;More DDL Support&lt;/h1&gt;
&lt;p&gt;Just as it is important to query, it is also important to give users the ability to define their data sources. We have added:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CREATE VIEW&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/2279"&gt;#2279&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DESCRIBE &amp;lt;table&amp;gt;&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/2642"&gt;#2642&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Custom / Dynamic table provider factories &lt;a href="https://github.com/apache/arrow-datafusion/issues/3311"&gt;#3311&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SHOW CREATE TABLE&lt;/code&gt; for support for views &lt;a href="https://github.com/apache/arrow-datafusion/issues/2830"&gt;#2830&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Faster Execution&lt;/h1&gt;
&lt;p&gt;Performance is always an important goal for DataFusion, and there are a number of significant new optimizations such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimizations of TopK (queries with a &lt;code&gt;LIMIT&lt;/code&gt; or &lt;code&gt;OFFSET&lt;/code&gt; clause):  &lt;a href="https://github.com/apache/arrow-datafusion/issues/3527"&gt;#3527&lt;/a&gt;, &lt;a href="https://github.com/apache/arrow-datafusion/issues/2521"&gt;#2521&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Reduce &lt;code&gt;left&lt;/code&gt;/&lt;code&gt;right&lt;/code&gt;/&lt;code&gt;full&lt;/code&gt; joins to &lt;code&gt;inner&lt;/code&gt; join &lt;a href="https://github.com/apache/arrow-datafusion/issues/2750"&gt;#2750&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Convert  cross joins to inner joins when possible &lt;a href="https://github.com/apache/arrow-datafusion/issues/3482"&gt;#3482&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sort preserving &lt;code&gt;SortMergeJoin&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/2699"&gt;#2699&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Improvements in group by and sort performance &lt;a href="https://github.com/apache/arrow-datafusion/issues/2375"&gt;#2375&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adaptive &lt;code&gt;regex_replace&lt;/code&gt; implementation &lt;a href="https://github.com/apache/arrow-datafusion/issues/3518"&gt;#3518&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Optimizer Enhancements&lt;/h1&gt;
&lt;p&gt;Internally the optimizer has been significantly enhanced as well.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Casting / coercion now happens during logical planning &lt;a href="https://github.com/apache/arrow-datafusion/issues/3396"&gt;#3185&lt;/a&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/3636"&gt;#3636&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More sophisticated expression analysis and simplification is available&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Parquet&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;The parquet reader can now read directly from parquet files on remote object storage &lt;a href="https://github.com/apache/arrow-datafusion/issues/2677"&gt;#2489&lt;/a&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/3051"&gt;#3051&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Experimental support for &amp;ldquo;predicate pushdown&amp;rdquo; with late materialization after filtering during the scan (another blog post on this topic is coming soon).&lt;/li&gt;
&lt;li&gt;Support reading directly from AWS S3 and other object stores via &lt;code&gt;datafusion-cli&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/3631"&gt;#3631&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;DataType Support&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Support for &lt;code&gt;TimestampTz&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/3660"&gt;#3660&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Expanded support for the &lt;code&gt;Decimal&lt;/code&gt; type, including  &lt;code&gt;IN&lt;/code&gt; list and better built in coercion.&lt;/li&gt;
&lt;li&gt;Expanded support for date/time manipulation such as  &lt;code&gt;date_bin&lt;/code&gt; built-in function , timestamp &lt;code&gt;+/-&lt;/code&gt; interval, &lt;code&gt;TIME&lt;/code&gt; literal values &lt;a href="https://github.com/apache/arrow-datafusion/issues/3010"&gt;#3010&lt;/a&gt;, &lt;a href="https://github.com/apache/arrow-datafusion/issues/3110"&gt;#3110&lt;/a&gt;, &lt;a href="https://github.com/apache/arrow-datafusion/issues/3034"&gt;#3034&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Binary operations (&lt;code&gt;AND&lt;/code&gt;, &lt;code&gt;XOR&lt;/code&gt;, etc):  &lt;a href="https://github.com/apache/arrow-datafusion/issues/1619"&gt;#3037&lt;/a&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/3430"&gt;#3420&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;IS TRUE/FALSE&lt;/code&gt; and &lt;code&gt;IS [NOT] UNKNOWN&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/issues/3235"&gt;#3235&lt;/a&gt;, &lt;a href="https://github.com/apache/arrow-datafusion/issues/3246"&gt;#3246&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Upcoming Work&lt;/h2&gt;
&lt;p&gt;With the community growing and code accelerating, there is so much great stuff on the horizon. Some features we expect to land in the next few months:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion/issues/3462"&gt;Complete Parquet Pushdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion/issues/3148"&gt;Additional date/time support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cost models, Nested Join Optimizations, analysis framework &lt;a href="https://github.com/apache/arrow-datafusion/issues/128"&gt;#128&lt;/a&gt;, &lt;a href="https://github.com/apache/arrow-datafusion/issues/3843"&gt;#3843&lt;/a&gt;, &lt;a href="https://github.com/apache/arrow-datafusion/issues/3845"&gt;#3845&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Community Growth&lt;/h1&gt;
&lt;p&gt;The DataFusion 9.0.0 and 13.0.0 releases consists of 433 PRs from 64 distinct contributors. This does not count all the work that goes into our dependencies such as &lt;a href="https://crates.io/crates/arrow"&gt;arrow&lt;/a&gt;,  &lt;a href="https://crates.io/crates/parquet"&gt;parquet&lt;/a&gt;, and &lt;a href="https://crates.io/crates/object_store"&gt;object_store&lt;/a&gt;, that much of the same community helps nurture.&lt;/p&gt;
&lt;!--
$ git log --pretty=oneline 9.0.0..13.0.0 . | wc -l
433

$ git shortlog -sn 9.0.0..13.0.0 . | wc -l
65
--&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;Kudos to everyone in the community who contributed ideas, discussions, bug reports, documentation and code. It is exciting to be building something so cool together!&lt;/p&gt;
&lt;p&gt;If you are interested in contributing to DataFusion, we would love to
have you join us on our journey to create the most advanced open
source query engine. You can try out DataFusion on some of your own
data and projects and let us know how it goes or contribute a PR with
documentation, tests or code. A list of open issues suitable for
beginners is
&lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Check out our &lt;a href="https://arrow.apache.org/datafusion/community/communication.html"&gt;Communication Doc&lt;/a&gt; on more
ways to engage with the community.&lt;/p&gt;
&lt;h2&gt;Appendix: Contributor Shoutout&lt;/h2&gt;
&lt;p&gt;To give a sense of the number of people who contribute to this project regularly, we present for your consideration the following list derived from &lt;code&gt;git shortlog -sn 9.0.0..13.0.0 .&lt;/code&gt; Thank you all again!&lt;/p&gt;
&lt;!-- Note: combined kmitchener and Kirk Mitchener --&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;    87  Andy Grove&lt;/span&gt;
&lt;span class="err"&gt;    71  Andrew Lamb&lt;/span&gt;
&lt;span class="err"&gt;    29  Kun Liu&lt;/span&gt;
&lt;span class="err"&gt;    29  Kirk Mitchener&lt;/span&gt;
&lt;span class="err"&gt;    17  Wei-Ting Kuo&lt;/span&gt;
&lt;span class="err"&gt;    14  Yang Jiang&lt;/span&gt;
&lt;span class="err"&gt;    12  Raphael Taylor-Davies&lt;/span&gt;
&lt;span class="err"&gt;    11  Batuhan Taskaya&lt;/span&gt;
&lt;span class="err"&gt;    10  Brent Gardner&lt;/span&gt;
&lt;span class="err"&gt;    10  Remzi Yang&lt;/span&gt;
&lt;span class="err"&gt;    10  comphead&lt;/span&gt;
&lt;span class="err"&gt;    10  xudong.w&lt;/span&gt;
&lt;span class="err"&gt;     8  AssHero&lt;/span&gt;
&lt;span class="err"&gt;     7  Ruihang Xia&lt;/span&gt;
&lt;span class="err"&gt;     6  Dan Harris&lt;/span&gt;
&lt;span class="err"&gt;     6  Dani&amp;euml;l Heres&lt;/span&gt;
&lt;span class="err"&gt;     6  Ian Alexander Joiner&lt;/span&gt;
&lt;span class="err"&gt;     6  Mike Roberts&lt;/span&gt;
&lt;span class="err"&gt;     6  askoa&lt;/span&gt;
&lt;span class="err"&gt;     4  BaymaxHWY&lt;/span&gt;
&lt;span class="err"&gt;     4  gorkem&lt;/span&gt;
&lt;span class="err"&gt;     4  jakevin&lt;/span&gt;
&lt;span class="err"&gt;     3  George Andronchik&lt;/span&gt;
&lt;span class="err"&gt;     3  Sarah Yurick&lt;/span&gt;
&lt;span class="err"&gt;     3  Stuart Carnie&lt;/span&gt;
&lt;span class="err"&gt;     2  Dalton Modlin&lt;/span&gt;
&lt;span class="err"&gt;     2  Dmitry Patsura&lt;/span&gt;
&lt;span class="err"&gt;     2  JasonLi&lt;/span&gt;
&lt;span class="err"&gt;     2  Jon Mease&lt;/span&gt;
&lt;span class="err"&gt;     2  Marco Neumann&lt;/span&gt;
&lt;span class="err"&gt;     2  yahoNanJing&lt;/span&gt;
&lt;span class="err"&gt;     1  Adilet Sarsembayev&lt;/span&gt;
&lt;span class="err"&gt;     1  Ayush Dattagupta&lt;/span&gt;
&lt;span class="err"&gt;     1  Dezhi Wu&lt;/span&gt;
&lt;span class="err"&gt;     1  Dhamotharan Sritharan&lt;/span&gt;
&lt;span class="err"&gt;     1  Eduard Karacharov&lt;/span&gt;
&lt;span class="err"&gt;     1  Francis Du&lt;/span&gt;
&lt;span class="err"&gt;     1  Harbour Zheng&lt;/span&gt;
&lt;span class="err"&gt;     1  Isma&amp;euml;l Mej&amp;iacute;a&lt;/span&gt;
&lt;span class="err"&gt;     1  Jack Klamer&lt;/span&gt;
&lt;span class="err"&gt;     1  Jeremy Dyer&lt;/span&gt;
&lt;span class="err"&gt;     1  Jiayu Liu&lt;/span&gt;
&lt;span class="err"&gt;     1  Kamil Konior&lt;/span&gt;
&lt;span class="err"&gt;     1  Liang-Chi Hsieh&lt;/span&gt;
&lt;span class="err"&gt;     1  Martin Grigorov&lt;/span&gt;
&lt;span class="err"&gt;     1  Matthijs Brobbel&lt;/span&gt;
&lt;span class="err"&gt;     1  Mehmet Ozan Kabak&lt;/span&gt;
&lt;span class="err"&gt;     1  Metehan Y&amp;inodot;ld&amp;inodot;r&amp;inodot;m&lt;/span&gt;
&lt;span class="err"&gt;     1  Morgan Cassels&lt;/span&gt;
&lt;span class="err"&gt;     1  Nitish Tiwari&lt;/span&gt;
&lt;span class="err"&gt;     1  Renjie Liu&lt;/span&gt;
&lt;span class="err"&gt;     1  Rito Takeuchi&lt;/span&gt;
&lt;span class="err"&gt;     1  Robert Pack&lt;/span&gt;
&lt;span class="err"&gt;     1  Thomas Cameron&lt;/span&gt;
&lt;span class="err"&gt;     1  Vrishabh&lt;/span&gt;
&lt;span class="err"&gt;     1  Xin Hao&lt;/span&gt;
&lt;span class="err"&gt;     1  Yijie Shen&lt;/span&gt;
&lt;span class="err"&gt;     1  byteink&lt;/span&gt;
&lt;span class="err"&gt;     1  kamille&lt;/span&gt;
&lt;span class="err"&gt;     1  mateuszkj&lt;/span&gt;
&lt;span class="err"&gt;     1  nvartolomei&lt;/span&gt;
&lt;span class="err"&gt;     1  yourenawo&lt;/span&gt;
&lt;span class="err"&gt;     1  &amp;Ouml;zg&amp;uuml;r Akkurt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow DataFusion 8.0.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2022/05/16/datafusion-8.0.0" rel="alternate"></link><published>2022-05-16T00:00:00+00:00</published><updated>2022-05-16T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2022-05-16:/blog/blog/2022/05/16/datafusion-8.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an extensible query execution framework, written in Rust, that
uses Apache Arrow as its in-memory format.&lt;/p&gt;
&lt;p&gt;When you want to extend your Rust project with &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/sql_status.html"&gt;SQL support&lt;/a&gt;,
a DataFrame API, or the ability to read and process Parquet, JSON, Avro or CSV data, DataFusion is definitely worth …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an extensible query execution framework, written in Rust, that
uses Apache Arrow as its in-memory format.&lt;/p&gt;
&lt;p&gt;When you want to extend your Rust project with &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/sql_status.html"&gt;SQL support&lt;/a&gt;,
a DataFrame API, or the ability to read and process Parquet, JSON, Avro or CSV data, DataFusion is definitely worth
checking out.&lt;/p&gt;
&lt;p&gt;DataFusion's SQL, &lt;code&gt;DataFrame&lt;/code&gt;, and manual &lt;code&gt;PlanBuilder&lt;/code&gt; API let users access a sophisticated query optimizer and
execution engine capable of fast, resource efficient, and parallel execution that takes optimal advantage of
today's multicore hardware. Being written in Rust means DataFusion can offer &lt;em&gt;both&lt;/em&gt; the safety of a dynamic language and
the resource efficiency of a compiled language.&lt;/p&gt;
&lt;p&gt;The Apache Arrow team is pleased to announce the DataFusion 8.0.0 release (and also the release of version 0.7.0 of
the Ballista subproject). This covers 3 months of development work and includes 279 commits from the following 49
distinct contributors.&lt;/p&gt;
&lt;!--
$ git log --pretty=oneline 7.0.0..8.0.0 datafusion datafusion-cli datafusion-examples ballista ballista-cli ballista-examples | wc -l
279

$ git shortlog -sn 7.0.0..8.0.0 datafusion datafusion-cli datafusion-examples ballista ballista-cli ballista-examples | wc -l
49

(feynman han, feynman.h, Feynman Han were assumed to be the same person)
--&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Grove&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andrew&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Lamb&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;DuRipeng&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Yijie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Shen&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Yang&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Jiang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Raphael&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Taylor&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Davies&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Harris&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Matthew&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Turner&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;yahoNanJing&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dependabot&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bot&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;jakevin&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Kun&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Liu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jiayu&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Liu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dani&amp;euml;l&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Heres&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;mingmwang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;xudong&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Carol&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Nichols&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Goulding&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dmitry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Patsura&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Eduard&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Karacharov&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jeremy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dyer&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Kaushik&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Rich&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;comphead&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;gaojun2048&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Feynman&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Han&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Han&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mease&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Tim&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Van&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Wassenhove&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Yt&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Zhang&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Li&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;silence&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;coding&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Alexander&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Spies&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;George&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Andronchik&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Guillaume&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Balaine&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Hao&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Xin&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jiacai&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Liu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;J&amp;ouml;rn&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Horstmann&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Liang&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Chi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Hsieh&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;Max&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Burke&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;NaincyKumariKnoldus&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Nga&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Tran&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Patrick&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;More&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Pierre&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Zemb&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Remzi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Yang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Sergey&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Melnychuk&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Stephen&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Carman&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;doki&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The following sections highlight some of the changes in this release. Of course, many other bug fixes and
improvements have been made and we encourage you to check out the
&lt;a href="https://github.com/apache/arrow-datafusion/blob/8.0.0/datafusion/CHANGELOG.md"&gt;changelog&lt;/a&gt; for full details.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;h2&gt;DDL Support&lt;/h2&gt;
&lt;p&gt;DDL support has been expanded to include the following commands for creating databases, schemas, and views. This
allows DataFusion to be used more effectively from the CLI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CREATE DATABASE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CREATE VIEW&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CREATE SCHEMA&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CREATE EXTERNAL TABLE&lt;/code&gt; now supports JSON files, &lt;code&gt;IF NOT EXISTS&lt;/code&gt;, and partition columns&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;SQL Support&lt;/h2&gt;
&lt;p&gt;The SQL query planner now supports a number of new SQL features, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Subqueries&lt;/em&gt;: when used via &lt;code&gt;IN&lt;/code&gt;, &lt;code&gt;EXISTS&lt;/code&gt;, and as scalars&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Grouping Sets&lt;/em&gt;: &lt;code&gt;CUBE&lt;/code&gt; and &lt;code&gt;ROLLUP&lt;/code&gt; grouping sets.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Aggregate functions&lt;/em&gt;: &lt;code&gt;approx_percentile&lt;/code&gt;, &lt;code&gt;approx_percentile_cont&lt;/code&gt;, &lt;code&gt;approx_percentile_cont_with_weight&lt;/code&gt;, &lt;code&gt;approx_distinct&lt;/code&gt;, &lt;code&gt;approx_median&lt;/code&gt; and &lt;code&gt;array&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;code&gt;null&lt;/code&gt; literals&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;bitwise operations&lt;/em&gt;: for example '&lt;code&gt;|&lt;/code&gt;'&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are also many bug fixes and improvements around normalizing identifiers consistently.&lt;/p&gt;
&lt;p&gt;We continue our tradition of incrementally releasing support for new
features as they are developed. Thus, while the physical plan may not yet
support all new features, it gets more complete each release. These
changes also make DataFusion an increasingly compelling choice for
projects looking for a SQL parser and query planner that can produce
optimized logical plans that can be translated to
their own execution engine.&lt;/p&gt;
&lt;h2&gt;Query Execution &amp;amp; Internals&lt;/h2&gt;
&lt;p&gt;There are several notable improvements and new features in the query execution engine:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;ExecutionContext&lt;/code&gt; has been renamed to &lt;code&gt;SessionContext&lt;/code&gt; and now supports multi-tenancy&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;ExecutionPlan&lt;/code&gt; trait is no longer &lt;code&gt;async&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;A new serialization API for serializing plans to bytes (based on protobuf)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, we have added several foundational features to drive even
more advanced query processing into DataFusion, focusing on running
arbitrary queries larger than available memory, and pushing the
envelope for performance of sorting, grouping, and joining even
further:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Morsel-Driven Scheduler based on &lt;a href="https://15721.courses.cs.cmu.edu/spring2016/papers/p743-leis.pdf"&gt;"Morsel-Driven Parallelism: A NUMA-Aware Query
  Evaluation Framework for the Many-Core Age"&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Consolidated object store implementation and integration with parquet decoding&lt;/li&gt;
&lt;li&gt;Memory Limited Spilling sort operator&lt;/li&gt;
&lt;li&gt;Memory Limited Sort-Merge join operator&lt;/li&gt;
&lt;li&gt;High performance JIT code generation for tuple comparisons&lt;/li&gt;
&lt;li&gt;Memory efficient Row Format&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Improved file support&lt;/h2&gt;
&lt;p&gt;DataFusion now supports JSON, both for reading and writing. There are also new DataFrame methods for writing query
results to files in CSV, Parquet, and JSON format.&lt;/p&gt;
&lt;h2&gt;Ballista&lt;/h2&gt;
&lt;p&gt;Ballista continues to mature and now supports a wider range of operators and expressions. There are also improvements
to the scheduler to support UDFs, and there are some robustness improvements, such as cleaning up work directories
and persisting session configs to allow schedulers to restart and continue processing in-flight jobs.&lt;/p&gt;
&lt;h2&gt;Upcoming Work&lt;/h2&gt;
&lt;p&gt;Here are some of the initiatives that the community plans on working on prior to the next release.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is a &lt;a href="https://docs.google.com/document/d/1jNRbadyStSrV5kifwn0khufAwq6OnzGczG4z8oTQJP4/edit?usp=sharing"&gt;proposal to move Ballista to its own top-level arrow-ballista repository&lt;/a&gt;
 to decouple DataFusion and Ballista releases and to allow each project to have documentation better targeted at
  its particular audience.&lt;/li&gt;
&lt;li&gt;We plan on increasing the frequency of DataFusion releases, with monthly releases now instead of quarterly. This
  is driven by requests from the increasing number of projects that now depend on DataFusion.&lt;/li&gt;
&lt;li&gt;There is ongoing work to implement new optimizer rules to rewrite queries containing subquery expressions as
  joins, to support a wider range of queries.&lt;/li&gt;
&lt;li&gt;The new scheduler based on morsel-driven execution will continue to evolve in this next release, with work to
  refine IO abstractions to improve performance and integration with the new scheduler.&lt;/li&gt;
&lt;li&gt;Improved performance for Sort, Grouping and Joins&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to DataFusion, and learning about state-of-the-art query processing, we would
love to have you join us on the journey! You can help by trying out DataFusion on some of your own data and projects
and let us know how it goes or contribute a PR with documentation, tests or code. A list of open issues suitable
for beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Check out our new &lt;a href="https://arrow.apache.org/datafusion/community/communication.html"&gt;Communication Doc&lt;/a&gt; on more
ways to engage with the community.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Introducing Apache Arrow DataFusion Contrib</title><link href="https://datafusion.apache.org/blog/blog/2022/03/21/datafusion-contrib" rel="alternate"></link><published>2022-03-21T00:00:00+00:00</published><updated>2022-03-21T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2022-03-21:/blog/blog/2022/03/21/datafusion-contrib</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Apache Arrow &lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an extensible query execution framework, written in Rust, that uses &lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt; as its in-memory format.&lt;/p&gt;
&lt;p&gt;When you want to extend your Rust project with &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/sql_status.html"&gt;SQL support&lt;/a&gt;, a DataFrame API, or the ability to read and process Parquet, JSON, Avro or CSV data, DataFusion is …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Apache Arrow &lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an extensible query execution framework, written in Rust, that uses &lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt; as its in-memory format.&lt;/p&gt;
&lt;p&gt;When you want to extend your Rust project with &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/sql_status.html"&gt;SQL support&lt;/a&gt;, a DataFrame API, or the ability to read and process Parquet, JSON, Avro or CSV data, DataFusion is definitely worth checking out. DataFusion's pluggable design makes creating extensions at various points particular easy to build.&lt;/p&gt;
&lt;p&gt;DataFusion's  SQL, &lt;code&gt;DataFrame&lt;/code&gt;, and manual &lt;code&gt;PlanBuilder&lt;/code&gt; API let users access a sophisticated query optimizer and execution engine capable of fast, resource efficient, and parallel execution that takes optimal advantage of todays multicore hardware. Being written in Rust means DataFusion can offer &lt;em&gt;both&lt;/em&gt; the safety of dynamic languages as well as the resource efficiency of a compiled language.&lt;/p&gt;
&lt;p&gt;The DataFusion team is pleased to announce the creation of the &lt;a href="https://github.com/datafusion-contrib"&gt;DataFusion-Contrib&lt;/a&gt; GitHub organization to support and accelerate other projects.  While the core DataFusion library remains under Apache governance, the contrib organization provides a more flexible testing ground for new DataFusion features and a home for DataFusion extensions.  With this announcement, we are pleased to introduce the following inaugural DataFusion-Contrib repositories.&lt;/p&gt;
&lt;h2&gt;DataFusion-Python&lt;/h2&gt;
&lt;p&gt;This &lt;a href="https://github.com/datafusion-contrib/datafusion-python"&gt;project&lt;/a&gt; provides Python bindings to the core Rust implementation of DataFusion, which allows users to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Work with familiar SQL or DataFrame APIs to run queries in a safe, multi-threaded environment, returning results in Python&lt;/li&gt;
&lt;li&gt;Create User Defined Functions and User Defined Aggregate Functions for complex operations&lt;/li&gt;
&lt;li&gt;Pay no overhead to copy between Python and underlying Rust execution engine (by way of Apache Arrow arrays)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Upcoming enhancements&lt;/h3&gt;
&lt;p&gt;The team is focusing on exposing more features from the underlying Rust implementation of DataFusion and improving documentation.&lt;/p&gt;
&lt;h3&gt;How to install&lt;/h3&gt;
&lt;p&gt;From &lt;code&gt;pip&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip install datafusion
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;python -m pip install datafusion
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;DataFusion-ObjectStore-S3&lt;/h2&gt;
&lt;p&gt;This &lt;a href="https://github.com/datafusion-contrib/datafusion-objectstore-s3"&gt;crate&lt;/a&gt; provides an &lt;code&gt;ObjectStore&lt;/code&gt; implementation for querying data stored in S3 or S3 compatible storage. This makes it almost as easy to query data that lives on S3 as lives in local files&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ability to create &lt;code&gt;S3FileSystem&lt;/code&gt; to register as part of DataFusion &lt;code&gt;ExecutionContext&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Register files or directories stored on S3 with &lt;code&gt;ctx.register_listing_table&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Upcoming enhancements&lt;/h3&gt;
&lt;p&gt;The current priority is adding python bindings for &lt;code&gt;S3FileSystem&lt;/code&gt;.  After that there will be async improvements as DataFusion adopts more of that functionality and we are looking into S3 Select functionality.&lt;/p&gt;
&lt;h3&gt;How to Install&lt;/h3&gt;
&lt;p&gt;Add the below to your &lt;code&gt;Cargo.toml&lt;/code&gt; in your Rust Project with DataFusion.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;datafusion-objectstore-s3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"0.1.0"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;DataFusion-Substrait&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://substrait.io/"&gt;Substrait&lt;/a&gt; is an emerging standard that provides a cross-language serialization format for relational algebra (e.g. expressions and query plans).&lt;/p&gt;
&lt;p&gt;This &lt;a href="https://github.com/datafusion-contrib/datafusion-substrait"&gt;crate&lt;/a&gt; provides a Substrait producer and consumer for DataFusion.  A producer converts a DataFusion logical plan into a Substrait protobuf and a consumer does the reverse.&lt;/p&gt;
&lt;p&gt;Examples of how to use this crate can be found &lt;a href="https://github.com/datafusion-contrib/datafusion-substrait/blob/main/src/lib.rs"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Potential Use Cases&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Replace custom DataFusion protobuf serialization.&lt;/li&gt;
&lt;li&gt;Make it easier to pass query plans over FFI boundaries, such as from Python to Rust&lt;/li&gt;
&lt;li&gt;Allow Apache Calcite query plans to be executed in DataFusion&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;DataFusion-BigTable&lt;/h2&gt;
&lt;p&gt;This &lt;a href="https://github.com/datafusion-contrib/datafusion-bigtable"&gt;crate&lt;/a&gt; implements &lt;a href="https://cloud.google.com/bigtable"&gt;Bigtable&lt;/a&gt; as a data source and physical executor for DataFusion queries.  It currently supports both UTF-8 string and 64-bit big-endian signed integers in Bigtable.  From a SQL perspective it supports both simple and composite row keys with &lt;code&gt;=&lt;/code&gt;, &lt;code&gt;IN&lt;/code&gt;, and &lt;code&gt;BETWEEN&lt;/code&gt; operators as well as projection pushdown.  The physical execution for queries is handled by this crate while any subsequent aggregation, group bys, or joins are handled in DataFusion.&lt;/p&gt;
&lt;h3&gt;Upcoming Enhancements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Predicate pushdown&lt;/li&gt;
&lt;li&gt;Value range&lt;/li&gt;
&lt;li&gt;Value Regex&lt;/li&gt;
&lt;li&gt;Timestamp range&lt;/li&gt;
&lt;li&gt;Multithreaded&lt;/li&gt;
&lt;li&gt;Partition aware execution&lt;/li&gt;
&lt;li&gt;Production ready&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;How to Install&lt;/h3&gt;
&lt;p&gt;Add the below to your &lt;code&gt;Cargo.toml&lt;/code&gt; in your Rust Project with DataFusion.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;datafusion-bigtable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"0.1.0"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;DataFusion-HDFS&lt;/h2&gt;
&lt;p&gt;This &lt;a href="https://github.com/datafusion-contrib/datafusion-objectstore-hdfs"&gt;crate&lt;/a&gt; introduces &lt;code&gt;HadoopFileSystem&lt;/code&gt; as a remote &lt;code&gt;ObjectStore&lt;/code&gt; which provides the ability to query HDFS files.  For HDFS access the &lt;a href="https://github.com/yahoNanJing/fs-hdfs"&gt;fs-hdfs&lt;/a&gt; library is used.&lt;/p&gt;
&lt;h2&gt;DataFusion-Tokomak&lt;/h2&gt;
&lt;p&gt;This &lt;a href="https://github.com/datafusion-contrib/datafusion-tokomak"&gt;crate&lt;/a&gt; provides an e-graph based DataFusion optimization framework based on the Rust &lt;a href="https://egraphs-good.github.io"&gt;egg&lt;/a&gt; library.  An e-graph is a data structure that powers the equality saturation optimization technique.&lt;/p&gt;
&lt;p&gt;As context, the optimizer framework within DataFusion is currently &lt;a href="https://github.com/apache/arrow-datafusion/issues/1972"&gt;under review&lt;/a&gt; with the objective of implementing a more strategic long term solution that is more efficient and simpler to develop.&lt;/p&gt;
&lt;p&gt;Some of the benefits of using &lt;code&gt;egg&lt;/code&gt; within DataFusion are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implements optimized algorithms that are hard to match with manually written optimization passes&lt;/li&gt;
&lt;li&gt;Makes it easy and less verbose to add optimization rules&lt;/li&gt;
&lt;li&gt;Plugin framework to add more complex optimizations&lt;/li&gt;
&lt;li&gt;Egg does not depend on rule order and can lead to a higher level of optimization by being able to apply multiple rules at the same time until it converges&lt;/li&gt;
&lt;li&gt;Allows for cost-based optimizations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is an exciting new area for DataFusion with lots of opportunity for community involvement!&lt;/p&gt;
&lt;h2&gt;DataFusion-Tui&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/datafusion-contrib/datafusion-tui"&gt;DataFusion-tui&lt;/a&gt; aka &lt;code&gt;dft&lt;/code&gt; provides a feature rich terminal application for using DataFusion.  It has drawn inspiration and several features from &lt;code&gt;datafusion-cli&lt;/code&gt;.  In contrast to &lt;code&gt;datafusion-cli&lt;/code&gt; the objective of this tool is to provide a light SQL IDE experience for querying data with DataFusion.  This includes features such as the following which are currently implemented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tab Management to provide clean and structured organization of DataFusion queries, results, &lt;code&gt;ExecutionContext&lt;/code&gt; information, and logs&lt;/li&gt;
&lt;li&gt;SQL Editor&lt;ul&gt;
&lt;li&gt;Text editor for writing SQL queries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Query History&lt;ul&gt;
&lt;li&gt;History of executed queries, their execution time, and the number of returned rows&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ExecutionContext&lt;/code&gt; information&lt;ul&gt;
&lt;li&gt;Expose information on which physical optimizers are used and which &lt;code&gt;ExecutionConfig&lt;/code&gt; settings are set&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Logs&lt;ul&gt;
&lt;li&gt;Logs from &lt;code&gt;dft&lt;/code&gt;, DataFusion, and any dependent libraries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for custom &lt;code&gt;ObjectStore&lt;/code&gt;s&lt;/li&gt;
&lt;li&gt;S3&lt;/li&gt;
&lt;li&gt;Preload DDL from &lt;code&gt;~/.datafusionrc&lt;/code&gt; to enable having local "database" available at startup&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Upcoming Enhancements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SQL Editor&lt;/li&gt;
&lt;li&gt;Command to write query results to file&lt;/li&gt;
&lt;li&gt;Multiple SQL editor tabs&lt;/li&gt;
&lt;li&gt;Expose more information from &lt;code&gt;ExecutionContext&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;A help tab that provides information on functions&lt;/li&gt;
&lt;li&gt;Query custom &lt;code&gt;TableProvider&lt;/code&gt;s such as &lt;a href="https://github.com/delta-io/delta-rs"&gt;DeltaTable&lt;/a&gt; or &lt;a href="https://github.com/datafusion-contrib/datafusion-bigtable"&gt;BigTable&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;DataFusion-Streams&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/datafusion-contrib/datafusion-streams"&gt;DataFusion-Stream&lt;/a&gt; is a new testing ground for creating a &lt;code&gt;StreamProvider&lt;/code&gt; in DataFusion that will enable querying streaming data sources such as Apache Kafka.  The implementation for this feature is currently being designed and is under active review.  Once the design is finalized the trait and attendant data structures will be added back to the core DataFusion crate.&lt;/p&gt;
&lt;h2&gt;DataFusion-Java&lt;/h2&gt;
&lt;p&gt;This &lt;a href="https://github.com/datafusion-contrib/datafusion-java"&gt;project&lt;/a&gt; created an initial set of Java bindings to DataFusion.  The project is currently in maintenance mode and is looking for maintainers to drive future development.&lt;/p&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to DataFusion, and learning about state of
the art query processing, we would love to have you join us on the journey! You
can help by trying out DataFusion on some of your own data and projects and let us know how it goes or contribute a PR with documentation, tests or code. A list of open issues suitable for beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The best way to find out about creating new extensions within DataFusion-Contrib is reaching out on the &lt;code&gt;#arrow-rust&lt;/code&gt; channel of the Apache Software Foundation &lt;a href="https://join.slack.com/t/the-asf/shared_invite/zt-vlfbf7ch-HkbNHiU_uDlcH_RvaHv9gQ"&gt;Slack&lt;/a&gt; workspace.&lt;/p&gt;
&lt;p&gt;You can also check out our new &lt;a href="https://arrow.apache.org/datafusion/community/communication.html"&gt;Communication Doc&lt;/a&gt; on more ways to engage with the community.&lt;/p&gt;
&lt;p&gt;Links for each DataFusion-Contrib repository are provided above if you would like to contribute to those.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow DataFusion 7.0.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2022/02/28/datafusion-7.0.0" rel="alternate"></link><published>2022-02-28T00:00:00+00:00</published><updated>2022-02-28T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2022-02-28:/blog/blog/2022/02/28/datafusion-7.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an extensible query execution framework, written in Rust, that uses Apache Arrow as its in-memory format.&lt;/p&gt;
&lt;p&gt;When you want to extend your Rust project with &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/sql_status.html"&gt;SQL support&lt;/a&gt;, a DataFrame API, or the ability to read and process Parquet, JSON, Avro or CSV data, DataFusion is definitely worth …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an extensible query execution framework, written in Rust, that uses Apache Arrow as its in-memory format.&lt;/p&gt;
&lt;p&gt;When you want to extend your Rust project with &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/sql_status.html"&gt;SQL support&lt;/a&gt;, a DataFrame API, or the ability to read and process Parquet, JSON, Avro or CSV data, DataFusion is definitely worth checking out.&lt;/p&gt;
&lt;p&gt;DataFusion's  SQL, &lt;code&gt;DataFrame&lt;/code&gt;, and manual &lt;code&gt;PlanBuilder&lt;/code&gt; API let users access a sophisticated query optimizer and execution engine capable of fast, resource efficient, and parallel execution that takes optimal advantage of todays multicore hardware. Being written in Rust means DataFusion can offer &lt;em&gt;both&lt;/em&gt; the safety of dynamic languages as well as the resource efficiency of a compiled language.&lt;/p&gt;
&lt;p&gt;The Apache Arrow team is pleased to announce the DataFusion 7.0.0 release. This covers 4 months of development work
and includes 195 commits from the following 37 distinct contributors.&lt;/p&gt;
&lt;!--
git log --pretty=oneline 5.0.0..6.0.0 datafusion datafusion-cli datafusion-examples | wc -l
     134

git shortlog -sn 5.0.0..6.0.0 datafusion datafusion-cli datafusion-examples | wc -l
      29

      Carlos and xudong963 are same individual
--&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;44&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andrew&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Lamb&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Kun&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Liu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jiayu&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Liu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;xudong&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Yijie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Shen&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Matthew&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Turner&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Liang&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Chi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Hsieh&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Lin&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Ma&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Stephen&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Carman&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;James&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Katz&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dmitry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Patsura&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;QP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Hou&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dependabot&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bot&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Remzi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Yang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Yang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;ic4y&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dani&amp;euml;l&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Heres&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Andy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Grove&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Raphael&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Taylor&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Davies&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Jason&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Tianyi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Wang&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Harris&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Sergey&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Melnychuk&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Nitish&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Tiwari&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Dom&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Eduard&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Karacharov&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Javier&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Goday&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Boaz&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Marko&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mikulicic&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;Max&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Burke&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Carol&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Nichols&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Goulding&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Phillip&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Cloud&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Rich&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Toby&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Hede&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Will&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Jones&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="mf"&gt;.4&lt;/span&gt;&lt;span class="n"&gt;ntix&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;rdettai&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The following section highlights some of the improvements in this release. Of course, many other bug fixes and improvements have also been made and we refer you to the complete &lt;a href="https://github.com/apache/arrow-datafusion/blob/7.0.0/datafusion/CHANGELOG.md"&gt;changelog&lt;/a&gt; for the full detail.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;DataFusion Crate&lt;/li&gt;
&lt;li&gt;The DataFusion crate is being split into multiple crates to decrease compilation times and improve the development experience. Initially, &lt;code&gt;datafusion-common&lt;/code&gt; (the core DataFusion components) and &lt;code&gt;datafusion-expr&lt;/code&gt; (DataFusion expressions, functions, and operators) have been split out. There will be additional splits after the 7.0 release.&lt;/li&gt;
&lt;li&gt;Performance Improvements and Optimizations&lt;/li&gt;
&lt;li&gt;Arrow&amp;rsquo;s dyn scalar kernels are now used to enable efficient operations on &lt;code&gt;DictionaryArray&lt;/code&gt;s &lt;a href="https://github.com/apache/arrow-datafusion/pull/1685"&gt;#1685&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Switch from &lt;code&gt;std::sync::Mutex&lt;/code&gt; to &lt;code&gt;parking_lot::Mutex&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/pull/1720"&gt;#1720&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;New Features&lt;/li&gt;
&lt;li&gt;Support for memory tracking and spilling to disk&lt;ul&gt;
&lt;li&gt;MemoryMananger and DiskManager &lt;a href="https://github.com/apache/arrow-datafusion/pull/1526"&gt;#1526&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Out of core sort &lt;a href="https://github.com/apache/arrow-datafusion/pull/1526"&gt;#1526&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;New metrics&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Gauge&lt;/code&gt; and &lt;code&gt;CurrentMemoryUsage&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/pull/1682"&gt;#1682&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Spill_count&lt;/code&gt; and &lt;code&gt;spilled_bytes&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/pull/1641"&gt;#1641&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;New math functions&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Approx_quantile&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/pull/1539"&gt;#1529&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stddev&lt;/code&gt; and &lt;code&gt;variance&lt;/code&gt; (sample and population) &lt;a href="https://github.com/apache/arrow-datafusion/pull/1525"&gt;#1525&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;corr&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/pull/1561"&gt;#1561&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support decimal type &lt;a href="https://github.com/apache/arrow-datafusion/pull/1394"&gt;#1394&lt;/a&gt;&lt;a href="https://github.com/apache/arrow-datafusion/pull/1407"&gt;#1407&lt;/a&gt;&lt;a href="https://github.com/apache/arrow-datafusion/pull/1408"&gt;#1408&lt;/a&gt;&lt;a href="https://github.com/apache/arrow-datafusion/pull/1431"&gt;#1431&lt;/a&gt;&lt;a href="https://github.com/apache/arrow-datafusion/pull/1483"&gt;#1483&lt;/a&gt;&lt;a href="https://github.com/apache/arrow-datafusion/pull/1554"&gt;#1554&lt;/a&gt;&lt;a href="https://github.com/apache/arrow-datafusion/pull/1640"&gt;#1640&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support for reading Parquet files with evolved schemas &lt;a href="https://github.com/apache/arrow-datafusion/pull/1622"&gt;#1622&lt;/a&gt;&lt;a href="https://github.com/apache/arrow-datafusion/pull/1709"&gt;#1709&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support for registering &lt;code&gt;DataFrame&lt;/code&gt; as table &lt;a href="https://github.com/apache/arrow-datafusion/pull/1699"&gt;#1699&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support for the &lt;code&gt;substring&lt;/code&gt; function &lt;a href="https://github.com/apache/arrow-datafusion/pull/1621"&gt;#1621&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support &lt;code&gt;array_agg(distinct ...)&lt;/code&gt; &lt;a href="https://github.com/apache/arrow-datafusion/pull/1579"&gt;#1579&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support &lt;code&gt;sort&lt;/code&gt; on unprojected columns &lt;a href="https://github.com/apache/arrow-datafusion/pull/1415"&gt;#1415&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Additional Integration Points&lt;/li&gt;
&lt;li&gt;A new public Expression simplification API &lt;a href="https://github.com/apache/arrow-datafusion/pull/1717"&gt;#1717&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datafusion-contrib"&gt;DataFusion-Contrib&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A new GitHub organization created as a home for both &lt;code&gt;DataFusion&lt;/code&gt; extensions and as a testing ground for new features.&lt;ul&gt;
&lt;li&gt;Extensions&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datafusion-contrib/datafusion-python"&gt;DataFusion-Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datafusion-contrib/datafusion-java"&gt;DataFusion-Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datafusion-contrib/datafusion-hdfs-native"&gt;DataFusion-hdsfs-native&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datafusion-contrib/datafusion-objectstore-s3"&gt;DataFusion-ObjectStore-s3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;New Features&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/datafusion-contrib/datafusion-streams"&gt;DataFusion-Streams&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jorgecarleitao/arrow2"&gt;Arrow2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;An &lt;a href="https://github.com/apache/arrow-datafusion/tree/arrow2"&gt;Arrow2 Branch&lt;/a&gt; has been created.  There are ongoing discussions in &lt;a href="https://github.com/apache/arrow-datafusion/issues/1532"&gt;DataFusion&lt;/a&gt; and &lt;a href="https://github.com/apache/arrow-rs/issues/1176"&gt;arrow-rs&lt;/a&gt; about migrating &lt;code&gt;DataFusion&lt;/code&gt; to &lt;code&gt;Arrow2&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Documentation and Roadmap&lt;/h1&gt;
&lt;p&gt;We are working to consolidate the documentation into the &lt;a href="https://arrow.apache.org/datafusion"&gt;official site&lt;/a&gt;.  You can find more details there on topics such as the &lt;a href="https://arrow.apache.org/datafusion/user-guide/sql/index.html"&gt;SQL status&lt;/a&gt;  and a &lt;a href="https://arrow.apache.org/datafusion/user-guide/introduction.html#introduction"&gt;user guide&lt;/a&gt;. This is also an area we would love to get help from the broader community &lt;a href="https://github.com/apache/arrow-datafusion/issues/1821"&gt;#1821&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To provide transparency on DataFusion&amp;rsquo;s priorities to users and developers a three month roadmap will be published at the beginning of each quarter.  This can be found here &lt;a href="https://arrow.apache.org/datafusion/specification/roadmap.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Upcoming Attractions&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Ballista is gaining momentum, and several groups are now evaluating and contributing to the project.&lt;/li&gt;
&lt;li&gt;Some of the proposed improvements&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion/issues/1701"&gt;Improvements Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion/issues/1675"&gt;Extensibility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion/issues/1702"&gt;File system access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion/issues/1704"&gt;Cluster state&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Continued improvements for working with limited resources and large datasets&lt;/li&gt;
&lt;li&gt;Memory limited joins&lt;a href="https://github.com/apache/arrow-datafusion/issues/1599"&gt;#1599&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sort-merge join&lt;a href="https://github.com/apache/arrow-datafusion/issues/141"&gt;#141&lt;/a&gt;&lt;a href="https://github.com/apache/arrow-datafusion/pull/1776"&gt;#1776&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Introduce row based bytes representation &lt;a href="https://github.com/apache/arrow-datafusion/pull/1708"&gt;#1708&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to DataFusion, and learning about state of
the art query processing, we would love to have you join us on the journey! You
can help by trying out DataFusion on some of your own data and projects and let us know how it goes or contribute a PR with documentation, tests or code. A list of open issues suitable for beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Check out our new &lt;a href="https://arrow.apache.org/datafusion/community/communication.html"&gt;Communication Doc&lt;/a&gt; on more
ways to engage with the community.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow DataFusion 6.0.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2021/11/19/2021-11-8-datafusion-6.0.0.md" rel="alternate"></link><published>2021-11-19T00:00:00+00:00</published><updated>2021-11-19T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2021-11-19:/blog/blog/2021/11/19/2021-11-8-datafusion-6.0.0.md</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an embedded
query engine which leverages the unique features of
&lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; and &lt;a href="https://arrow.apache.org/"&gt;Apache
Arrow&lt;/a&gt; to provide a system that is high
performance, easy to connect, easy to embed, and high quality.&lt;/p&gt;
&lt;p&gt;The Apache Arrow team is pleased to announce the DataFusion 6.0.0 release. This covers …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://arrow.apache.org/datafusion/"&gt;DataFusion&lt;/a&gt; is an embedded
query engine which leverages the unique features of
&lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; and &lt;a href="https://arrow.apache.org/"&gt;Apache
Arrow&lt;/a&gt; to provide a system that is high
performance, easy to connect, easy to embed, and high quality.&lt;/p&gt;
&lt;p&gt;The Apache Arrow team is pleased to announce the DataFusion 6.0.0 release. This covers 4 months of development work
and includes 134 commits from the following 28 distinct contributors.&lt;/p&gt;
&lt;!--
git log --pretty=oneline 5.0.0..6.0.0 datafusion datafusion-cli datafusion-examples | wc -l
     134

git shortlog -sn 5.0.0..6.0.0 datafusion datafusion-cli datafusion-examples | wc -l
      29

      Carlos and xudong963 are same individual
--&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;    28  Andrew Lamb&lt;/span&gt;
&lt;span class="err"&gt;    26  Jiayu Liu&lt;/span&gt;
&lt;span class="err"&gt;    13  xudong963&lt;/span&gt;
&lt;span class="err"&gt;     9  rdettai&lt;/span&gt;
&lt;span class="err"&gt;     9  QP Hou&lt;/span&gt;
&lt;span class="err"&gt;     6  Matthew Turner&lt;/span&gt;
&lt;span class="err"&gt;     5  Dani&amp;euml;l Heres&lt;/span&gt;
&lt;span class="err"&gt;     4  Guillaume Balaine&lt;/span&gt;
&lt;span class="err"&gt;     3  Francis Du&lt;/span&gt;
&lt;span class="err"&gt;     3  Marco Neumann&lt;/span&gt;
&lt;span class="err"&gt;     3  Jon Mease&lt;/span&gt;
&lt;span class="err"&gt;     3  Nga Tran&lt;/span&gt;
&lt;span class="err"&gt;     2  Yijie Shen&lt;/span&gt;
&lt;span class="err"&gt;     2  Ruihang Xia&lt;/span&gt;
&lt;span class="err"&gt;     2  Liang-Chi Hsieh&lt;/span&gt;
&lt;span class="err"&gt;     2  baishen&lt;/span&gt;
&lt;span class="err"&gt;     2  Andy Grove&lt;/span&gt;
&lt;span class="err"&gt;     2  Jason Tianyi Wang&lt;/span&gt;
&lt;span class="err"&gt;     1  Nan Zhu&lt;/span&gt;
&lt;span class="err"&gt;     1  Antoine Wendlinger&lt;/span&gt;
&lt;span class="err"&gt;     1  Kriszti&amp;aacute;n Sz&amp;udblac;cs&lt;/span&gt;
&lt;span class="err"&gt;     1  Mike Seddon&lt;/span&gt;
&lt;span class="err"&gt;     1  Conner Murphy&lt;/span&gt;
&lt;span class="err"&gt;     1  Patrick More&lt;/span&gt;
&lt;span class="err"&gt;     1  Taehoon Moon&lt;/span&gt;
&lt;span class="err"&gt;     1  Tiphaine Ruy&lt;/span&gt;
&lt;span class="err"&gt;     1  adsharma&lt;/span&gt;
&lt;span class="err"&gt;     1  lichuan6&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes
and improvements have been made: we refer you to the complete
&lt;a href="https://github.com/apache/arrow-datafusion/blob/6.0.0/datafusion/CHANGELOG.md"&gt;changelog&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;New Website&lt;/h1&gt;
&lt;p&gt;Befitting a growing project, DataFusion now has its
&lt;a href="https://arrow.apache.org/datafusion/"&gt;own website&lt;/a&gt; hosted as part of the
main &lt;a href="https://arrow.apache.org"&gt;Apache Arrow Website&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Roadmap&lt;/h1&gt;
&lt;p&gt;The community worked to gather their thoughts about where we are
taking DataFusion into a public
&lt;a href="https://arrow.apache.org/datafusion/specification/roadmap.html"&gt;Roadmap&lt;/a&gt;
for the first time&lt;/p&gt;
&lt;h1&gt;New Features&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Runtime operator metrics collection framework&lt;/li&gt;
&lt;li&gt;Object store abstraction for unified access to local or remote storage&lt;/li&gt;
&lt;li&gt;Hive style table partitioning support, for Parquet, CSV, Avro and Json files&lt;/li&gt;
&lt;li&gt;DataFrame API support for: &lt;code&gt;except&lt;/code&gt;, &lt;code&gt;intersect&lt;/code&gt;, &lt;code&gt;show&lt;/code&gt;, &lt;code&gt;limit&lt;/code&gt; and window functions&lt;/li&gt;
&lt;li&gt;SQL&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt; with runtime metrics&lt;/li&gt;
&lt;li&gt;&lt;code&gt;trim ( [ LEADING | TRAILING | BOTH ] [ FROM ] string text [, characters text ] )&lt;/code&gt; syntax&lt;/li&gt;
&lt;li&gt;Postgres style regular expression matching operators &lt;code&gt;~&lt;/code&gt;, &lt;code&gt;~*&lt;/code&gt;, &lt;code&gt;!~&lt;/code&gt;, and &lt;code&gt;!~*&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;SQL set operators &lt;code&gt;UNION&lt;/code&gt;, &lt;code&gt;INTERSECT&lt;/code&gt;, and &lt;code&gt;EXCEPT&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cume_dist&lt;/code&gt;, &lt;code&gt;percent_rank&lt;/code&gt; window functions&lt;/li&gt;
&lt;li&gt;&lt;code&gt;digest&lt;/code&gt;, &lt;code&gt;blake2s&lt;/code&gt;, &lt;code&gt;blake2b&lt;/code&gt;, &lt;code&gt;blake3&lt;/code&gt; crypto functions&lt;/li&gt;
&lt;li&gt;HyperLogLog based &lt;code&gt;approx_distinct&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;is distinct from&lt;/code&gt; and &lt;code&gt;is not distinct from&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CREATE TABLE AS SELECT&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Accessing elements of nested &lt;code&gt;Struct&lt;/code&gt; and &lt;code&gt;List&lt;/code&gt; columns (e.g. &lt;code&gt;SELECT struct_column['field_name'], array_column[0] FROM ...&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Boolean expressions in &lt;code&gt;CASE&lt;/code&gt; statement&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DROP TABLE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VALUES&lt;/code&gt; List&lt;/li&gt;
&lt;li&gt;Postgres regex match operators&lt;/li&gt;
&lt;li&gt;Support for Avro format&lt;/li&gt;
&lt;li&gt;Support for &lt;code&gt;ScalarValue::Struct&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Automatic schema inference for CSV files&lt;/li&gt;
&lt;li&gt;Better interactive editing support in &lt;code&gt;datafusion-cli&lt;/code&gt; as well as &lt;code&gt;psql&lt;/code&gt; style commands such as &lt;code&gt;\d&lt;/code&gt;, &lt;code&gt;\?&lt;/code&gt;, and &lt;code&gt;\q&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Generic constant evaluation and simplification framework&lt;/li&gt;
&lt;li&gt;Added common subexpression eliminate query plan optimization rule&lt;/li&gt;
&lt;li&gt;Python binding 0.4.0 with all Datafusion 6.0.0 features&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With these new features, we are also now passing TPC-H queries 8, 13 and 21.&lt;/p&gt;
&lt;p&gt;For the full list of new features with their relevant PRs, see the
&lt;a href="https://github.com/apache/arrow-datafusion/blob/6.0.0/datafusion/CHANGELOG.md"&gt;enhancements section&lt;/a&gt;
in the changelog.&lt;/p&gt;
&lt;h1&gt;&lt;code&gt;async&lt;/code&gt; planning and decoupling file format from table layout&lt;/h1&gt;
&lt;p&gt;Driven by the need to support Hive style table partitioning, @rdettai
introduced the following design change to the Datafusion core.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The code for reading specific file formats (&lt;code&gt;Parquet&lt;/code&gt;, &lt;code&gt;Avro&lt;/code&gt;, &lt;code&gt;CSV&lt;/code&gt;, and
&lt;code&gt;JSON&lt;/code&gt;) was separated from the logic that handles grouping sets of
files into execution partitions.&lt;/li&gt;
&lt;li&gt;The query planning process was made &lt;code&gt;async&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As a result, we are able to replace the old &lt;code&gt;Parquet&lt;/code&gt;, &lt;code&gt;CSV&lt;/code&gt; and &lt;code&gt;JSON&lt;/code&gt; table
providers with a single &lt;code&gt;ListingTable&lt;/code&gt; table provider.&lt;/p&gt;
&lt;p&gt;This also sets up DataFusion and its plug-in ecosystem to
supporting a wide range of catalogs and various object store implementations.
You can read more about this change in the
&lt;a href="https://docs.google.com/document/d/1Bd4-PLLH-pHj0BquMDsJ6cVr_awnxTuvwNJuWsTHxAQ"&gt;design document&lt;/a&gt;
and on the &lt;a href="https://github.com/apache/arrow-datafusion/pull/1010"&gt;arrow-datafusion#1010 PR&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to DataFusion, we would love to have you! You
can help by trying out DataFusion on some of your own data and projects and filing bug reports and helping to
improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for
beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;
and the full list is &lt;a href="https://github.com/apache/arrow-datafusion/issues"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Check out our new &lt;a href="https://arrow.apache.org/datafusion/community/communication.html"&gt;Communication Doc&lt;/a&gt; on more
ways to engage with the community.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow Ballista 0.5.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2021/08/18/ballista-0.5.0" rel="alternate"></link><published>2021-08-18T00:00:00+00:00</published><updated>2021-08-18T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2021-08-18:/blog/blog/2021/08/18/ballista-0.5.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;Ballista extends DataFusion to provide support for distributed queries. This is the first release of Ballista since 
the project was &lt;a href="https://arrow.apache.org/blog/2021/04/12/ballista-donation/"&gt;donated&lt;/a&gt; to the Apache Arrow project 
and includes 80 commits from 11 contributors.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;git shortlog -sn 4.0.0..5.0.0 ballista/rust/client ballista/rust/core ballista/rust …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;Ballista extends DataFusion to provide support for distributed queries. This is the first release of Ballista since 
the project was &lt;a href="https://arrow.apache.org/blog/2021/04/12/ballista-donation/"&gt;donated&lt;/a&gt; to the Apache Arrow project 
and includes 80 commits from 11 contributors.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;git shortlog -sn 4.0.0..5.0.0 ballista/rust/client ballista/rust/core ballista/rust/executor ballista/rust/scheduler&lt;/span&gt;
&lt;span class="err"&gt;  27  Andy Grove&lt;/span&gt;
&lt;span class="err"&gt;  15  Jiayu Liu&lt;/span&gt;
&lt;span class="err"&gt;  12  Andrew Lamb&lt;/span&gt;
&lt;span class="err"&gt;   8  Ximo Guanter&lt;/span&gt;
&lt;span class="err"&gt;   6  Dani&amp;euml;l Heres&lt;/span&gt;
&lt;span class="err"&gt;   5  QP Hou&lt;/span&gt;
&lt;span class="err"&gt;   2  Jorge Leitao&lt;/span&gt;
&lt;span class="err"&gt;   1  Javier Goday&lt;/span&gt;
&lt;span class="err"&gt;   1  K.I. (Dennis) Jung&lt;/span&gt;
&lt;span class="err"&gt;   1  Mike Seddon&lt;/span&gt;
&lt;span class="err"&gt;   1  sathis&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!--
$ git log --pretty=oneline 4.0.0..5.0.0 ballista/rust/client ballista/rust/core ballista/rust/executor ballista/rust/scheduler ballista-examples/ | wc -l
80
--&gt;
&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes 
and improvements have been made: we refer you to the &lt;a href="https://github.com/apache/arrow-datafusion/blob/5.0.0/ballista/CHANGELOG.md"&gt;complete changelog&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Performance and Scalability&lt;/h1&gt;
&lt;p&gt;Ballista is now capable of running complex SQL queries at scale and supports scalable distributed joins. We have been 
benchmarking using individual queries from the TPC-H benchmark at scale factors up to 1000 (1 TB). When running against 
CSV files, performance is generally very close to DataFusion, and significantly faster in some cases due to the fact 
that the scheduler limits the number of concurrent tasks that run at any given time. Performance against large Parquet 
datasets is currently non ideal due to some issues (&lt;a href="https://github.com/apache/arrow-datafusion/issues/867"&gt;#867&lt;/a&gt;, 
&lt;a href="https://github.com/apache/arrow-datafusion/issues/868"&gt;#868&lt;/a&gt;) that we hope to resolve for the next release. &lt;/p&gt;
&lt;h1&gt;New Features&lt;/h1&gt;
&lt;p&gt;The main new features in this release are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ballista queries can now be executed by calling DataFrame.collect()&lt;/li&gt;
&lt;li&gt;The shuffle mechanism has been re-implemented&lt;/li&gt;
&lt;li&gt;Distributed hash-partitioned joins are now supported&lt;/li&gt;
&lt;li&gt;Keda autoscaling is supported&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To get started with Ballista, refer to the &lt;a href="https://docs.rs/ballista/0.5.0/ballista/"&gt;crate documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now that the basic functionality is in place, the focus for the next release will be to improve the performance and
scalability as well as improving the documentation.&lt;/p&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to Ballista, we would love to have you! You
can help by trying out Ballista on some of your own data and projects and filing bug reports and helping to
improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for
beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt;
and the full list is &lt;a href="https://github.com/apache/arrow-datafusion/issues"&gt;here&lt;/a&gt;.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Apache Arrow DataFusion 5.0.0 Release</title><link href="https://datafusion.apache.org/blog/blog/2021/08/18/datafusion-5.0.0" rel="alternate"></link><published>2021-08-18T00:00:00+00:00</published><updated>2021-08-18T00:00:00+00:00</updated><author><name>pmc</name></author><id>tag:datafusion.apache.org,2021-08-18:/blog/blog/2021/08/18/datafusion-5.0.0</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache Arrow team is pleased to announce the DataFusion 5.0.0 release. This covers 4 months of development work 
and includes 211 commits from the following 31 distinct contributors.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ git shortlog -sn &lt;span class="m"&gt;4&lt;/span&gt;.0.0..5.0.0 datafusion datafusion-cli datafusion-examples
    &lt;span class="m"&gt;61&lt;/span&gt;  Jiayu Liu
    &lt;span class="m"&gt;47&lt;/span&gt;  Andrew Lamb
    &lt;span class="m"&gt;27 …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;The Apache Arrow team is pleased to announce the DataFusion 5.0.0 release. This covers 4 months of development work 
and includes 211 commits from the following 31 distinct contributors.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ git shortlog -sn &lt;span class="m"&gt;4&lt;/span&gt;.0.0..5.0.0 datafusion datafusion-cli datafusion-examples
    &lt;span class="m"&gt;61&lt;/span&gt;  Jiayu Liu
    &lt;span class="m"&gt;47&lt;/span&gt;  Andrew Lamb
    &lt;span class="m"&gt;27&lt;/span&gt;  Dani&amp;euml;l Heres
    &lt;span class="m"&gt;13&lt;/span&gt;  QP Hou
    &lt;span class="m"&gt;13&lt;/span&gt;  Andy Grove
     &lt;span class="m"&gt;4&lt;/span&gt;  Javier Goday
     &lt;span class="m"&gt;4&lt;/span&gt;  sathis
     &lt;span class="m"&gt;3&lt;/span&gt;  Ruan Pearce-Authers
     &lt;span class="m"&gt;3&lt;/span&gt;  Raphael Taylor-Davies
     &lt;span class="m"&gt;3&lt;/span&gt;  Jorge Leitao
     &lt;span class="m"&gt;3&lt;/span&gt;  Cui Wenzheng
     &lt;span class="m"&gt;3&lt;/span&gt;  Mike Seddon
     &lt;span class="m"&gt;3&lt;/span&gt;  Edd Robinson
     &lt;span class="m"&gt;2&lt;/span&gt;  思维
     &lt;span class="m"&gt;2&lt;/span&gt;  Liang-Chi Hsieh
     &lt;span class="m"&gt;2&lt;/span&gt;  Michael Lu
     &lt;span class="m"&gt;2&lt;/span&gt;  Parth Sarthy
     &lt;span class="m"&gt;2&lt;/span&gt;  Patrick More
     &lt;span class="m"&gt;2&lt;/span&gt;  Rich
     &lt;span class="m"&gt;1&lt;/span&gt;  Charlie Evans
     &lt;span class="m"&gt;1&lt;/span&gt;  Gang Liao
     &lt;span class="m"&gt;1&lt;/span&gt;  Agata Naomichi
     &lt;span class="m"&gt;1&lt;/span&gt;  Ritchie Vink
     &lt;span class="m"&gt;1&lt;/span&gt;  Evan Chan
     &lt;span class="m"&gt;1&lt;/span&gt;  Ruihang Xia
     &lt;span class="m"&gt;1&lt;/span&gt;  Todd Treece
     &lt;span class="m"&gt;1&lt;/span&gt;  Yichen Wang
     &lt;span class="m"&gt;1&lt;/span&gt;  baishen
     &lt;span class="m"&gt;1&lt;/span&gt;  Nga Tran
     &lt;span class="m"&gt;1&lt;/span&gt;  rdettai
     &lt;span class="m"&gt;1&lt;/span&gt;  Marco Neumann
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!--
$ git log --pretty=oneline 4.0.0..5.0.0 datafusion datafusion-cli datafusion-examples | wc -l
     211
--&gt;
&lt;p&gt;The release notes below are not exhaustive and only expose selected highlights of the release. Many other bug fixes 
and improvements have been made: we refer you to the complete 
&lt;a href="https://github.com/apache/arrow-datafusion/blob/5.0.0/datafusion/CHANGELOG.md"&gt;changelog&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Performance&lt;/h1&gt;
&lt;p&gt;There have been numerous performance improvements in this release. The following chart shows the relative 
performance of individual TPC-H queries compared to the previous release.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;TPC-H @ scale factor 100, in parquet format. Concurrency 24.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="../images/2021-08-18-datafusion500perf.png"/&gt;&lt;/p&gt;
&lt;p&gt;We also extended support for more TPC-H queries: q7, q8, q9 and q13 are running successfully in DataFusion 5.0.&lt;/p&gt;
&lt;h1&gt;New Features&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Initial support for SQL-99 Analytics (WINDOW functions)&lt;/li&gt;
&lt;li&gt;Improved JOIN support: cross join, semi-join, anti join, and fixes to null handling&lt;/li&gt;
&lt;li&gt;Improved EXPLAIN support&lt;/li&gt;
&lt;li&gt;Initial implementation of metrics in the physical plan&lt;/li&gt;
&lt;li&gt;Support for SELECT DISTINCT&lt;/li&gt;
&lt;li&gt;Support for Json and NDJson formatted inputs&lt;/li&gt;
&lt;li&gt;Query column with relations&lt;/li&gt;
&lt;li&gt;Added more datetime related functions: &lt;code&gt;now&lt;/code&gt;, &lt;code&gt;date_trunc&lt;/code&gt;, &lt;code&gt;to_timestamp_millis&lt;/code&gt;, &lt;code&gt;to_timestamp_micros&lt;/code&gt;, &lt;code&gt;to_timestamp_seconds&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Streaming Dataframe.collect&lt;/li&gt;
&lt;li&gt;Support table column aliases&lt;/li&gt;
&lt;li&gt;Answer count(*), min() and max() queries using only statistics&lt;/li&gt;
&lt;li&gt;Non-equi-join filters in JOIN conditions&lt;/li&gt;
&lt;li&gt;Modulus operation&lt;/li&gt;
&lt;li&gt;Support group by column positions&lt;/li&gt;
&lt;li&gt;Added constant folding query optimizer&lt;/li&gt;
&lt;li&gt;Hash partitioned aggregation&lt;/li&gt;
&lt;li&gt;Added &lt;code&gt;random&lt;/code&gt; SQL function&lt;/li&gt;
&lt;li&gt;Implemented count distinct for floats and dictionary types&lt;/li&gt;
&lt;li&gt;Re-exported arrow and parquet crates in Datafusion&lt;/li&gt;
&lt;li&gt;General row group pruning logic that&amp;rsquo;s agnostic to storage format&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;How to Get Involved&lt;/h1&gt;
&lt;p&gt;If you are interested in contributing to DataFusion, we would love to have you! You 
can help by trying out DataFusion on some of your own data and projects and filing bug reports and helping to 
improve the documentation, or contribute to the documentation, tests or code. A list of open issues suitable for 
beginners is &lt;a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;here&lt;/a&gt; 
and the full list is &lt;a href="https://github.com/apache/arrow-datafusion/issues"&gt;here&lt;/a&gt;.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Ballista: A Distributed Scheduler for Apache Arrow</title><link href="https://datafusion.apache.org/blog/blog/2021/04/12/ballista-donation" rel="alternate"></link><published>2021-04-12T00:00:00+00:00</published><updated>2021-04-12T00:00:00+00:00</updated><author><name>agrove</name></author><id>tag:datafusion.apache.org,2021-04-12:/blog/blog/2021/04/12/ballista-donation</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;We are excited to announce that &lt;a href="https://github.com/apache/arrow-datafusion/tree/master/ballista"&gt;Ballista&lt;/a&gt; has been donated 
to the Apache Arrow project. &lt;/p&gt;
&lt;p&gt;Ballista is a distributed compute platform primarily implemented in Rust, and powered by Apache Arrow. It is built
on an architecture that allows other programming languages (such as Python, C++, and Java) to be supported …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;We are excited to announce that &lt;a href="https://github.com/apache/arrow-datafusion/tree/master/ballista"&gt;Ballista&lt;/a&gt; has been donated 
to the Apache Arrow project. &lt;/p&gt;
&lt;p&gt;Ballista is a distributed compute platform primarily implemented in Rust, and powered by Apache Arrow. It is built
on an architecture that allows other programming languages (such as Python, C++, and Java) to be supported as
first-class citizens without paying a penalty for serialization costs.&lt;/p&gt;
&lt;p&gt;The foundational technologies in Ballista are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; memory model and compute kernels for efficient processing of data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion"&gt;Apache Arrow DataFusion&lt;/a&gt; query planning and 
  execution framework, extended by Ballista to provide distributed planning and execution.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/"&gt;Apache Arrow Flight Protocol&lt;/a&gt; for efficient
  data transfer between processes.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developers.google.com/protocol-buffers"&gt;Google Protocol Buffers&lt;/a&gt; for serializing query plans.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; for packaging up executors along with user-defined code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ballista can be deployed as a standalone cluster and also supports &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;. In either
case, the scheduler can be configured to use &lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; as a backing store to (eventually) provide
redundancy in the case of a scheduler failing.&lt;/p&gt;
&lt;h2&gt;Status&lt;/h2&gt;
&lt;p&gt;The Ballista project is at an early stage of development. However, it is capable of running complex analytics queries 
in a distributed cluster with reasonable performance (comparable to more established distributed query frameworks).&lt;/p&gt;
&lt;p&gt;One of the benefits of Ballista being part of the Arrow codebase is that there is now an opportunity to push parts of 
the scheduler down to DataFusion so that is possible to seamlessly scale across cores in DataFusion, and across nodes 
in Ballista, using the same unified query scheduler.&lt;/p&gt;
&lt;h2&gt;Contributors Welcome!&lt;/h2&gt;
&lt;p&gt;If you are excited about being able to use Rust for distributed compute and ETL and would like to contribute to this 
work then there are many ways to get involved. The simplest way to get started is to try out Ballista against your own 
datasets and file bug reports for any issues that you find. You could also check out the current 
&lt;a href="https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20component%20%3D%20%22Rust%20-%20Ballista%22"&gt;list of issues&lt;/a&gt; and have a go at fixing one.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/apache/arrow/blob/master/rust/README.md#arrow-rust-community"&gt;Arrow Rust Community&lt;/a&gt;
section of the Rust README provides information on other ways to interact with the Ballista contributors and 
maintainers.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>DataFusion: A Rust-native Query Engine for Apache Arrow</title><link href="https://datafusion.apache.org/blog/blog/2019/02/04/datafusion-donation" rel="alternate"></link><published>2019-02-04T00:00:00+00:00</published><updated>2019-02-04T00:00:00+00:00</updated><author><name>agrove</name></author><id>tag:datafusion.apache.org,2019-02-04:/blog/blog/2019/02/04/datafusion-donation</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;We are excited to announce that &lt;a href="https://github.com/apache/arrow-datafusion"&gt;DataFusion&lt;/a&gt; has been donated to the Apache Arrow project. DataFusion is an in-memory query engine for the Rust implementation of Apache Arrow.&lt;/p&gt;
&lt;p&gt;Although DataFusion was started two years ago, it was recently re-implemented to be Arrow-native and currently has limited capabilities but does support …&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;p&gt;We are excited to announce that &lt;a href="https://github.com/apache/arrow-datafusion"&gt;DataFusion&lt;/a&gt; has been donated to the Apache Arrow project. DataFusion is an in-memory query engine for the Rust implementation of Apache Arrow.&lt;/p&gt;
&lt;p&gt;Although DataFusion was started two years ago, it was recently re-implemented to be Arrow-native and currently has limited capabilities but does support SQL queries against iterators of RecordBatch and has support for CSV files. There are plans to &lt;a href="https://issues.apache.org/jira/browse/ARROW-4466"&gt;add support for Parquet files&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;SQL support is limited to projection (&lt;code&gt;SELECT&lt;/code&gt;), selection (&lt;code&gt;WHERE&lt;/code&gt;), and simple aggregates (&lt;code&gt;MIN&lt;/code&gt;, &lt;code&gt;MAX&lt;/code&gt;, &lt;code&gt;SUM&lt;/code&gt;) with an optional &lt;code&gt;GROUP BY&lt;/code&gt; clause.&lt;/p&gt;
&lt;p&gt;Supported expressions are identifiers, literals, simple math operations (&lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;), binary expressions (&lt;code&gt;AND&lt;/code&gt;, &lt;code&gt;OR&lt;/code&gt;), equality and comparison operators (&lt;code&gt;=&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;), and &lt;code&gt;CAST(expr AS type)&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;The following example demonstrates running a simple aggregate SQL query against a CSV file.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;// create execution context&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;mut&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ExecutionContext&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// define schema for data source (csv file)&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;schema&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Arc&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Schema&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vec&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c1"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;Utf8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c2"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;UInt32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c3"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;Int8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c4"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;Int16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c5"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;Int32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c6"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;Int64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c7"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;UInt8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c8"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;UInt16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c9"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;UInt32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c10"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;UInt64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c11"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;Float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c12"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;Float64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"c13"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DataType&lt;/span&gt;::&lt;span class="n"&gt;Utf8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;]));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// register csv file with the execution context&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;csv_datasource&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;CsvDataSource&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"test/data/aggregate_test_100.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;schema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clone&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;register_datasource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"aggregate_test_100"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Rc&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;RefCell&lt;/span&gt;::&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;csv_datasource&lt;/span&gt;&lt;span class="p"&gt;)));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"SELECT c1, MIN(c12), MAX(c12) FROM aggregate_test_100 WHERE c11 &amp;gt; 0.1 AND c11 &amp;lt; 0.9 GROUP BY c1"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// execute the query&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;relation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;mut&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;relation&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;borrow_mut&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c1"&gt;// iterate over the results&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;Some&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s"&gt;"RecordBatch has {} rows and {} columns"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_rows&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_columns&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_any&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;downcast_ref&lt;/span&gt;::&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;BinaryArray&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_any&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;downcast_ref&lt;/span&gt;::&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Float64Array&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_any&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;downcast_ref&lt;/span&gt;::&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Float64Array&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;..&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_rows&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c1_value&lt;/span&gt;: &lt;span class="nb"&gt;String&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;String&lt;/span&gt;::&lt;span class="n"&gt;from_utf8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;to_vec&lt;/span&gt;&lt;span class="p"&gt;()).&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"{}, Min: {}, Max: {}"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c1_value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Roadmap&lt;/h2&gt;
&lt;p&gt;The roadmap for DataFusion will depend on interest from the Rust community, but here are some of the short term items that are planned:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extending test coverage of the existing functionality&lt;/li&gt;
&lt;li&gt;Adding support for Parquet data sources&lt;/li&gt;
&lt;li&gt;Implementing more SQL features such as &lt;code&gt;JOIN&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt; and &lt;code&gt;LIMIT&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Implement a DataFrame API as an alternative to SQL&lt;/li&gt;
&lt;li&gt;Adding support for partitioning and parallel query execution using Rust's async and await functionality&lt;/li&gt;
&lt;li&gt;Creating a Docker image to make it easy to use DataFusion as a standalone query tool for interactive and batch queries&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Contributors Welcome!&lt;/h2&gt;
&lt;p&gt;If you are excited about being able to use Rust for data science and would like to contribute to this work then there are many ways to get involved. The simplest way to get started is to try out DataFusion against your own data sources and file bug reports for any issues that you find. You could also check out the current &lt;a href="https://cwiki.apache.org/confluence/display/ARROW/Rust+JIRA+Dashboard"&gt;list of issues&lt;/a&gt; and have a go at fixing one. You can also join the &lt;a href="http://mail-archives.apache.org/mod_mbox/arrow-user/"&gt;user mailing list&lt;/a&gt; to ask questions.&lt;/p&gt;</content><category term="blog"></category></entry></feed>