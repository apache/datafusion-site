<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Apache DataFusion Blog - Adrian Garcia Badaracco (Pydantic), Andrew Lamb (InfluxData)</title><link href="https://datafusion.apache.org/blog/" rel="alternate"></link><link href="https://datafusion.apache.org/blog/feeds/adrian-garcia-badaracco-pydantic-andrew-lamb-influxdata.atom.xml" rel="self"></link><id>https://datafusion.apache.org/blog/</id><updated>2025-09-10T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Dynamic Filters: Passing Information Between Operators During Execution for 10x Faster Queries</title><link href="https://datafusion.apache.org/blog/2025/09/10/dynamic-filters" rel="alternate"></link><published>2025-09-10T00:00:00+00:00</published><updated>2025-09-10T00:00:00+00:00</updated><author><name>Adrian Garcia Badaracco (Pydantic), Andrew Lamb (InfluxData)</name></author><id>tag:datafusion.apache.org,2025-09-10:/blog/2025/09/10/dynamic-filters</id><summary type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;!-- 
diagrams source: https://docs.google.com/presentation/d/1FFYy27ydZdeFZWWuMjZGnYKUx9QNJfzuVLAH8AE5wlc/edit?slide=id.g364a74cba3d_0_92#slide=id.g364a74cba3d_0_92
Intended Audience: Query engine / data systems developers who want to learn about topk optimization
Goal: Introduce TopK and dynamic filters as in general optimization techniques for query engines, and how they were used to improve performance in DataFusion.
--&gt;
&lt;p&gt;This blog post introduces the query engine optimization techniques called TopK
and dynamic filters. We describe the motivating use case, how these
optimizations work, and how we implemented them with the &lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt;
community to support advanced use cases like custom operators and distributed
usage. These optimizations (and related work â€¦&lt;/p&gt;</summary><content type="html">&lt;!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
--&gt;
&lt;!-- 
diagrams source: https://docs.google.com/presentation/d/1FFYy27ydZdeFZWWuMjZGnYKUx9QNJfzuVLAH8AE5wlc/edit?slide=id.g364a74cba3d_0_92#slide=id.g364a74cba3d_0_92
Intended Audience: Query engine / data systems developers who want to learn about topk optimization
Goal: Introduce TopK and dynamic filters as in general optimization techniques for query engines, and how they were used to improve performance in DataFusion.
--&gt;
&lt;p&gt;This blog post introduces the query engine optimization techniques called TopK
and dynamic filters. We describe the motivating use case, how these
optimizations work, and how we implemented them with the &lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt;
community to support advanced use cases like custom operators and distributed
usage. These optimizations (and related work) have resulted in order of
magnitude improvements for some query patterns.&lt;/p&gt;
&lt;h2&gt;Motivation and Results&lt;/h2&gt;
&lt;p&gt;The main commercial product at &lt;a href="https://pydantic.dev"&gt;Pydantic&lt;/a&gt;, &lt;a href="https://pydantic.dev/logfire"&gt;Logfire&lt;/a&gt; is an observability
platform built on DataFusion. One of the most common workflows / queries is
"show me the last K traces" which translates to a query similar to:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;SELECT * FROM records ORDER BY start_timestamp DESC LIMIT 1000;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We noticed this was &lt;em&gt;pretty slow&lt;/em&gt;, even thought DataFusion has long had the
classic &lt;code&gt;TopK&lt;/code&gt; optimization (described below). After implementing the
dynamic filter techniques described in this blog, we saw &lt;em&gt;10x and higher
performance improvement&lt;/em&gt; for this query pattern, and are applying the
optimization to other queries and operators as well.&lt;/p&gt;
&lt;p&gt;Let's look at some preliminary numbers, using &lt;a href="https://github.com/apache/datafusion/blob/main/benchmarks/queries/clickbench/queries/q23.sql"&gt;ClickBench&lt;/a&gt; which is very similar to our earlier examples:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;SELECT * FROM hits WHERE "URL" LIKE '%google%' ORDER BY "EventTime" LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class="text-center"&gt;
&lt;img alt="Q23 Performance Improvement with Dynamic Filters and Late Materialization" class="img-responsive" src="/blog/images/dynamic-filters/execution-time.svg" width="80%"/&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;: Execution times for ClickBench Q23 with and without dynamic
filters (DF)&lt;sup id="fn1"&gt;&lt;a href="#footnote1"&gt;1&lt;/a&gt;&lt;/sup&gt;, and late materialization
(LM)&lt;sup id="fn2"&gt;&lt;a href="#footnote2"&gt;2&lt;/a&gt;&lt;/sup&gt; for different partitions / core usage.
Both dynamic filters alone (yellow) and late materialization alone (red) show a
large improvement over the baseline (blue). Combined (green) they show an even
larger improvement, up to a 22x improvement in execution time. See the appendix
for reproduction instructions.&lt;/p&gt;
&lt;h2&gt;Background: TopK Optimization&lt;/h2&gt;
&lt;p&gt;To explain how dynamic filters improve query performance we first need to
explain the so called "TopK" optimization. To do so we will use a simplified
version of ClickBench Q23:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;SELECT * 
FROM hits 
ORDER BY "EventTime"
LIMIT 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A straightforward, though slow, plan to answer this query is shown in Figure 2.&lt;/p&gt;
&lt;div class="text-center"&gt;
&lt;img alt="Naive Query Plan" class="img-responsive" src="/blog/images/dynamic-filters/query-plan-naive.png" width="80%"/&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt;: Simple Query Plan for ClickBench Q23. Data flows in plans from the
scan at the bottom to limit at the top. This plan reads all 100M rows of the
&lt;code&gt;hits&lt;/code&gt; table, sorts them by &lt;code&gt;EventTime&lt;/code&gt;, and then return only the top 10 rows.&lt;/p&gt;
&lt;p&gt;This naive plan requires substantial effort: all columns from all rows are
decoded and sorted, but then only 10 are returned. &lt;/p&gt;
&lt;p&gt;High performance query engines typically avoid the expensive full sort a
specialized operator that tracks the current top rows using a &lt;a href="https://en.wikipedia.org/wiki/Heap_(data_structure)"&gt;heap&lt;/a&gt;, rather
than sorting the entire data. For example this operator
is called &lt;a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/struct.TopK.html"&gt;TopK in DataFusion&lt;/a&gt;, &lt;a href="https://docs.snowflake.com/en/user-guide/ui-snowsight-activity"&gt;SortWithLimit in Snowflake&lt;/a&gt; and &lt;a href="https://duckdb.org/2024/10/25/topn.html#introduction-to-top-n"&gt;topn in
DuckDB&lt;/a&gt;. The plan for Q23 using this specialized operator is shown in Figure 3.&lt;/p&gt;
&lt;div class="text-center"&gt;
&lt;img alt="TopK Query Plan" class="img-responsive" src="/blog/images/dynamic-filters/query-plan-topk.png" width="80%"/&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 3&lt;/strong&gt;: Query plan for Q23 in DataFusion using the TopK Operator. This
plan still reads all 100M rows of the &lt;code&gt;hits&lt;/code&gt; table, but instead of first sorting
them all by &lt;code&gt;EventTime&lt;/code&gt;, the TopK operator keeps track of the current top 10
rows using a Min/Max heap. Credit to &lt;a href="https://visualgo.net/en"&gt;Visualgo&lt;/a&gt; for the
heap icon&lt;/p&gt;
&lt;p&gt;However, this plan still reads and decodes all 100M rows of the &lt;code&gt;hits&lt;/code&gt; table,
which is often unnecessary once we have found the top 10 rows. For example,
while running they query, if the current top 10 rows all have &lt;code&gt;EventTime&lt;/code&gt; in
2025, then any subsequent rows with &lt;code&gt;EventTime&lt;/code&gt; in 2024 or earlier can be
skipped entirely without reading or decoding them. This technique is especially
effective at skipping entire files or row groups if the top 10 values are in the
first few files read, which is very common with timestamp predicates when the
data insert order is approximately the same as the timestamp order.&lt;/p&gt;
&lt;p&gt;Leveraging this insight is the key idea behind dynamic filters, which introduces
a runtime mechanism for the TopK operator to provide the current top values to
scan operator, allowing it to skip unnecessary rows, entire files, or portions
of files. The plan for Q23 with dynamic filters is shown in Figure 4.&lt;/p&gt;
&lt;div class="text-center"&gt;
&lt;img alt="TopK Query Plan with Dynamic Filters" class="img-responsive" src="/blog/images/dynamic-filters/query-plan-topk-dynamic-filters.png" width="80%"/&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt;: Query plan for Q23 in DataFusion with specialized TopK Operator
and dynamic filters. The TopK operator provides the minimum &lt;code&gt;EventTime&lt;/code&gt; of the
current top 10 rows to the scan operator, allowing it to skip rows with
&lt;code&gt;EventTime&lt;/code&gt; earlier than that value. The scan operator uses this dynamic filter
to skip unnecessary files, and rows, reducing the amount of data that needs to
be read and&lt;/p&gt;
&lt;h2&gt;Topk and Dynamic Filters: Example&lt;/h2&gt;
&lt;p&gt;To dynamic filters more concrete let's look at a simplified example. Imagine we
have a table &lt;code&gt;records&lt;/code&gt; with a column &lt;code&gt;start_timestamp&lt;/code&gt; and we are running the
query from the introduction:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;SELECT * 
FROM records 
ORDER BY start_timestamp 
DESC LIMIT 3;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, let's imagine that at some point during execution, the heap in the
&lt;code&gt;TopK&lt;/code&gt; operator has actual 3 most recent values:&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;start_timestamp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2025-08-16T20:35:15.00Z&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2025-08-16T20:35:14.00Z&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2025-08-16T20:35:13.00Z&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since &lt;code&gt;2025-08-16T20:35:13.00Z&lt;/code&gt; is the smallest of these values, we know that
any subsequent rows with &lt;code&gt;start_timestamp&lt;/code&gt; less than or equal to this value
cannot possibly be in the top 3, and can be skipped entirely.&lt;/p&gt;
&lt;p&gt;We can express this condition as a filter of the form &lt;code&gt;start_timestamp &amp;gt;
'2025-08-16T20:35:13.00Z'&lt;/code&gt;. If we knew the correct timestamp value before
starting the plan, we could simply write:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;SELECT *
FROM records
WHERE start_timestamp &amp;gt; '2025-08-16T20:35:13.00Z'  -- Filter to skip rows
ORDER BY start_timestamp DESC
LIMIT 3;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And DataFusion's sophisticated &lt;a href="https://datafusion.apache.org/blog/2025/08/15/external-parquet-indexes/"&gt;multi-level filter pushdown&lt;/a&gt; and pruning would
ensure that we skip reading unnecessary files and row groups, and only decode
the necessary rows.&lt;/p&gt;
&lt;p&gt;However, obviously when we start running the query we don't have the value
&lt;code&gt;'2025-08-16T20:35:13.00Z'&lt;/code&gt; so what DataFusion does is put in a placeholder in
the plan, which you can think of as:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;SELECT *
FROM records
WHERE dynamic_filter()
ORDER BY start_timestamp DESC
LIMIT 3;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, &lt;code&gt;dynamic_filter()&lt;/code&gt; is a structure that initially has the value
&lt;code&gt;true&lt;/code&gt; but will be progressively updated by the TopK operator as the query
progresses. Note that while we are using SQL for illustrative purposes these
optimizations are actually done at the physical plan ([&lt;code&gt;ExecutionPlan&lt;/code&gt;]) layer -
and they apply to both SQL and DataFrame APIs.&lt;/p&gt;
&lt;h2&gt;Improving TopK in DataFusion&lt;/h2&gt;
&lt;p&gt;As mentioned above, DataFusion has a specialized sort operator named [&lt;code&gt;TopK&lt;/code&gt;]
that only keeps ~ &lt;code&gt;K&lt;/code&gt; rows in memory. For a &lt;code&gt;DESC&lt;/code&gt; sort order, each new input
batch is compared against the current &lt;code&gt;K&lt;/code&gt; largest values, and then the current
&lt;code&gt;K&lt;/code&gt; rows possibly get replaced with any new rows that were larger. The &lt;a href="https://github.com/apache/datafusion/blob/b4a8b5ae54d939353b7cbd5ab8aee7d3bedecb66/datafusion/physical-plan/src/topk/mod.rs"&gt;code is here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Prior to dynamic filters, DataFusion had no early termination: it would read the
&lt;em&gt;entire&lt;/em&gt; &lt;code&gt;records&lt;/code&gt; table even if it already had the top &lt;code&gt;K&lt;/code&gt; rows because it
still had to check that there were no rows that had larger &lt;code&gt;start_timestamp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can see how this is a problem if you have 2 years worth of timeseries data:
the largest &lt;code&gt;1000&lt;/code&gt; values of &lt;code&gt;start_timestamp&lt;/code&gt; are likely within the first few
files read, but even if the TopK operator has seen 1000 timestamps on August
16th 2025, DataFusion would still read files that have only data in 2024 just to
make sure.&lt;/p&gt;
&lt;p&gt;InfluxData &lt;a href="https://www.influxdata.com/blog/making-recent-value-queries-hundreds-times-faster/"&gt;optimized a similar query pattern in InfluxDB IOx&lt;/a&gt; using another
operator called [&lt;code&gt;ProgressiveEvalExec&lt;/code&gt;] but that operator requires that the data
is already sorted and a careful analysis of ordering to prove that it can be
used. That is not the case for Logfire data (and many other datasets out there):
data can tend to be &lt;em&gt;roughly&lt;/em&gt; sorted (e.g. if you append to files as you receive
it) but that does not guarantee that it is fully sorted, including between
files. &lt;/p&gt;
&lt;p&gt;We &lt;a href="https://github.com/apache/datafusion/issues/15037"&gt;discussed possible solutions&lt;/a&gt; with the community, which ultimately resulted
in the implementation of "dynamic filters", and our design is general enough it
applies to joins as well. We believe our implementation is very similar to
recently announced optimizations in closed source, commercial systems such as
&lt;a href="https://program.berlinbuzzwords.de/bbuzz24/talk/3DTQJB/"&gt;Accelerating TopK Queries in Snowflake&lt;/a&gt;, or &lt;a href="https://www.alibabacloud.com/blog/about-database-kernel-%7C-learn-about-polardb-imci-optimization-techniques_600274"&gt;self sharpening runtime filters in
Alibaba Cloud's PolarDB&lt;/a&gt;, and we are excited we can offer similar performance
improvements in an open source query engine like DataFusion. We hope this will
help all users with similar workloads.&lt;/p&gt;
&lt;h2&gt;Implementation for TopK Operator&lt;/h2&gt;
&lt;p&gt;TopK operators (a specialization of a sort operator + a limit operator)
implement dynamic filter pushdown by updating a filter each time the heap / topK
is updated. The filter is then used to skip rows and files during the scan
operator. At the query plan level, Q23 looks like this before it is executed:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;       SortExec(TopK)      &amp;boxv;
&amp;boxv;    --------------------   &amp;boxv;
&amp;boxv; EventTime@4 ASC NULLS LAST&amp;boxv;
&amp;boxv;                           &amp;boxv;
&amp;boxv;         limit: 10         &amp;boxv;
&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhd;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;       DataSourceExec      &amp;boxv;
&amp;boxv;    --------------------   &amp;boxv;
&amp;boxv;         files: 100        &amp;boxv;
&amp;boxv;      format: parquet      &amp;boxv;
&amp;boxv;                           &amp;boxv;
&amp;boxv;         predicate:        &amp;boxv;
&amp;boxv; CAST(URL AS Utf8View) LIKE&amp;boxv;
&amp;boxv;      %google% AND true    &amp;boxv;
&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see the &lt;code&gt;true&lt;/code&gt; placeholder filter for the dynamic filter in the
&lt;code&gt;predicate&lt;/code&gt; field of the &lt;code&gt;DataSourceExec&lt;/code&gt; operator. This will be updated by the
&lt;code&gt;SortExec&lt;/code&gt; operator as it processes rows. After running the query, the plan
looks like this, showing the updated filter:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;       SortExec(TopK)      &amp;boxv;
&amp;boxv;    --------------------   &amp;boxv;
&amp;boxv; EventTime@4 ASC NULLS LAST&amp;boxv;
&amp;boxv;                           &amp;boxv;
&amp;boxv;         limit: 10         &amp;boxv;
&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhd;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;       DataSourceExec      &amp;boxv;
&amp;boxv;    --------------------   &amp;boxv;
&amp;boxv;         files: 100        &amp;boxv;
&amp;boxv;      format: parquet      &amp;boxv;
&amp;boxv;                           &amp;boxv;
&amp;boxv;         predicate:        &amp;boxv;
&amp;boxv; CAST(URL AS Utf8View) LIKE&amp;boxv;
&amp;boxv;      %google% AND         &amp;boxv;
&amp;boxv; EventTime &amp;lt; 1372713773.0  &amp;boxv;
&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Implementation for Hash Join Operator&lt;/h2&gt;
&lt;p&gt;We've also implemented dynamic filters for hash joins, also called "sideways information passing".&lt;/p&gt;
&lt;p&gt;In a Hash Join the query engine picks one side of the join to be the "build" side and the other side to be the "probe" side. The build side is read first and then the probe side is read, using a hash table built from the build side to match rows from the probe side.
Dynamic filters are used to filter the probe side based on the values from the build side.
In particular, we take the min/max values from the build side and use them to create a filter that is applied to the probe side.
This is a very cheap filter to evaluate but when combined with statistics pruning, later materialization and other optimizations it can lead to significant performance improvements (we've observed up to 20x improvements in some queries).&lt;/p&gt;
&lt;p&gt;A query plan for a hash join with dynamic filters looks like this after it is executed:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;copy (select i as k from generate_series(1, 1000) t(i)) to 'small_table.parquet';
copy (select i as k, i as v from generate_series(1, 100000) t(i)) to 'large_table.parquet';
create external table small_table stored as parquet location 'small_table.parquet';
create external table large_table stored as parquet location 'large_table.parquet';
explain select * from small_table join large_table on small_table.k = large_table.k where large_table.v &amp;gt;= 50;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;    CoalesceBatchesExec    &amp;boxv;
&amp;boxv;    --------------------   &amp;boxv;
&amp;boxv;     target_batch_size:    &amp;boxv;
&amp;boxv;            8192           &amp;boxv;
&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhd;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;        HashJoinExec       &amp;boxv;
&amp;boxv;    --------------------   &amp;boxvr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;        on: (k = k)        &amp;boxv;              &amp;boxv;
&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhd;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;              &amp;boxv;
&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;&amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
&amp;boxv;       DataSourceExec      &amp;boxv;&amp;boxv;    CoalesceBatchesExec    &amp;boxv;
&amp;boxv;    --------------------   &amp;boxv;&amp;boxv;    --------------------   &amp;boxv;
&amp;boxv;          files: 1         &amp;boxv;&amp;boxv;     target_batch_size:    &amp;boxv;
&amp;boxv;      format: parquet      &amp;boxv;&amp;boxv;            8192           &amp;boxv;
&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;&amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhd;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
                              &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
                              &amp;boxv;         FilterExec        &amp;boxv;
                              &amp;boxv;    --------------------   &amp;boxv;
                              &amp;boxv;     predicate: v &amp;gt;= 50    &amp;boxv;
                              &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhd;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
                              &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
                              &amp;boxv;      RepartitionExec      &amp;boxv;
                              &amp;boxv;    --------------------   &amp;boxv;
                              &amp;boxv; partition_count(in-&amp;gt;out): &amp;boxv;
                              &amp;boxv;          1 -&amp;gt; 12          &amp;boxv;
                              &amp;boxv;                           &amp;boxv;
                              &amp;boxv;    partitioning_scheme:   &amp;boxv;
                              &amp;boxv;    RoundRobinBatch(12)    &amp;boxv;
                              &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhd;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
                              &amp;boxdr;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxhu;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxdl;
                              &amp;boxv;       DataSourceExec      &amp;boxv;
                              &amp;boxv;    --------------------   &amp;boxv;
                              &amp;boxv;          files: 1         &amp;boxv;
                              &amp;boxv;      format: parquet      &amp;boxv;
                              &amp;boxv;                           &amp;boxv;
                              &amp;boxv;         predicate:        &amp;boxv;
                              &amp;boxv;      v &amp;gt;= 50 AND.         &amp;boxv;
                              &amp;boxv;     k &amp;gt;= 1 AND k &amp;lt;= 1000  &amp;boxv;
                              &amp;boxur;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxh;&amp;boxul;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Implementation for Scan Operator&lt;/h2&gt;
&lt;p&gt;Scan operators do not actually know anything about dynamic filters: we were able to package up dynamic filters as an &lt;code&gt;Arc&amp;lt;dyn PhysicalExpr&amp;gt;&lt;/code&gt; which is mostly handled by scan operators like any other expression.
We did however add some new functionality to &lt;code&gt;PhysicalExpr&lt;/code&gt; to make working with dynamic filters easier:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;PhysicalExpr::generation() -&amp;gt; u64&lt;/code&gt;: used to track if a tree of filters has changed (e.g. because it has a dynamic filter that has been updated). For example, if we go from &lt;code&gt;c1 = 'a' AND DynamicFilter [ c2 &amp;gt; 1]&lt;/code&gt; to &lt;code&gt;c1 = 'a' AND DynamicFilter [ c2 &amp;gt; 2]&lt;/code&gt; the generation value will change so we know if we should re-evaluate the filter against static date like file or row group level statistics. This is used to do early termination of reading a file if the filter is updated mid scan and we can now skip the file, all without needlessly re-evaluating file level statistics all the time.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PhysicalExpr::snapshot() -&amp;gt; Arc&amp;lt;dyn PhysicalExpr&amp;gt;&lt;/code&gt;: used to create a snapshot of the filter at a given point in time. Dynamic filters use this to return the current value of their innner static filter. This can be used to serialize the filter across the wire in the case of distributed queries or to pass to systems that only support more basic filters (e.g. stats pruning rewrites).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is all encapsulated in the &lt;code&gt;DynamicFilterPhysicalExpr&lt;/code&gt; struct.&lt;/p&gt;
&lt;p&gt;One of the important design decisions was around directionality of information passing and locking: some early designs had the scan polling the source operators on every row / batch, but this causes a lot of overhead.
Instead we opted for a "push" based model where the read path has minimal locking and the write path (the TopK operator) is responsible for updating the filter.
Thus &lt;code&gt;DynamicFilterPhysicalExpr&lt;/code&gt; is essentially an &lt;code&gt;Arc&amp;lt;RwLock&amp;lt;Arc&amp;lt;dyn PhysicalExpr&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; which allows the TopK operator to update the filter while the scan operator can read it without blocking.&lt;/p&gt;
&lt;h2&gt;Custom &lt;code&gt;ExectuionPlan&lt;/code&gt; Operators&lt;/h2&gt;
&lt;p&gt;We went to great efforts to ensure that dynamic filters are not a hardcoded black box that only works for internal operators.
The DataFusion community is dynamic and the project is used in many different contexts, some with very advanced custom operators specialized for specific use cases.
To support this we made sure that dynamic filters can be used with custom &lt;code&gt;ExecutionPlan&lt;/code&gt; operators by implementing a couple of methods in the &lt;code&gt;ExecutionPlan&lt;/code&gt; trait.
We've made an extensive library of helper structs and functions that make it only 1-2 lines to implement filter pushdown support or a source of dynamic filters for custom operators.&lt;/p&gt;
&lt;p&gt;This approach has already paid off: we've had multiple community members implement support for dynamic filter pushdown in just the first few months of this feature being available.&lt;/p&gt;
&lt;h2&gt;Future Work&lt;/h2&gt;
&lt;p&gt;Although we've made great progress and DataFusion now has one of the most advanced dynamic filter / sideways information passing implementations that we know of we are not done yet!&lt;/p&gt;
&lt;p&gt;There's a multitude of areas of future improvement that we are looking into:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support for more types of joins: we only implemented support for hash inner joins so far. There's the potential to expand this to other join types both in terms of the physical implementation (nested loop joins, etc.) and join type (e.g. left outer joins, cross joins, etc.).&lt;/li&gt;
&lt;li&gt;Push down entire hash tables to the scan operator: this could potentially help a lot with join keys that are not naturally ordered or have a lot of skew.&lt;/li&gt;
&lt;li&gt;Use file level statistics to order files to match the &lt;code&gt;ORDER BY&lt;/code&gt; clause as best we can: this will help TopK dynamic filters be more effective by skipping more work earlier in the scan.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;h3&gt;Queries and Data&lt;/h3&gt;
&lt;h4&gt;Figure 1: ClickBench Q23&lt;/h4&gt;
&lt;pre&gt;&lt;code class="language-sql"&gt;-- Data was downloaded using apache/datafusion -&amp;gt; benchmarks/bench.sh -&amp;gt; ./benchmarks/bench.sh data clickbench_partitioned
create external table hits stored as parquet location 'benchmarks/data/hits_partitioned';

-- Must set for ClickBench hits_partitioned dataset. See https://github.com/apache/datafusion/issues/16591
set datafusion.execution.parquet.binary_as_string = true;
-- Only matters if pushdown_filters is enabled but they don't get enabled together sadly
set datafusion.execution.parquet.reorder_filters = true;

set datafusion.execution.target_partitions = 1;  -- or set to 12 to use multiple cores
set datafusion.optimizer.enable_dynamic_filter_pushdown = false;
set datafusion.execution.parquet.pushdown_filters = false;

explain analyze
SELECT *
FROM hits
WHERE "URL" LIKE '%google%'
ORDER BY "EventTime"
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left;"&gt;dynamic filters&lt;/th&gt;
&lt;th style="text-align: left;"&gt;late materialization&lt;/th&gt;
&lt;th style="text-align: right;"&gt;cores&lt;/th&gt;
&lt;th style="text-align: right;"&gt;time (s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;False&lt;/td&gt;
&lt;td style="text-align: left;"&gt;False&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1&lt;/td&gt;
&lt;td style="text-align: right;"&gt;32.039&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;False&lt;/td&gt;
&lt;td style="text-align: left;"&gt;True&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1&lt;/td&gt;
&lt;td style="text-align: right;"&gt;16.903&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;True&lt;/td&gt;
&lt;td style="text-align: left;"&gt;False&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1&lt;/td&gt;
&lt;td style="text-align: right;"&gt;18.195&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;True&lt;/td&gt;
&lt;td style="text-align: left;"&gt;True&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1.42&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;False&lt;/td&gt;
&lt;td style="text-align: left;"&gt;False&lt;/td&gt;
&lt;td style="text-align: right;"&gt;12&lt;/td&gt;
&lt;td style="text-align: right;"&gt;5.04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;False&lt;/td&gt;
&lt;td style="text-align: left;"&gt;True&lt;/td&gt;
&lt;td style="text-align: right;"&gt;12&lt;/td&gt;
&lt;td style="text-align: right;"&gt;2.37&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;True&lt;/td&gt;
&lt;td style="text-align: left;"&gt;False&lt;/td&gt;
&lt;td style="text-align: right;"&gt;12&lt;/td&gt;
&lt;td style="text-align: right;"&gt;5.055&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left;"&gt;True&lt;/td&gt;
&lt;td style="text-align: left;"&gt;True&lt;/td&gt;
&lt;td style="text-align: right;"&gt;12&lt;/td&gt;
&lt;td style="text-align: right;"&gt;0.602&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;About the Authors&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.linkedin.com/in/adrian-garcia-badaracco/"&gt;Adrian Garcia Badaracco&lt;/a&gt; is a Founding Engineer at
&lt;a href="https://pydantic.dev/"&gt;Pydantic&lt;/a&gt;, and an &lt;a href="https://datafusion.apache.org/"&gt;Apache
DataFusion&lt;/a&gt; committer. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.linkedin.com/in/andrewalamb/"&gt;Andrew Lamb&lt;/a&gt; is a Staff Engineer at
&lt;a href="https://www.influxdata.com/"&gt;InfluxData&lt;/a&gt;, and a member of the &lt;a href="https://datafusion.apache.org/"&gt;Apache
DataFusion&lt;/a&gt; and &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; PMCs. He has been working on
Databases and related systems more than 20 years.&lt;/p&gt;
&lt;h2&gt;About DataFusion&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://datafusion.apache.org/"&gt;Apache DataFusion&lt;/a&gt; is an extensible query engine toolkit, written
in Rust, that uses &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; as its in-memory format. DataFusion and
similar technology are part of the next generation &amp;ldquo;Deconstructed Database&amp;rdquo;
architectures, where new systems are built on a foundation of fast, modular
components, rather than as a single tightly integrated system.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://datafusion.apache.org/contributor-guide/communication.html"&gt;DataFusion community&lt;/a&gt; is always looking for new contributors to help
improve the project. If you are interested in learning more about how query
execution works, help document or improve the DataFusion codebase, or just try
it out, we would love for you to join us.&lt;/p&gt;
&lt;h2&gt;Footnotes&lt;/h2&gt;
&lt;p&gt;&lt;a id="footnote1"&gt;&lt;/a&gt;&lt;sup&gt;&lt;a href="#fn1"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;em&gt;Dynamic Filters (DF)&lt;/em&gt; refers to the
optimization described in this blog post. The TopK operator will generate a
filter that is applied to the scan operators, which will first be used to skip
rows and then as we open new files (if there are more to open) it will be used
to skip entire files that do not match the filter.&lt;/p&gt;
&lt;p&gt;&lt;a id="footnote2"&gt;&lt;/a&gt;&lt;sup&gt;&lt;a href="#fn2"&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;em&gt;Late Materialization (LM)&lt;/em&gt; refers to
the optimization described in &lt;a href="https://datafusion.apache.org/blog/2025/03/21/parquet-pushdown/"&gt;this blog post&lt;/a&gt;. Late Materialization is
particularly effective when combined with dynamic filters as it can apply
filters during a scan. Without late materialization, dynamic filters can only be
used to prune row groups or entire files, which will be less effective if the 
files themselves are large or the top values are not in the first few files read.&lt;/p&gt;</content><category term="blog"></category></entry></feed>